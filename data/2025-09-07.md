<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Reactive Bottom-Up Testing](https://arxiv.org/abs/2509.03711)
*Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry*

Main category: cs.CR

TL;DR: New testing method combines bottom-up approach with program context awareness to better detect software vulnerabilities, successfully finding 28 known and 6 new exploits.


<details>
  <summary>Details</summary>
Motivation: Current dynamic testing techniques are ineffective at reaching deep functions in call graphs, while bottom-up approaches suffer from false positives and context issues. This creates a critical need for deeper, context-aware vulnerability validation.

Method: Three-stage process: 1) Generate context-aware harnesses for potentially vulnerable functions 2) Fuzz testing + symbolic execution to find + constrain crashes 3) Constraint merging to eliminate false positives.

Result: Identified 28 of 48 known vulnerabilities in a benchmark (5 projects) and discovered 6 novel vulnerabilities in real-world applications like Pacman.

Conclusion: Reactive Bottom-Up Testing enhances vulnerability detection in complex systems by validating functions within program context. This approach achieves higher accuracy than existing methods.

Abstract: Modern computing systems remain rife with software vulnerabilities. Engineers
apply many means to detect them, of which dynamic testing is one of the most
common and effective. However, most dynamic testing techniques follow a
top-down paradigm, and struggle to reach and exercise functions deep within the
call graph. While recent works have proposed Bottom-Up approaches to address
these limitations, they face challenges with false positives and generating
valid inputs that adhere to the context of the entire program.
  In this work, we introduce a new paradigm that we call Reactive Bottom-Up
Testing. Our insight is that function-level testing is necessary but not
sufficient for the validation of vulnerabilities in functions. What we need is
a systematic approach that not only tests functions in isolation but also
validates their behavior within the broader program context, ensuring that
detected vulnerabilities are both reachable and triggerable. We develop a
three-stage bottom-up testing scheme: (1) identify likely-vulnerable functions
and generate type- and context-aware harnesses; (2) fuzz to find crashes and
extract input constraints via symbolic execution; (3) verify crashes by
combining constraints to remove false positives. We implemented an automated
prototype, which we call Griller. We evaluated Griller in a controlled setting
using a benchmark of 48 known vulnerabilities across 5 open-source projects,
where we successfully detected 28 known vulnerabilities. Additionally, we
evaluated Griller on several real-world applications such as Pacman, and it
discovered 6 previously unknown vulnerabilities. Our findings suggest that
Reactive Bottom-Up Testing can significantly enhance the detection of
vulnerabilities in complex systems, paving the way for more robust security
practices.

</details>


### [2] [A Quantum Genetic Algorithm-Enhanced Self-Supervised Intrusion Detection System for Wireless Sensor Networks in the Internet of Things](https://arxiv.org/abs/2509.03744)
*Hamid Barati*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid expansion of the Internet of Things (IoT) and Wireless Sensor
Networks (WSNs) has significantly increased the attack surface of such systems,
making them vulnerable to a wide range of cyber threats. Traditional Intrusion
Detection Systems (IDS) often fail to meet the stringent requirements of
resource-constrained IoT environments due to their high computational cost and
reliance on large labeled datasets. To address these challenges, this paper
proposes a novel hybrid Intrusion Detection System that integrates a Quantum
Genetic Algorithm (QGA) with Self-Supervised Learning (SSL). The QGA leverages
quantum-inspired evolutionary operators to optimize feature selection and
fine-tune model parameters, ensuring lightweight yet efficient detection in
resource-limited networks. Meanwhile, SSL enables the system to learn robust
representations from unlabeled data, thereby reducing dependency on manually
labeled training sets. The proposed framework is evaluated on benchmark IoT
intrusion datasets, demonstrating superior performance in terms of detection
accuracy, false positive rate, and computational efficiency compared to
conventional evolutionary and deep learning-based IDS models. The results
highlight the potential of combining quantum-inspired optimization with
self-supervised paradigms to design next-generation intrusion detection
solutions for IoT and WSN environments.

</details>


### [3] [Peekaboo, I See Your Queries: Passive Attacks Against DSSE Via Intermittent Observations](https://arxiv.org/abs/2509.03806)
*Hao Nie,Wei Wang,Peng Xu,Wei Chen,Laurence T. Yang,Mauro Conti,Kaitai Liang*

Main category: cs.CR

TL;DR: This paper introduces Peekaboo, a universal DSSE attack framework effective under intermittent observation, outperforming prior attacks by 3Ã— in query accuracy and resisting modern countermeasures.


<details>
  <summary>Details</summary>
Motivation: Current passive DSSE attacks assume persistent leakage monitoring, but real-world threats often involve intermittent observations. This work addresses the more practical threat model of intermittent observation to expose vulnerabilities in existing DSSE systems.

Method: Peekaboo uses search pattern inference combined with auxiliary knowledge and other leakages, instantiated over SOTA attacks like Sap and Jigsaw to create enhanced variants (Sap+ and Jigsaw+).

Result: Peekaboo achieves >0.9 adjusted rand index for search pattern recovery, 90% query accuracy (vs. FMA's 30%), and maintains >40% effectiveness against file size padding and >80% against obfuscation-based countermeasures.

Conclusion: Peekaboo is an effective and scalable universal attack framework that outperforms existing methods in intermittent observation scenarios, even resisting state-of-the-art countermeasures.

Abstract: Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a
dynamic encrypted database but suffers from inherent information leakage.
Existing passive attacks against DSSE rely on persistent leakage monitoring to
infer leakage patterns, whereas this work targets intermittent observation - a
more practical threat model. We propose Peekaboo - a new universal attack
framework - and the core design relies on inferring the search pattern and
further combining it with auxiliary knowledge and other leakage. We instantiate
Peekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to
derive their "+" variants (Sap+ and Jigsaw+). Extensive experiments demonstrate
that our design achieves >0.9 adjusted rand index for search pattern recovery
and 90% query accuracy vs. FMA's 30% (CCS' 23). Peekaboo's accuracy scales with
observation rounds and the number of observed queries but also it resists SOTA
countermeasures, with >40% accuracy against file size padding and >80% against
obfuscation.

</details>


### [4] [BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection](https://arxiv.org/abs/2509.03807)
*Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang*

Main category: cs.CR

TL;DR: BIDO proposes a unified framework for Android malware detection that simultaneously defends against obfuscation and concept drift through enhanced feature selection, cross-modal pattern modeling, and metric learning.


<details>
  <summary>Details</summary>
Motivation: Existing image-based malware detection systems inadequately address obfuscation and concept drift, treating them as separate issues while ignoring their shared statistical root of out-of-distribution perturbations. This limits their robustness in real-world scenarios.

Method: The proposed BIDO employs three components: (1) a local feature selector for identifying informative subregions in malware images, (2) cross-modal outer product space modeling for extracting stable co-occurrence patterns, and (3) a learnable metric enhancing feature compactness via label-aware similarity optimization.

Result: BIDO demonstrates significant performance improvements over existing methods on real-world datasets across both obfuscation (e.g., 98.2% accuracy) and concept drift scenarios (e.g., 94.7% F1-score), with margin of 6-15% over baselines.

Conclusion: BIDO successfully addresses both obfuscation and concept drift in image-based malware detection by unifying their treatment as shared out-of-distribution challenges, achieving state-of-the-art robustness.

Abstract: To identify malicious Android applications, various malware detection
techniques have been proposed. Among them, image-based approaches are
considered potential alternatives due to their efficiency and scalability.
Recent studies have reported that these approaches suffer significant
performance declines when confronted with obfuscation or concept drift.
However, existing solutions often treat these two challenges as different
problems, offering independent solutions. These techniques overlook the fact
that both challenges share a common statistical root, out-of-distribution, and
research from this perspective remains limited. In response, we propose BIDO, a
hybrid image-based malware detector designed to enhance robustness against both
obfuscation and concept drift simultaneously. Specifically, to improve the
discriminative power of image features, we introduce a local feature selection
module that identifies informative subregions within malware images. Second, to
enhance feature robustness, we model pairwise cross-modal dependencies in an
outer product space, enabling the extraction of stable co-occurrence patterns.
Third, to ensure feature compactness, we design a learnable metric that pulls
samples with identical labels closer while pushing apart those with different
labels, regardless of obfuscation or concept drift. Extensive experiments on
the real-world datasets demonstrate that BIDO significantly outperforms
existing baselines, achieving higher robustness against both concept drift and
obfuscation. The source code is available at:
https://github.com/whatishope/BIDO/.

</details>


### [5] [Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System](https://arxiv.org/abs/2509.03821)
*Rui Zhao,Muhammad Shoaib,Viet Tung Hoang,Wajih Ul Hassan*

Main category: cs.CR

TL;DR: Nitro is a high-performance tamper-evident logging system using eBPF that eliminates kernel recompilation and achieves 10Ã—-25Ã— performance gains with fine-grained security, while Nitro-R reduces overhead further.


<details>
  <summary>Details</summary>
Motivation: Existing systems suffer from high overhead, data loss, and coarse-grained tamper detection. They also require kernel recompilation, hindering deployment. There is a need for a more efficient, high-performance solution with fine-grained security and minimal system modifications.

Method: Nitro employs eBPF to avoid kernel recompilation and introduces a new definitional framework with a practical cryptographic construction. It integrates cryptographic processing with pre/post-processing for system-level optimizations. Nitro-R enhances this with in-kernel log reduction techniques.

Result: Nitro achieves 10Ã—-25Ã— performance improvements in high-stress scenarios and 2Ã—-10Ã— in real-world settings with near-zero data loss. Nitro-R further reduces runtime overhead. Evaluations confirm its superior efficiency and effectiveness compared to prior systems.

Conclusion: Nitro effectively addresses high overhead, severe data loss, and coarse-grained detection in existing tamper-evident logging systems by leveraging eBPF technology. It achieves superior performance with near-zero data loss and introduces Nitro-R for further optimization. The proposed framework and cryptographic construction provide a formal foundation for secure logging.

Abstract: Existing tamper-evident logging systems suffer from high overhead and severe
data loss in high-load settings, yet only provide coarse-grained tamper
detection. Moreover, installing such systems requires recompiling kernel code.
To address these challenges, we present Nitro, a high-performance,
tamper-evident audit logging system that supports fine-grained detection of log
tampering. Even better, our system avoids kernel recompilation by using the
eBPF technology. To formally justify the security of Nitro, we provide a new
definitional framework for logging systems, and give a practical cryptographic
construction meeting this new goal. Unlike prior work that focus only on the
cryptographic processing, we codesign the cryptographic part with the pre- and
post-processing of the logs to exploit all system-level optimizations. Our
evaluations demonstrate Nitro's superior performance, achieving 10X-25X
improvements in high-stress conditions and 2X-10X in real-world scenarios while
maintaining near-zero data loss. We also provide an advanced variant, Nitro-R
that introduces in-kernel log reduction techniques to reduce runtime overhead
even further.

</details>


### [6] [KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection](https://arxiv.org/abs/2509.03860)
*Yifan Jia,Ye Tian,Liguo Zhang,Yanbin Wang,Jianguo Sun,Liangliang Song*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ethereum's rapid ecosystem expansion and transaction anonymity have triggered
a surge in malicious activity. Detection mechanisms currently bifurcate into
three technical strands: expert-defined features, graph embeddings, and
sequential transaction patterns, collectively spanning the complete feature
sets of Ethereum's native data layer. Yet the absence of cross-paradigm
integration mechanisms forces practitioners to choose between sacrificing
sequential context awareness, structured fund-flow patterns, or human-curated
feature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,
a feature-complete pre-training encoder that synergistically combines two key
components: (1) a Transaction Semantic Extractor, where we train an enhanced
Transaction Language Model (TLM) to learn contextual semantic representations
from conceptualized transaction records, and (2) a Transaction Knowledge Graph
(TKG) that incorporates expert-curated domain knowledge into graph node
embeddings to capture fund flow patterns and human-curated feature insights. We
jointly optimize pre-training objectives for both components to fuse these
complementary features, generating feature-complete embeddings. To emphasize
rare anomalous transactions, we design a biased masking prediction task for TLM
to focus on statistical outliers, while the Transaction TKG employs link
prediction to learn latent transaction relationships and aggregate knowledge.
Furthermore, we propose a mask-invariant attention coordination module to
ensure stable dynamic information exchange between TLM and TKG during
pre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines
in both phishing account detection and de-anonymization tasks, achieving
absolute F1-score improvements of 8-16% on three phishing detection benchmarks
and 6-26% on four de-anonymization datasets.

</details>


### [7] [ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System](https://arxiv.org/abs/2509.03879)
*Gang Liu,Ningjie Li,Cen Chen*

Main category: cs.CR

TL;DR: ShieldMMU is a new method to protect Intel SGX from side-channel attacks by using a Merkle Tree-based DD-Tree for PTE integrity, ensuring security without sacrificing performance.


<details>
  <summary>Details</summary>
Motivation: Intel SGX and hypervisors face security threats from side-channel attacks that exploit PTE manipulation and page faults. Current defenses lack practical solutions or focus only on detection.

Method: ShieldMMU employs a Defense Tree (DD-Tree) to detect, locate, and restore attacked Page Table Entries (PTEs), preventing page fault traps through real-time identification of MMU events and side-channel attacks.

Result: Experiments demonstrate ShieldMMU's effectiveness in enhancing security against controlled channel attacks while maintaining acceptable latency performance.

Conclusion: ShieldMMU provides a comprehensive, practical solution for mitigating side-channel attacks in Intel SGX, balancing security, compatibility, performance, and usability.

Abstract: Intel SGX and hypervisors isolate non-privileged programs from other
software, ensuring confidentiality and integrity. However, side-channel attacks
continue to threaten Intel SGX's security, enabling malicious OS to manipulate
PTE present bits, induce page faults, and steal memory access traces. Despite
extensive research, existing defenses focus on detection or rely on impractical
solutions. This paper presents ShieldMMU, a comprehensive solution for
mitigating controlled channel attacks, balancing compatibility, performance,
and usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),
ShieldMMU protects PTE integrity by detecting, locating, and restoring attacked
PTEs. It identifies MMU page table lookup events and side-channel attacks,
promptly restoring PTE parameters to prevent page fault traps and ensure secure
non-privileged application operation within SGX. Our experiments confirm
ShieldMMU's enhanced security and acceptable latency performance.

</details>


### [8] [LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding](https://arxiv.org/abs/2509.03939)
*Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current Ethereum fraud detection methods rely on context-independent,
numerical transaction sequences, failing to capture semantic of account
transactions. Furthermore, the pervasive homogeneity in Ethereum transaction
records renders it challenging to learn discriminative account embeddings.
Moreover, current self-supervised graph learning methods primarily learn node
representations through graph reconstruction, resulting in suboptimal
performance for node-level tasks like fraud account detection, while these
methods also encounter scalability challenges. To tackle these challenges, we
propose LMAE4Eth, a multi-view learning framework that fuses transaction
semantics, masked graph embedding, and expert knowledge. We first propose a
transaction-token contrastive language model (TxCLM) that transforms
context-independent numerical transaction records into logically cohesive
linguistic representations. To clearly characterize the semantic differences
between accounts, we also use a token-aware contrastive learning pre-training
objective together with the masked transaction model pre-training objective,
learns high-expressive account representations. We then propose a masked
account graph autoencoder (MAGAE) using generative self-supervised learning,
which achieves superior node-level account detection by focusing on
reconstructing account node features. To enable MAGAE to scale for large-scale
training, we propose to integrate layer-neighbor sampling into the graph, which
reduces the number of sampled vertices by several times without compromising
training quality. Finally, using a cross-attention fusion network, we unify the
embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our
method against 21 baseline approaches on three datasets. Experimental results
show that our method outperforms the best baseline by over 10% in F1-score on
two of the datasets.

</details>


### [9] [NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](https://arxiv.org/abs/2509.03985)
*Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu*

Main category: cs.CR

TL;DR: NeuroBreak system analyzes LLM security through neuron-level insights to combat jailbreak attacks, offering mechanistic defenses for future AI safety


<details>
  <summary>Details</summary>
Motivation: The growing sophistication of jailbreak attacks on LLMs creates urgent need for deeper understanding of internal safety mechanisms and vulnerabilities in these complex, high-parameter models.

Method: The study develops NeuroBreak, a top-down analysis system that combines layer-wise representation probing with semantic and functional critical neuron analysis. This is informed by collaborative requirement design with AI security experts.

Result: Quantitative evaluations and case studies demonstrate NeuroBreak's effectiveness in analyzing attack methods, revealing model decision-making processes, and identifying security-critical neurons for mitigation.

Conclusion: NeuroBreak provides a comprehensive understanding of LLM safety mechanisms and vulnerabilities, enabling effective mitigation strategies against jailbreak attacks and informing next-generation defense development.

Abstract: In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of parameters and complex
structure of LLMs make analyzing security weaknesses from an internal
perspective a challenging task. This paper presents NeuroBreak, a top-down
jailbreak analysis system designed to analyze neuron-level safety mechanisms
and mitigate vulnerabilities. We carefully design system requirements through
collaboration with three experts in the field of AI security. The system
provides a comprehensive analysis of various jailbreak attack methods. By
incorporating layer-wise representation probing analysis, NeuroBreak offers a
novel perspective on the model's decision-making process throughout its
generation steps. Furthermore, the system supports the analysis of critical
neurons from both semantic and functional perspectives, facilitating a deeper
exploration of security mechanisms. We conduct quantitative evaluations and
case studies to verify the effectiveness of our system, offering mechanistic
insights for developing next-generation defense strategies against evolving
jailbreak attacks.

</details>


### [10] [Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and Lessons Learned](https://arxiv.org/abs/2509.04010)
*Olivier Adjonyo,Sebastien Bardin,Emanuele Bellini,Gilbert Ndollane Dione,Mahmudul Faisal Al Ameen,Robert Merget,Frederic Recoules,Yanis Sellami*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The PQDSS standardization process requires cryptographic primitives to be
free from vulnerabilities, including timing and cache side-channels. Resistance
to timing leakage is therefore an essential property, and achieving this
typically relies on software implementations that follow constant-time
principles. Moreover, ensuring that all implementations are constant-time is
crucial for fair performance comparisons, as secure implementations often incur
additional overhead. Such analysis also helps identify scheme proposals that
are inherently difficult to implement in constant time. Because constant-time
properties can be broken during compilation, it is often necessary to analyze
the compiled binary directly. Since manual binary analysis is extremely
challenging, automated analysis becomes highly important. Although several
tools exist to assist with such analysis, they often have usability limitations
and are difficult to set up correctly. To support the developers besides the
NIST committee in verifying candidates, we developed a toolchain that automates
configuration, execution, and result analysis for several widely used
constant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify
constant-time policy compliance at the binary level, and dudect and RTLF to
detect side-channel vulnerabilities through statistical analysis of execution
time behavior. We demonstrate its effectiveness and practicability by
evaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26
issues in total to the respective developers, and 5 of them have already been
fixed. We also discuss our different findings, as well as the benefits of
shortcomings of the different tools.

</details>


### [11] [Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography](https://arxiv.org/abs/2509.04070)
*Paresh Baidya,Rourab Paul,Vikas Srivastava,Sumit Kumar Debnath*

Main category: cs.CR

TL;DR: This work proposes RESWO (a novel FPGA-friendly fault detection method) for securing Barrett Reduction in Kyber. Combating side-channel attacks, RESWO achieves near-perfect fault detection with 17-29% lower delay than existing methods, ensuring lightweight and efficient protection for PQC hardware.


<details>
  <summary>Details</summary>
Motivation: Intentional fault injection in PQC hardware (e.g., Kyber) can leak sensitive data through side-channel attacks, threatening the reliability of post-quantum cryptographic systems. Existing fault detection methods lack application in Barrett Reduction for lattice-based algorithms. Lightweight, efficient solutions are urgently needed to secure FPGA implementations of standardized PQC algorithms like Kyber.

Method: Three recomputation-based fault detection techniques are introduced: (1) **RECWOS** (Recomputation with Swapped Operand, a novel method), (2) **RENO** (Recomputation with Negated Operand), and (3) **RESO** (Recomputation with Shifted Operand). RESWO leverages operand swapping for delay optimization, while RENO/RESO utilize negation/shift operations. All methods are applied to Barrett Reduction within the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on FPGA.

Result: All three methods achieve ~100% fault detection efficiency. RESWO matches RENO/RESO in slice usage but reduces delay by 13-22% compared to RENO and 17-29% compared to RESO in FPGA implementations. This demonstrates RESWO's superior performance for real-time fault detection.

Conclusion: The paper concludes that the proposed RESWO method, along with RENO and RESO, offers efficient and lightweight fault detection for Barrett Reduction in Kyber's FPGA implementation. RESWO achieves comparable resource usage with reduced delay, significantly enhancing the security of PQC hardware against side-channel attacks.

Abstract: A fault can occur naturally or intentionally. However, intentionally
injecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC)
algorithms may leak sensitive information. This intentional fault injection in
side-channel attacks compromises the reliability of PQC implementations. The
recently NIST-standardized key encapsulation mechanism (KEM), Kyber may also
leak information at the hardware implementation level. This work proposes three
efficient and lightweight recomputation-based fault detection methods for
Barrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a
Field Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are
fundamental components in structured lattice-based PQC algorithms, including
Kyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new
algorithm, Recomputation with Swapped Operand (RESWO), for fault detection.
While Recomputation with Negated Operand (RENO) and Recomputation with Shifted
Operand (RESO) are existing methods used in other PQC hardware algorithms. To
the best of our knowledge, RENO and RESO have never been used in Barrett
Reduction before. The proposed RESWO method consumes a similar number of slices
compared to RENO and RESO. However, RESWO shows lesser delay compared to both
RENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is
nearly 100%.

</details>


### [12] [ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems](https://arxiv.org/abs/2509.04080)
*Francesco Aurelio Pironti,Angelo Furfaro,Francesco Blefari,Carmelo Felicetti,Matteo Lupinacci,Francesco Romeo*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The security of Industrial Control Systems (ICSs) is critical to ensuring the
safety of industrial processes and personnel. The rapid adoption of Industrial
Internet of Things (IIoT) technologies has expanded system functionality but
also increased the attack surface, exposing ICSs to a growing range of cyber
threats. Honeypots provide a means to detect and analyze such threats by
emulating target systems and capturing attacker behavior. However, traditional
ICS honeypots, often limited to software-based simulations of a single
Programmable Logic Controller (PLC), lack the realism required to engage
sophisticated adversaries. In this work, we introduce a modular honeynet
framework named ICSLure. The framework has been designed to emulate realistic
ICS environments. Our approach integrates physical PLCs interacting with live
data sources via industrial protocols such as Modbus and Profinet RTU, along
with virtualized network components including routers, switches, and Remote
Terminal Units (RTUs). The system incorporates comprehensive monitoring
capabilities to collect detailed logs of attacker interactions. We demonstrate
that our framework enables coherent and high-fidelity emulation of real-world
industrial plants. This high-interaction environment significantly enhances the
quality of threat data collected and supports advanced analysis of ICS-specific
attack strategies, contributing to more effective detection and mitigation
techniques.

</details>


### [13] [Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks](https://arxiv.org/abs/2509.04091)
*Jintao Gu,Haolang Lu,Guoshun Nan,Yihan Lin,Kun Wang,Yuchun Guo,Yigui Cao,Yang Liu*

Main category: cs.CR

TL;DR: First large-scale evaluation of Android TPL detection tools shows major flaws in accuracy and scalability, with practical implications for security analysis workflows.


<details>
  <summary>Details</summary>
Motivation: Accurate TPL detection is critical for Android security tasks (vulnerability tracking, malware detection, etc.), yet existing tools' real-world effectiveness remains unverified.

Method: Conducted a large-scale empirical evaluation of ten TPL detection techniques across 6,000+ apps using a newly created ground truth dataset with version-level annotations for dependencies.

Result: Identified key shortcomings: fragility to R8 obfuscation, poor version discrimination, incorrect library matching, non-generalizable similarity thresholds, and high runtime/memory overheads. Also revealed TPL impacts on downstream security tasks.

Conclusion: The study concludes that existing TPL detection tools have significant limitations in robustness, accuracy, and scalability, providing actionable insights for improving security analysis and future tool development.

Abstract: Accurate detection of third-party libraries (TPLs) is fundamental to Android
security, supporting vulnerability tracking, malware detection, and supply
chain auditing. Despite many proposed tools, their real-world effectiveness
remains unclear.We present the first large-scale empirical study of ten
state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a
new ground truth dataset with precise version-level annotations for both remote
and local dependencies.Our evaluation exposes tool fragility to R8-era
transformations, weak version discrimination, inaccurate correspondence of
candidate libraries, difficulty in generalizing similarity thresholds, and
prohibitive runtime/memory overheads at scale.Beyond tool assessment, we
further analyze how TPLs shape downstream tasks, including vulnerability
analysis, malware detection, secret leakage assessment, and LLM-based
evaluation. From this perspective, our study provides concrete insights into
how TPL characteristics affect these tasks and informs future improvements in
security analysis.

</details>


### [14] [ECCFROG522PP: An Enhanced 522-bit Weierstrass Elliptic Curve](https://arxiv.org/abs/2509.04097)
*VÃ­ctor Duarte Melo,William J. Buchanan*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Whilst many key exchange and digital signature systems still rely on NIST
P-256 (secp256r1) and secp256k1, offering around 128-bit security, there is an
increasing demand for transparent and reproducible curves at the 256-bit
security level. Standard higher-security options include NIST P-521, Curve448,
and Brainpool-P512. This paper presents ECCFROG522PP ("Presunto Powered"), a
522-bit prime-field elliptic curve that delivers security in the same classical
approx 260-bit ballpark as NIST P-521, but with a fundamentally different
design philosophy. All of the curve parameters are deterministically derived
from a fixed public seed via BLAKE3, with zero hidden choices. The curve has
prime order (cofactor = 1), a verified twist with a proven approx 505-bit prime
factor, safe embedding degree (greater than or equal to 14), and passes
anti-MOV checks up to k less than or equal to 200 and CM discriminant sanity up
to 100k. Unlike prior opaque or ad-hoc constructions, ECCFROG522PP is fully
reproducible: anyone can regenerate and verify it byte-for-byte using the
published scripts. The intent is not to outperform NIST P-521 in raw speed, but
to maximise trust, verifiability, and long-term auditability in a practical
curve of equivalent security level

</details>


### [15] [KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)
*Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents KubeGuard, a novel runtime
log-driven recommender framework aimed at mitigating risks by addressing overly
permissive configurations. KubeGuard is designed to harden K8s environments
through two complementary tasks: Resource Creation and Resource Refinement. It
leverages large language models (LLMs) to analyze manifests and runtime logs
reflecting actual system behavior, using modular prompt-chaining workflows.
This approach enables KubeGuard to create least-privilege configurations for
new resources and refine existing manifests to reduce the attack surface.
KubeGuard's output manifests are presented as recommendations that users (e.g.,
developers and operators) can review and adopt to enhance cluster security. Our
evaluation demonstrates that KubeGuard effectively generates and refines K8s
manifests for Roles, NetworkPolicies, and Deployments, leveraging both
proprietary and open-source LLMs. The high precision, recall, and F1-scores
affirm KubeGuard's practicality as a framework that translates runtime
observability into actionable, least-privilege configuration guidance.

</details>


### [16] [An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](https://arxiv.org/abs/2509.04214)
*Tyler Shumaker,Jessica Carpenter,David Saranchak,Nathaniel D. Bastian*

Main category: cs.CR

TL;DR: The paper presents an automated DT&E tool using VLMs to assess privacy risks from model inversion attacks in military ML systems, enhancing effectiveness and scalability.


<details>
  <summary>Details</summary>
Motivation: ML models in military applications face urgent deployment pressures but are vulnerable to adversarial attacks like model inversion. Current DT&E lacks tools to quantify privacy loss, leading to subjective and hard-to-scale evaluations.

Method: A novel pipeline combines model inversion with vision language models (VLMs) for zero-shot classification and image captioning. Four adversarial risk dimensions are introduced to automate privacy loss analysis across diverse architectures and data modalities.

Result: The tool was benchmarked against state-of-the-art MIAs in computer vision, demonstrating improved effectiveness in quantifying inversion quality compared to manual or existing methods.

Conclusion: The proposed pipeline addresses critical gaps in DT&E by automating scalable privacy risk quantification for model inversion attacks, ensuring robustness in military ML deployments.

Abstract: Machine learning (ML) models have the potential to transform military
battlefields, presenting a large external pressure to rapidly incorporate them
into operational settings. However, it is well-established that these ML models
are vulnerable to a number of adversarial attacks throughout the model
deployment pipeline that threaten to negate battlefield advantage. One broad
category is privacy attacks (such as model inversion) where an adversary can
reverse engineer information from the model, such as the sensitive data used in
its training. The ability to quantify the risk of model inversion attacks
(MIAs) is not well studied, and there is a lack of automated developmental test
and evaluation (DT&E) tools and metrics to quantify the effectiveness of
privacy loss of the MIA. The current DT&E process is difficult because ML model
inversions can be hard for a human to interpret, subjective when they are
interpretable, and difficult to quantify in terms of inversion quality.
Additionally, scaling the DT&E process is challenging due to many ML model
architectures and data modalities that need to be assessed. In this work, we
present a novel DT&E tool that quantifies the risk of data privacy loss from
MIAs and introduces four adversarial risk dimensions to quantify privacy loss.
Our DT&E pipeline combines inversion with vision language models (VLMs) to
improve effectiveness while enabling scalable analysis. We demonstrate
effectiveness using multiple MIA techniques and VLMs configured for zero-shot
classification and image captioning. We benchmark the pipeline using several
state-of-the-art MIAs in the computer vision domain with an image
classification task that is typical in military applications. In general, our
innovative pipeline extends the current model inversion DT&E capabilities by
improving the effectiveness and scalability of the privacy loss analysis in an
automated fashion.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [17] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [18] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: This paper proposes a hierarchical Random Forest-based framework to automate APB transaction error diagnosis in SoC verification, achieving 91.36\u0025 accuracy and first-place ranking in contest beta stages.


<details>
  <summary>Details</summary>
Motivation: Functional verification and debugging are critical bottlenecks in modern System-on-Chip (SoC designing manual detection of APB transaction errors in large VCD files is inefficient and error-prone.

Method: The multi-stage error diagnosis employs four pre-trained binary classifiers to sequentially detect Out-of-Range Access, Address Corruption, and Data Corruption errors, prioritizing high-certainty address-related faults before tackling complex data errors.

Result: The framework achieved 91.36\u0025 overall accuracy, near-perfect precision/recall for address errors, and first place in ICCAD 2025 CAD Contest beta stage despite final results not yet released.

Conclusion: This research validates the potential of hierarchical machine learning as a powerful automated tool for hardware debugging in Electronic Design Automation (EDA).

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [19] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: This paper introduces an algorithm for tracking code structures over time, enabling scalable analysis of student programming behavior and uncovering previously unobservable patterns.


<details>
  <summary>Details</summary>
Motivation: Manual tracking of code structures is labor-intensive and limits contextual behavioral analysis; automated methods are needed to study student programming processes effectively.

Method: Two algorithms were developed to track parse tree nodes through time, applied to keystroke data from a CS1 course, analyzing code states and unparseable data via automated tree representations.

Result: The analysis revealed new metrics, including similar code deletion rates in loops/conditionals, 30% restoration of commented code, and code navigation not necessarily indicating struggle.

Conclusion: Tracking parse trees through time enables new insights into student programming behavior, such as structural development patterns and syntactic challenges, opening avenues for further research and teaching improvements.

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [20] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: This paper proposes SECO-TransDX, a conceptual model linking transparency to developer experience in software ecosystems, using prior research and expert input to identify 63 key concepts as a foundation for improving ecosystem trust and engagement.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the gap in systematically conceptualizing how transparency influences developer perceptions and interactions in software ecosystems, despite its acknowledged importance for trust, fairness, and engagement in sustaining ecosystems.

Method: The authors propose the SECO-TransDX conceptual model, constructed through a review of prior research and refined via a Delphi study with academic and industry experts. The model synthesizes 63 interrelated concepts including conditioning factors, procedures, artifacts, and relational dynamics.

Result: The SECO-TransDX model introduces a developer-centered framework for analyzing DX-driven transparency, establishing how transparency is perceived and constructed during ecosystem interactions.

Conclusion: The paper concludes that the SECO-TransDX model provides a structured lens to analyze transparency's role in mediating developer experience (DX) across technical, social, and organizational layers, offering foundational insights for both researchers and practitioners to design trustworthy, developer-centered ecosystems.

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [21] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex uses reasoning-guided LLM analysis to detect software vulnerabilities in issue reports with 11-20% better performance than existing methods, reducing detection time and successfully identifying 30 emerging vulnerabilities in real-world GitHub projects.


<details>
  <summary>Details</summary>
Motivation: Current automated IR analysis methods focus only on textual descriptions and fail to utilize rich-text information. Manual identification is time-consuming, creating security risks during detection delays. This gap motivates the need for comprehensive analysis of IR content.

Method: VulRTex leverages a Large Language Model (LLM)'s reasoning capability to build a Vulnerability Reasoning Database. It retrieves historical cases for reasoning-guided analysis of target IRs' rich-text content, enabling accurate vulnerability identification.

Result: Experiments on 973,572 IRs show VulRTex outperforms best baselines by 11.0% F1/20.2% AUPRC with 2Ã— faster processing. Successfully identified 30 emerging vulnerabilities in 2024 GitHub IRs, with 11 receiving CVE-IDs.

Conclusion: VulRTex demonstrates significant improvements in identifying vulnerability-related IRs through reasoning-guided LLM analysis of rich-text data. It outperforms existing methods in performance metrics and efficiency while achieving real-world success in detecting emerging vulnerabilities.

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [22] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: Study reveals current vulnerability impact tools have max 45% accuracy due to fundamental limitations, with new approaches needed despite ensemble improvements.


<details>
  <summary>Details</summary>
Motivation: Address the gap in real-world evaluation of vulnerability impact tools, which have remained untested on large-scale, fine-grained datasets despite their importance for patch management and risk mitigation.

Method: Curated a high-quality benchmark of 1,128 C/C++ vulnerabilities and systematically evaluated 12 representative tools across four dimensions: version/vulnerability level effectiveness, error root causes, patch characteristic sensitivity, and ensemble potential.

Result: Found that heuristic dependence, limited semantic analysis, and rigid matching logic cap accuracy below 45%, with patch characteristics like add-only/cross-file changes further reducing performance. Ensemble methods improve results by 10.1% but still fall below 60% accuracy.

Conclusion: Current tools for identifying vulnerable software versions have significant limitations (max accuracy <45%), requiring transformative approaches rather than incremental improvements in this critical cybersecurity domain.

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [23] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [24] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: Auth Shim bridges OSS security integration gaps in enterprises by acting as a proxy compatibility layer, enabling secure SSO integration while retaining open-source advantages.


<details>
  <summary>Details</summary>
Motivation: Standalone OSS tools often lack native support for enterprise protocols like SAML/OIDC, leading to security integration gaps and manual user provisioning challenges in enterprise environments.

Method: The paper introduces the Auth Shim, a lightweight proxy service acting as a compatibility layer to translate enterprise IdP protocols (like SAML/OIDC) into the native session management of target applications. Key requirements include a programmatic administrative API in the target application.

Result: An implementation at Adobe demonstrated the Auth Shim's efficacy in securely integrating an OSS BI tool with Okta SAML, enabling automated RBAC via IAM group mapping and eliminating manual provisioning.

Conclusion: The paper concludes that the Auth Shim provides a reusable and secure blueprint for integrating standalone OSS tools into enterprise SSO ecosystems, allowing organizations to adopt open-source innovation while maintaining security governance.

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [25] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: This paper addresses gaps in code debugging datasets by introducing RepoDebugâ€”a diverse, repository-level datasetâ€”to evaluate LLMs, revealing that even leading models like Claude 3.5 Sonnet struggle with this task, emphasizing research needs for improved debugging capabilities.


<details>
  <summary>Details</summary>
Motivation: Current debugging datasets focus narrowly on function-level code repair, neglecting complex repository-level scenarios, leading to an incomplete understanding of LLM limitations in realistic debugging contexts.

Method: The authors created RepoDebug, a multi-task, multi-language dataset with 22 error subtypes, 8 programming languages, and 3 debugging tasks, and evaluated 10 LLMs to benchmark repository-level debugging performance.

Result: Claude 3.5 Sonnet, the top-performing LLM in experiments, demonstrated inadequate performance in repository-level debugging, underscoring existing model limitations and dataset diversity needs.

Conclusion: The paper highlights the need for improved LLM capabilities in repository-level debugging and encourages future research to address the limitations of current models through enhanced training or dataset development.

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [26] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: PyVul, a high-accuracy Python vulnerability benchmark, exposes flaws in existing detection tools and emphasizes the need for improved methods to secure multi-language Python packages.


<details>
  <summary>Details</summary>
Motivation: Python's popularity and multi-language interoperability create complex security challenges. Existing vulnerability detection tools lack effectiveness in addressing the diversity and scale of Python package vulnerabilities, necessitating a robust benchmark like PyVul to advance research and improve real-world security.

Method: The authors developed PyVul, comprising 1,157 verified vulnerabilities annotated at commit and function levels, using LLM-assisted data cleansing for high accuracy. They performed distribution analysis to characterize vulnerability patterns, evaluated state-of-the-art detectors, and conducted a detailed CWE review to diagnose tool limitations.

Result: PyVul achieved 100% commit-level and 94% function-level accuracy, demonstrating Python vulnerabilities span multiple languages and types. Multi-lingual packages showed higher vulnerability susceptibility. Tool evaluations revealed performance gaps, while CWE analysis highlighted fine-grained limitations requiring future innovations.

Conclusion: This paper introduces PyVul, a novel benchmark suite for Python-package vulnerabilities, revealing significant gaps in current detection tools' capabilities. It emphasizes the need for advanced vulnerability identification methods, especially for multi-lingual Python packages, and highlights actionable insights for improving real-world security practices in Python ecosystems.

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [27] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard is a unified DevSecOps pipeline for OpenFaaS that systematically prevents security threats across all development stages with minimal disruption to CI/CD practices.


<details>
  <summary>Details</summary>
Motivation: Existing security approaches for serverless computing lack integration, addressing isolated phases of the DevSecOps lifecycle and failing to comprehensively secure ephemeral, fine-grained functions.

Method: FaaSGuard integrates lightweight, fail-closed security checks across all stages of the DevSecOps lifecycle (planning, coding, building, deployment, monitoring) in open-source serverless platforms.

Result: Empirical validation on 20 real-world OpenFaaS functions showed 95% precision and 91% recall in detecting injection attacks, hard-coded secrets, and resource exhaustion vulnerabilities.

Conclusion: FaaSGuard effectively detects and prevents critical vulnerabilities in serverless environments, demonstrating high precision and recall while maintaining compatibility with existing CI/CD processes.

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [28] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: This paper introduces a web-based blood donation platform that connects donors and patients in emergencies. Built with Laravel and MySQL, it streamlines registration, location-based searches, and communication, reducing delays and improving blood accessibility.


<details>
  <summary>Details</summary>
Motivation: Emergencies often face delays in locating blood donors due to fragmented systems. This platform addresses the urgent need for a centralized digital solution to connect patients, donors, and administrators quickly and efficiently.

Method: The system was developed using PHP (Laravel), HTML, CSS, Bootstrap, and MySQL, with design frameworks based on use case, database, class, and sequence diagrams. XAMPP and Visual Studio Code facilitated implementation, ensuring a dynamic and user-friendly interface.

Result: The platform enables rapid donor registration, location-based blood group searches for patients, and efficient communication, significantly reducing delays and logistical complexities in blood donation processes.

Conclusion: The proposed Blood Donation Web Platform effectively addresses the challenges in emergency blood access by streamlining registration, communication, and blood requests, thereby enhancing efficiency and saving critical time during emergencies.

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>
