{"id": "2509.14265", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14265", "abs": "https://arxiv.org/abs/2509.14265", "authors": ["Siyuan Chen", "Zhichao Lu", "Qingfu Zhang"], "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models", "comment": "Technical report", "summary": "Automated kernel design is critical for overcoming software ecosystem\nbarriers in emerging hardware platforms like RISC-V. While large language\nmodels (LLMs) have shown promise for automated kernel optimization,\ndemonstrating success in CUDA domains with comprehensive technical documents\nand mature codebases, their effectiveness remains unproven for reference-scarce\ndomains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based\nevolutionary program search framework that automates kernel design for domains\nwith limited reference material. EoK mitigates reference scarcity by mining and\nformalizing reusable optimization ideas (general design principles + actionable\nthoughts) from established kernel libraries' development histories; it then\nguides parallel LLM explorations using these ideas, enriched via\nRetrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing\nhistorically effective techniques. Empirically, EoK achieves a median 1.27x\nspeedup, surpassing human experts on all 80 evaluated kernel design tasks and\nimproving upon prior LLM-based automated kernel design methods by 20%. These\nresults underscore the viability of incorporating human experience into\nemerging domains and highlight the immense potential of LLM-based automated\nkernel optimization.", "AI": {"tldr": "EoK: LLM-powered evolutionary framework enabling RISC-V kernel optimization via RAG and reused design principles, beating humans and existing methods.", "motivation": "Emerging hardware domains (e.g., RISC-V) face software ecosystem barriers due to limited reference material, where traditional LLM-based optimization methods (successful in CUDA) underperform.", "method": "EoK combines evolutionary program search with LLMs, leveraging Retrieval-Augmented Generation (RAG) and mined optimization principles from historical kernel libraries to guide exploration.", "result": "EoK achieves a median 1.27x speedup on 80 kernel tasks, surpassing human experts and improving 20% over prior LLM-based approaches.", "conclusion": "EoK demonstrates the viability of LLM-based automated kernel optimization in reference-scarce domains like RISC-V, outperforming human experts and prior methods."}}
{"id": "2509.14273", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14273", "abs": "https://arxiv.org/abs/2509.14273", "authors": ["Swapnil Sharma Sarker", "Tanzina Taher Ifty"], "title": "Automated and Context-Aware Code Documentation Leveraging Advanced LLMs", "comment": null, "summary": "Code documentation is essential to improve software maintainability and\ncomprehension. The tedious nature of manual code documentation has led to much\nresearch on automated documentation generation. Existing automated approaches\nprimarily focused on code summarization, leaving a gap in template-based\ndocumentation generation (e.g., Javadoc), particularly with publicly available\nLarge Language Models (LLMs). Furthermore, progress in this area has been\nhindered by the lack of a Javadoc-specific dataset that incorporates modern\nlanguage features, provides broad framework/library coverage, and includes\nnecessary contextual information. This study aims to address these gaps by\ndeveloping a tailored dataset and assessing the capabilities of publicly\navailable LLMs for context-aware, template-based Javadoc generation. In this\nwork, we present a novel, context-aware dataset for Javadoc generation that\nincludes critical structural and semantic information from modern Java\ncodebases. We evaluate five open-source LLMs (including LLaMA-3.1, Gemma-2,\nPhi-3, Mistral, Qwen-2.5) using zero-shot, few-shot, and fine-tuned setups and\nprovide a comparative analysis of their performance. Our results demonstrate\nthat LLaMA 3.1 performs consistently well and is a reliable candidate for\npractical, automated Javadoc generation, offering a viable alternative to\nproprietary systems.", "AI": {"tldr": "This paper introduces a novel dataset for Javadoc generation, evaluates open-source LLMs for template-based documentation, and identifies LLaMA 3.1 as the most reliable model for this task.", "motivation": "Existing automated documentation systems focus on code summarization, neglecting template-based Javadoc generation. Current LLMs lack specialized training data incorporating modern Java features and contextual information for this use case.", "method": "1) Created a context-aware Javadoc dataset with modern Java code structural/semantic info\n2] Evaluated 5 open-source LLMs (LLaMA-3.1, Gemma-2, etc.) using zero-shot/few-shot/fine-tuning\n3) Compared performance metrics across these setups", "result": "LLaMA 3.1 demonstrated consistent superior performance across all evaluation setups. The new dataset provides a benchmark with framework coverage, modern Java features, and rich context information", "conclusion": "The dataset advances template-based documentation research. LLaMA 3.1 stands as a viable open-source alternative to proprietary systems for automated Javadoc generation, especially when fine-tuned on the proposed dataset."}}
