<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance](https://arxiv.org/abs/2510.25882)
*Wenhao Yang,Minghui Zhou,Daniel Izquierdo Cortázar,Yehui Wang*

Main category: cs.SE

TL;DR: The study presents a holistic risk governance framework for enterprises using open source, addressing both technical and non-technical threats.


<details>
  <summary>Details</summary>
Motivation: Traditional risk management is inadequate for the complex, systemic threats faced by enterprises integrating open source strategically.

Method: The authors conducted a grounded theory study with 15 practitioners to develop a risk governance framework based on the principle of External Threats exploiting Internal Vulnerabilities.

Result: The framework includes a Strategic Objectives Matrix, a dual taxonomy of threats and vulnerabilities, and a mitigation strategy, validated by industry experts through case studies.

Conclusion: The framework enables enterprises to shift from reactive firefighting to proactive risk governance, enhancing their organizational resilience.

Abstract: Enterprise engagement with open source has evolved from tactical adoption to
strategic deep integration, exposing them to a complex risk landscape far
beyond mere code. However, traditional risk management, narrowly focused on
technical tools, is structurally inadequate for systemic threats like upstream
"silent fixes", community conflicts, or sudden license changes, creating a
dangerous governance blind spot. To address this governance vacuum and enable
the necessary shift from tactical risk management to holistic risk governance,
we conducted a grounded theory study with 15 practitioners to develop a
holistic risk governance framework. Our study formalizes an analytical
framework built on a foundational risk principle: an uncontrollable External
Threat (e.g., a sudden license change in a key dependency) only becomes a
critical risk when it exploits a controllable Internal Vulnerability (e.g., an
undefined risk appetite for single-vendor projects), which then amplifies the
impact.The framework operationalizes this principle through a clear logical
chain: "Objectives -> Threats -> Vulnerabilities -> Mitigation" (OTVM). This
provides a holistic decision model that transcends mere technical checklists.
Based on this logic, our contributions are: (1) a "Strategic Objectives Matrix"
to clarify goals; (2) a systematic dual taxonomy of External Threats (Ex-Tech,
Ex-Comm, Ex-Eco) and Internal Vulnerabilities (In-Strat, In-Ops, In-Tech); and
(3) an actionable mitigation framework mapping capability-building to these
vulnerabilities. The framework's analytical utility was validated by three
industry experts through retrospective case studies on real-world incidents.
This work provides a novel diagnostic lens and a systematic path for
enterprises to shift from reactive "firefighting" to proactively building an
organizational "immune system".

</details>


### [2] [PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints](https://arxiv.org/abs/2510.25890)
*Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang*

Main category: cs.SE

TL;DR: PRISM unifies LLMs and MDE to automate compliant artifact generation, ensuring validity and reducing manual work through semantic-enforced models.


<details>
  <summary>Details</summary>
Motivation: The need for regulator-ready artifacts and machine-checkable evidence in safety- and compliance-critical domains drives the development of PRISM.

Method: PRISM combines a Unified Meta-Model (UMM), an Integrated Constraint Model (ICM), and Constraint-Guided Verifiable Generation (CVG) with two-layer enforcement and audit-guided repair.

Result: PRISM generates structurally valid, auditable artifacts in domains like AUTOSAR and Brussels I bis, integrating with existing tooling and minimizing manual effort.

Conclusion: PRISM offers a practical path toward automated artifact generation with built-in assurance by integrating LLMs with MDE, reducing manual remediation effort.

Abstract: PRISM unifies Large Language Models with Model-Driven Engineering to generate
regulator-ready artifacts and machine-checkable evidence for safety- and
compliance-critical domains. PRISM integrates three pillars: a Unified
Meta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a
single semantic space; an Integrated Constraint Model (ICM) compiles structural
and semantic requirements into enforcement artifacts including generation-time
automata (GBNF, DFA) and post-generation validators (e.g., SHACL, SMT); and
Constraint-Guided Verifiable Generation (CVG) applies these through two-layer
enforcement - structural constraints drive prefix-safe decoding while
semantic/logical validation produces machine-checkable certificates. When
violations occur, PRISM performs audit-guided repair and records generation
traces for compliance review. We evaluate PRISM in automotive software
engineering (AUTOSAR) and cross-border legal jurisdiction (Brussels I bis).
PRISM produces structurally valid, auditable artifacts that integrate with
existing tooling and substantially reduce manual remediation effort, providing
a practical path toward automated artifact generation with built-in assurance.

</details>


### [3] [A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows](https://arxiv.org/abs/2510.25935)
*Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace*

Main category: cs.SE

TL;DR: CodeSight is a system that uses process mining and LSTM models to predict if software projects will meet deadlines by analyzing GitHub data.


<details>
  <summary>Details</summary>
Motivation: The system aims to help software teams proactively manage deadlines by identifying potential breaches early in the development process.

Method: CodeSight extracts data from GitHub, converts it into process mining logs, derives metrics and dashboards, and uses an LSTM model to predict PR resolution times based on sequential activities and static features.

Result: The system achieved high precision and F1 scores in deadline compliance prediction, effectively combining process mining and machine learning for project monitoring.

Conclusion: Integrating process mining with machine learning through CodeSight enables proactive deadline management and valuable insights into workflow efficiency in software development.

Abstract: CodeSight is an end-to-end system designed to anticipate deadline compliance
in software development workflows. It captures development and deployment data
directly from GitHub, transforming it into process mining logs for detailed
analysis. From these logs, the system generates metrics and dashboards that
provide actionable insights into PR activity patterns and workflow efficiency.
Building on this structured representation, CodeSight employs an LSTM model
that predicts remaining PR resolution times based on sequential activity traces
and static features, enabling early identification of potential deadline
breaches. In tests, the system demonstrates high precision and F1 scores in
predicting deadline compliance, illustrating the value of integrating process
mining with machine learning for proactive software project management.

</details>


### [4] [Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation](https://arxiv.org/abs/2510.26130)
*Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: LLMs struggle with class-level code generation in real-world settings despite strong synthetic results. A new benchmark reveals significant performance gaps and error patterns, suggesting improvements in retrieval and documentation strategies.


<details>
  <summary>Details</summary>
Motivation: Despite progress in function-level code generation, LLMs' ability to produce correct class-level implementations in authentic software projects remains underexplored.

Method: The researchers developed a new benchmark using real-world classes from open-source repositories, divided into seen/unseen partitions, and evaluated LLMs under varying input conditions, retrieval-augmented setups, and documentation completeness.

Result: LLMs achieved 84-89% correctness on synthetic benchmarks but only 25-34% on real-world tasks. Retrieval augmentation improved correctness by 4-7% for partial documentation. errors were dominated by AttributeError, TypeError, and AssertionError (84% of cases).

Conclusion: The study highlights critical limitations in current LLMs for class-level code generation in real-world scenarios, advocating for improvements in context modeling, documentation strategies, and retrieval integration.

Abstract: Large language models (LLMs) have advanced code generation at the function
level, yet their ability to produce correct class-level implementations in
authentic software projects remains poorly understood. This work introduces a
novel benchmark derived from open-source repositories, comprising real-world
classes divided into seen and unseen partitions to evaluate generalization
under practical conditions. The evaluation examines multiple LLMs under varied
input specifications, retrieval-augmented configurations, and documentation
completeness levels.
  Results reveal a stark performance disparity: LLMs achieve 84% to 89%
correctness on established synthetic benchmarks but only 25% to 34% on
real-world class tasks, with negligible differences between familiar and novel
codebases. Comprehensive docstrings yield modest gains of 1% to 3% in
functional accuracy, though statistical significance is rare.
Retrieval-augmented generation proves most effective with partial
documentation, improving correctness by 4% to 7% by supplying concrete
implementation patterns absent from specifications. Error profiling identifies
AttributeError, TypeError, and AssertionError as dominant failure modes (84% of
cases), with synthetic tests overemphasizing assertion issues and real-world
scenarios highlighting type and attribute mismatches. Retrieval augmentation
reduces logical flaws but can introduce dependency conflicts.
  The benchmark and analysis expose critical limitations in current LLM
capabilities for class-level engineering, offering actionable insights for
enhancing context modelling, documentation strategies, and retrieval
integration in production code assistance tools.

</details>
