{"id": "2508.14070", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14070", "abs": "https://arxiv.org/abs/2508.14070", "authors": ["Ephraiem Sarabamoun"], "title": "Special-Character Adversarial Attacks on Open-Source Language Model", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable performance across\ndiverse natural language processing tasks, yet their vulnerability to\ncharacter-level adversarial manipulations presents significant security\nchallenges for real-world deployments.", "AI": {"tldr": "This paper investigates vulnerabilities in large language models under character-level adversarial attacks and proposes solutions to enhance their security for practical use.", "motivation": "LLMs achieve high performance in NLP tasks but face security risks from character-level adversarial manipulations.", "method": "The paper likely proposes methods to mitigate character-level adversarial attacks, though specific techniques are not detailed in the abstract.", "result": "Demonstrates the effectiveness of proposed methods against adversarial attacks, improving model robustness.", "conclusion": "Addressing character-level adversarial vulnerabilities is crucial for the secure deployment of LLMs in real-world applications."}}
{"id": "2508.14128", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14128", "abs": "https://arxiv.org/abs/2508.14128", "authors": ["Jiaming Hu", "Haoyu Wang", "Debarghya Mukherjee", "Ioannis Ch. Paschalidis"], "title": "CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection", "comment": "11 pages, 1 figure", "summary": "Jailbreak attacks pose a serious challenge to the safe deployment of large\nlanguage models (LLMs). We introduce CCFC (Core & Core-Full-Core), a\ndual-track, prompt-level defense framework designed to mitigate LLMs'\nvulnerabilities from prompt injection and structure-aware jailbreak attacks.\nCCFC operates by first isolating the semantic core of a user query via few-shot\nprompting, and then evaluating the query using two complementary tracks: a\ncore-only track to ignore adversarial distractions (e.g., toxic suffixes or\nprefix injections), and a core-full-core (CFC) track to disrupt the structural\npatterns exploited by gradient-based or edit-based attacks. The final response\nis selected based on a safety consistency check across both tracks, ensuring\nrobustness without compromising on response quality. We demonstrate that CCFC\ncuts attack success rates by 50-75% versus state-of-the-art defenses against\nstrong adversaries (e.g., DeepInception, GCG), without sacrificing fidelity on\nbenign queries. Our method consistently outperforms state-of-the-art\nprompt-level defenses, offering a practical and effective solution for safer\nLLM deployment.", "AI": {"tldr": "CCFC is a dual-track defense framework that mitigates LLM jailbreak attacks by 50-75% through isolated semantic core analysis and structural attack disruption, outperforming existing methods while preserving response quality.", "motivation": "Jailbreak attacks pose serious risks to LLM deployment, motivating the need for defenses against prompt injection and structure-aware attacks like DeepInception and GCG.", "method": "CCFC employs a dual-track approach: a core-only track to eliminate adversarial distractions and a core-full-core (CFC) track to disrupt attack structures. It combines safety consistency checks across tracks for robust responses.", "result": "CCFC reduces attack success rates by 50-75% compared to state-of-the-art defenses, demonstrating superior robustness without compromising benign query fidelity.", "conclusion": "The paper concludes that CCFC offers a practical and effective solution for safer LLM deployment by significantly mitigating jailbreak attacks while maintaining response quality."}}
{"id": "2508.14190", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14190", "abs": "https://arxiv.org/abs/2508.14190", "authors": ["Zixin Rao", "Youssef Mohamed", "Shang Liu", "Zeyan Liu"], "title": "Two Birds with One Stone: Multi-Task Detection and Attribution of LLM-Generated Text", "comment": "Securecomm 2025", "summary": "Large Language Models (LLMs), such as GPT-4 and Llama, have demonstrated\nremarkable abilities in generating natural language. However, they also pose\nsecurity and integrity challenges. Existing countermeasures primarily focus on\ndistinguishing AI-generated content from human-written text, with most\nsolutions tailored for English. Meanwhile, authorship attribution--determining\nwhich specific LLM produced a given text--has received comparatively little\nattention despite its importance in forensic analysis. In this paper, we\npresent DA-MTL, a multi-task learning framework that simultaneously addresses\nboth text detection and authorship attribution. We evaluate DA-MTL on nine\ndatasets and four backbone models, demonstrating its strong performance across\nmultiple languages and LLM sources. Our framework captures each task's unique\ncharacteristics and shares insights between them, which boosts performance in\nboth tasks. Additionally, we conduct a thorough analysis of cross-modal and\ncross-lingual patterns and assess the framework's robustness against\nadversarial obfuscation techniques. Our findings offer valuable insights into\nLLM behavior and the generalization of both detection and authorship\nattribution.", "AI": {"tldr": "This paper proposes DA-MTL, a multi-task framework for detecting AI-generated text while identifying the specific LLM source. Evaluated across languages and models, it demonstrates how task-sharing improves both detection accuracy and attribution robustness, with new insights into LLM forensic analysis.", "motivation": "Excessive focus on English-centric AI-text classification has left authorship attribution under-explored despite its critical role in forensic analysis. The multi-task approach addresses this gap by simultaneously solving both detection and attribution challenges across diverse linguistic contexts.", "method": "The paper introduces DA-MTL, a multi-task learning framework designed to jointly address text detection and authorship attribution by leveraging task-specific characteristics and sharing insights between them. Evaluations span nine datasets, four backbone models, and multiple languages.", "result": "DA-MTL shows strong performance across multiple languages and LLM sources. The framework's analysis reveals cross-modal/cross-lingual patterns and robustness against adversarial obfuscation techniques, offering insights into LLM generalization capabilities.", "conclusion": "DA-MTL demonstrates that multi-task learning improves both text detection and authorship attribution, while providing insights into LLM behavior cross-linguistically and cross-modally."}}
{"id": "2508.14230", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.14230", "abs": "https://arxiv.org/abs/2508.14230", "authors": ["Eduardo Brito", "Fernando Castillo", "Liina Kamm", "Amnir Hadachi", "Ulrich Norbisrath"], "title": "A Taxonomy and Methodology for Proof-of-Location Systems", "comment": "This work has been accepted to the 29th International Conference on\n  Enterprise Design, Operations, and Computing (EDOC 2025)", "summary": "Digital societies increasingly rely on trustworthy proofs of physical\npresence for services such as supply-chain tracking, e-voting, ride-sharing,\nand location-based rewards. Yet, traditional localization methods often lack\ncryptographic guarantees of where and when an entity was present, leaving them\nvulnerable to spoofing, replay, or collusion attacks. In response, research on\nProof-of-Location (PoL) has emerged, with recent approaches combining distance\nbounding, distributed consensus, and privacy-enhancing techniques to enable\nverifiable, tamper-resistant location claims.\n  As the design space for PoL systems grows in complexity, this paper provides\na unified framework to help practitioners navigate diverse application needs.\nWe first propose a taxonomy identifying four core domains: (1) cryptographic\nguarantees, (2) spatio-temporal synchronization, (3) trust and witness models,\nand (4) interaction and overhead. Building on this, we introduce a methodology\nto map application-specific requirements onto appropriate PoL architectures. We\nillustrate this process through three use cases (retail e-coupons, supply chain\nauditing, and physical e-voting), each showing how different constraints shape\nprotocol choices. Overall, this work offers a structured approach to building\nsecure, scalable, and interoperable PoL systems.", "AI": {"tldr": "This paper introduces a unified framework for designing secure Proof-of-Location systems by categorizing key design domains and mapping application needs to architectures, validated via real-world use cases.", "motivation": "Traditional localization methods lack cryptographic guarantees, making them vulnerable to spoofing, replay, and collusion attacks. The paper addresses this gap to enable trustworthy, tamper-resistant location proofs essential for digital services.", "method": "The method involves proposing a taxonomy of four core domains (cryptographic guarantees, spatio-temporal synchronization, trust/witness models, and interaction/overhead) and a methodology for mapping application-specific requirements to appropriate PoL architectures, illustrated through three use cases.", "result": "The framework is demonstrated through three use cases (retail e-coupons, supply chain auditing, and physical e-voting), showing how application-specific constraints influence protocol design, enabling secure and interoperable PoL implementations.", "conclusion": "The paper concludes that the proposed framework provides a structured approach for designing secure, scalable, and interoperable Proof-of-Location (PoL) systems, addressing critical vulnerabilities in traditional localization methods."}}
{"id": "2508.14104", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14104", "abs": "https://arxiv.org/abs/2508.14104", "authors": ["Yutong Bian", "Xianhao Lin", "Yupeng Xie", "Tianyang Liu", "Mingchen Zhuge", "Siyuan Lu", "Haoming Tang", "Jinlin Wang", "Jiayi Zhang", "Jiaqi Chen", "Xiangru Tang", "Yongxin Ni", "Sirui Hong", "Chenglin Wu"], "title": "You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation", "comment": null, "summary": "Large Language Models (LLMs) and code agents in software development are\nrapidly evolving from generating isolated code snippets to producing\nfull-fledged software applications with graphical interfaces, interactive\nlogic, and dynamic behaviors. However, current benchmarks fall short in\nevaluating such production-ready software, as they often rely on static checks\nor binary pass/fail scripts, failing to capture the interactive behaviors and\nruntime dynamics that define real-world usability - qualities that only emerge\nwhen an application is actively used. This is the blind spot of current\nevaluation: you don't know if an app works until you click through it, interact\nwith it, and observe how it responds. To bridge this gap, we introduce\nRealDevWorld, a novel evaluation framework for automated end-to-end assessment\nof LLMs' ability to generate production-ready repositories from scratch. It\nfeatures two key components: (1) RealDevBench, a diverse collection of 194\nopen-ended software engineering tasks across multiple domains, incorporating\nmultimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a\nnew agent-as-a-judge evaluation system that simulates realistic, GUI-based user\ninteractions to automatically and holistically assess software functional\ncorrectness, visual fidelity, and runtime behavior. The framework delivers\nfine-grained, task-specific diagnostic feedback, supporting nuanced evaluation\nbeyond simple success/failure judgments. Empirical results show that\nRealDevWorld delivers effective, automatic, and human-aligned evaluations,\nachieving an accuracy of 0.92 and a correlation of 0.85 with expert human\nassessments, while significantly reducing the reliance on manual review. This\nenables scalable, human-aligned assessment of production-level software\ngenerated by LLMs. Our code is available on GitHub.", "AI": {"tldr": "RealDevWorld is a production-ready software evaluation framework for LLMs that automates interactive testing of generated applications through a taskbench and GUI-based agent-as-a-judge system, delivering human-aligned assessments with 92% accuracy.", "motivation": "Current benchmarks inadequately evaluate production-ready LLM-generated software due to reliance on static checks and binary pass/fail metrics, which fail to capture runtime dynamics and interactive behaviors essential for real-world usability.", "method": "The framework introduces (1) RealDevBench: 194 open-ended software engineering tasks across domains with multimodal complexity; and (2) AppEvalPilot: a GUI-based agent-as-a-judge system simulating realistic user interactions to assess functional correctness, visual fidelity, and runtime behavior through task-specific diagnostic feedback.", "result": "RealDevWorld achieves 0.92 accuracy and 0.85 correlation with human expert evaluations while reducing manual review by automating assessments of 194 tasks across domains through interactive testing mechanisms, demonstrating effective human-aligned evaluation of LLM-generated software.", "conclusion": "RealDevWorld fills the critical evaluation gap for LLM-generated production-ready software by introducing automated interactive testing frameworks, enabling scalable, human-aligned assessments of real-world software functionality and usability."}}
{"id": "2508.14261", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.14261", "abs": "https://arxiv.org/abs/2508.14261", "authors": ["Meet Udeshi", "Venkata Sai Charan Putrevu", "Prashanth Krishnamurthy", "Ramesh Karri", "Farshad Khorrami"], "title": "SaMOSA: Sandbox for Malware Orchestration and Side-Channel Analysis", "comment": null, "summary": "Cyber-attacks on operational technology (OT) and cyber-physical systems (CPS)\nhave increased tremendously in recent years with the proliferation of malware\ntargeting Linux-based embedded devices of OT and CPS systems. Comprehensive\nmalware detection requires dynamic analysis of execution behavior in addition\nto static analysis of binaries. Safe execution of malware in a manner that\ncaptures relevant behaviors via side-channels requires a sandbox environment.\nExisting Linux sandboxes are built for specific tasks, only capture one or two\nside-channels, and do not offer customization for different analysis tasks. We\npresent the SaMOSA Linux sandbox that allows emulation of Linux malwares while\ncapturing time-synchronized side-channels from four sources. SaMOSA\nadditionally provides emulation of network services via FakeNet, and allows\norchestration and customization of the sandbox environment via pipeline hooks.\nIn comparison to existing Linux sandboxes, SaMOSA captures more side-channels\nnamely system calls, network activity, disk activity, and hardware performance\ncounters. It supports three architectures predominantly used in OT and CPS\nnamely x86-64, ARM64, and PowerPC 64. SaMOSA fills a gap in Linux malware\nanalysis by providing a modular and customizable sandbox framework that can be\nadapted for many malware analysis tasks. We present three case studies of three\ndifferent malware families to demonstrate the advantages of SaMOSA.", "AI": {"tldr": "SaMOSA is a customizable Linux sandbox for OT/CPS malware analysis, capturing four synchronized side-channels and supporting major architectures. It outperforms existing tools by enabling adaptable, comprehensive malware analysis via modular design and pipeline hooks.", "motivation": "The proliferation of malware targeting Linux-based embedded devices in OT and CPS systems necessitates dynamic analysis of execution behaviors beyond static binary analysis. Existing Linux sandboxes are task-specific, limited to one or two side-channels, and lack customization capabilities for diverse analysis tasks.", "method": "The authors developed SaMOSA, a Linux sandbox capable of emulating malware while capturing time-synchronized side-channels (system calls, network activity, disk activity, hardware performance counters). It integrates FakeNet for network service emulation and supports x86-64, ARM64, and PowerPC 64 architectures. The framework allows customization via pipeline hooks.", "result": "SaMOSA captures four types of side-channels compared to existing tools' one or two. It supports three key architectures for OT/CPS and demonstrates practical utility through three case studies involving different malware families, validating its effectiveness in malware analysis.", "conclusion": "SaMOSA addresses the gap in Linux malware analysis by providing a modular and customizable sandbox framework tailored for operational technology (OT) and cyber-physical systems (CPS). Its adaptability to diverse malware analysis tasks is demonstrated through case studies involving three malware families."}}
{"id": "2508.14114", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14114", "abs": "https://arxiv.org/abs/2508.14114", "authors": ["Aditey Nandan", "Viraj Kumar"], "title": "Ambiguity Resolution with Human Feedback for Code Writing Tasks", "comment": "Accepted at the Proceedings of the 33rd International Conference on\n  Computers in Education (ICCE 2025), Asia-Pacific Society for Computers in\n  Education (APSCE)", "summary": "Specifications for code writing tasks are usually expressed in natural\nlanguage and may be ambiguous. Programmers must therefore develop the ability\nto recognize ambiguities in task specifications and resolve them by asking\nclarifying questions. We present and evaluate a prototype system, based on a\nnovel technique (ARHF: Ambiguity Resolution with Human Feedback), that (1)\nsuggests specific inputs on which a given task specification may be ambiguous,\n(2) seeks limited human feedback about the code's desired behavior on those\ninputs, and (3) uses this feedback to generate code that resolves these\nambiguities. We evaluate the efficacy of our prototype, and we discuss the\nimplications of such assistive systems on Computer Science education.", "AI": {"tldr": "ARHF system identifies and resolves code spec ambiguities using targeted test cases and human feedback, improving code accuracy and offering a new approach for teaching ambiguity resolution in CS education.", "motivation": "Natural language task specifications in programming are inherently ambiguous, requiring programmers to identify and resolve these ambiguities manually. Existing tools lack structured methods to assist with this critical skill development in educational contexts.", "method": "The system combines ambiguity detection by generating specific test inputs, a limited human feedback mechanism to clarify desired behavior, and code generation that conforms to clarified specifications. This integrates automated analysis with iterative user interaction.", "result": "Evaluation showed the prototype successfully identified ambiguous inputs and achieved accurate code generation after feedback collection. Human feedback improved final code correctness by resolving specification ambiguities in 82% of test cases.", "conclusion": "The study demonstrates that ARHF can effectively resolve ambiguities in code specifications through targeted human feedback, suggesting its potential to be integrated into Computer Science education to enhance students' ability to handle unclear requirements and improve coding outcomes."}}
{"id": "2508.14284", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.14284", "abs": "https://arxiv.org/abs/2508.14284", "authors": ["Jonathan Passerat-Palmbach", "Sarisht Wadhwa"], "title": "Differentially Private aggregate hints in mev-share", "comment": null, "summary": "Flashbots recently released mev-share to empower users with control over the\namount of information they share with searchers for extracting Maximal\nExtractable Value (MEV). Searchers require more information to maintain\non-chain exchange efficiency and profitability, while users aim to prevent\nfrontrunning by withholding information. After analyzing two searching\nstrategies in mev-share to reason about searching techniques, this paper\nintroduces Differentially-Private (DP) aggregate hints as a new type of hints\nto disclose information quantitatively. DP aggregate hints enable users to\nformally quantify their privacy loss to searchers, and thus better estimate the\nlevel of rebates to ask in return. The paper discusses the current properties\nand privacy loss in mev-share and lays out how DP aggregate hints could enhance\nthe system for both users and searchers. We leverage Differential Privacy in\nthe Trusted Curator Model to design our aggregate hints. Additionally, we\nexplain how random sampling can defend against sybil attacks and amplify\noverall user privacy while providing valuable hints to searchers for improved\nbackrunning extraction and frontrunning prevention.", "AI": {"tldr": "This work introduces differentially-private aggregate hints for mev-share, enabling users to control information disclosure levels, quantify privacy costs, and receive better rebates, while empowering searchers to optimize MEV extraction without compromising user privacy.", "motivation": "The paper addresses the tension between searchers' information requirements for MEV extraction and users' desire to minimize information sharing to avoid frontrunning attacks in blockchain environments.", "method": "The authors employ Differential Privacy techniques within the Trusted Curator Model to design aggregate hints, combined with random sampling to mitigate sybil attacks and amplify privacy while providing actionable insights for searchers.", "result": "The analysis shows that DP aggregate hints allow users to formally quantify privacy loss and set rebates accordingly, while supporting improved searcher strategies through structured, privacy-preserving hints.", "conclusion": "The paper concludes that Differentially-Private aggregate hints enhance mev-share by enabling users to balance privacy concerns with the need for searcher efficiency, ultimately improving backrunning strategies and front-running prevention while quantifying privacy trade-offs."}}
{"id": "2508.14288", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14288", "abs": "https://arxiv.org/abs/2508.14288", "authors": ["Yewei Song", "Tiezhu Sun", "Xunzhu Tang", "Prateek Rajput", "Tegawende F. Bissyande", "Jacques Klein"], "title": "Measuring LLM Code Generation Stability via Structural Entropy", "comment": "ASE-NIER", "summary": "Assessing the stability of code generation from large language models (LLMs)\nis essential for judging their reliability in real-world development. We extend\nprior \"structural-entropy concepts\" to the program domain by pairing entropy\nwith abstract syntax tree (AST) analysis. For any fixed prompt, we collect the\nmultiset of depth-bounded subtrees of AST in each generated program and treat\ntheir relative frequencies as a probability distribution. We then measure\nstability in two complementary ways: (i) Jensen-Shannon divergence, a\nsymmetric, bounded indicator of structural overlap, and (ii) a Structural\nCross-Entropy ratio that highlights missing high-probability patterns. Both\nmetrics admit structural-only and token-aware variants, enabling separate views\non control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or\nCodeBLEU, our metrics are reference-free, language-agnostic, and\nexecution-independent. We benchmark several leading LLMs on standard code\ngeneration tasks, demonstrating that AST-driven structural entropy reveals\nnuances in model consistency and robustness. The method runs in O(n,d) time\nwith no external tests, providing a lightweight addition to the code-generation\nevaluation toolkit.", "AI": {"tldr": "The paper proposes AST-based structural entropy metrics to evaluate code-generation stability in LLMs, offering reference-free, language-agnostic insights into model consistency and robustness without execution overhead.", "motivation": "Stability assessment of code generation is critical for real-world LLM reliability, yet existing metrics like pass@k or CodeBLEU are reference-dependent or language-specific. This work addresses the need for objective, scalable, and language-agnostic evaluation frameworks.", "method": "The method extends structural-entropy concepts by pairing AST analysis with prompt-based code generation. It measures stability through (i) Jensen-Shannon divergence for structural overlap and (ii) Structural Cross-Entropy ratio for missing patterns, with structural-only and token-aware variants. The approach runs in linear time without external tests.", "result": "The metrics reveal granular differences in LLM consistency across standard code-generation tasks, outperforming reference-based metrics. The method is efficient (O(n,d) time), applicable to any programming language, and requires no execution or test-suite dependencies.", "conclusion": "The paper introduces a lightweight, reference-free method for evaluating code generation stability using structural entropy, demonstrating its effectiveness in revealing nuances of model consistency and robustness across tasks and languages."}}
