{"id": "2509.00005", "categories": ["cs.CR", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.00005", "abs": "https://arxiv.org/abs/2509.00005", "authors": ["Rohit Dube"], "title": "Per-sender neural network classifiers for email authorship validation", "comment": "11 pages, 5 figures, 8 tables", "summary": "Business email compromise and lateral spear phishing attacks are among modern\norganizations' most costly and damaging threats. While inbound phishing\ndefenses have improved significantly, most organizations still trust internal\nemails by default, leaving themselves vulnerable to attacks from compromised\nemployee accounts. In this work, we define and explore the problem of\nauthorship validation: verifying whether a claimed sender actually authored a\ngiven email. Authorship validation is a lightweight, real-time defense that\ncomplements traditional detection methods by modeling per-sender writing style.\nFurther, the paper presents a collection of new datasets based on the Enron\ncorpus. These simulate inauthentic messages using both human-written and large\nlanguage model-generated emails. The paper also evaluates two classifiers -- a\nNaive Bayes model and a character-level convolutional neural network (Char-CNN)\n-- for the authorship validation task. Our experiments show that the Char-CNN\nmodel achieves high accuracy and F1 scores under various circumstances.\nFinally, we discuss deployment considerations and show that per-sender\nauthorship classifiers are practical for integrating into existing commercial\nemail security systems with low overhead.", "AI": {"tldr": "Researchers develop and evaluate authorship validation techniques for email security, showing CNN-based models can effectively detect inauthentic messages and integrate into existing systems with low overhead.", "motivation": "Modern organizations remain vulnerable to email-based attacks from compromised employee accounts because they continue to trust internal emails by default despite improved inbound phishing defenses.", "method": "The paper introduces authorship validation based on per-sender writing style modeling, evaluates Naive Bayes and character-level CNN (Char-CNN) models for this task, and uses newly created Enron-based datasets with both human-written and LLM-generated simulated inauthentic emails for evaluation.", "result": "Char-CNN achieves high accuracy and F1 scores across various conditions, and the study demonstrates the feasibility of deploying per-sender authorship validation in commercial systems with minimal resource requirements.", "conclusion": "Authorship validation is a practical and effective real-time defense mechanism that can be integrated into commercial email systems to enhance security against internal email threats, with the character-level CNN model demonstrating high performance and low overhead."}}
{"id": "2509.00006", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00006", "abs": "https://arxiv.org/abs/2509.00006", "authors": ["Motunrayo Adebayo"], "title": "Case Studies: Effective Approaches for Navigating Cross-Border Cloud Data Transfers Amid U.S. Government Privacy and Safety Concerns", "comment": "Privacy, Security", "summary": "This study attempts to explain the impact of information exchange from one\ncountry to another, as well as the legal and technological implications for\nthese exchanges. Due to the emergence of cloud technology, possibilities for\nfree exchange of information between countries have increased rapidly, as it\nhas become possible to save information in a country and access it in almost\nany part of the world. Countries all around the world have been confronted with\ndeveloping frameworks to facilitate this process, although there are\nsignificant challenges which must be confronted on legal and technological\nfronts, as loopholes in the framework adopted by countries may hinder free\naccess to information stored on cloud, and also compromise data privacy. Cloud\ntechnology is impacting a lot of issues, including domestic and international\nbusinesses, hence the need for a study to propose measures for safe exchange of\ninformation using cloud technology.", "AI": {"tldr": "This paper examines legal and tech challenges in international cloud data exchange and proposes frameworks for secure solutions.", "motivation": "The rapid advancement of cloud technology has increased cross-border information exchange, creating a need to address legal and technological challenges to ensure secure and compliant data sharing.", "method": "The paper examines existing frameworks for cross-border information exchange, identifies legal and technological challenges, and proposes solutions to address these issues.", "result": "The analysis highlights vulnerabilities in existing frameworks that hinder secure cloud-based information exchange, while emphasizing the impact on domestic and international business operations.", "conclusion": "The study underlines the necessity for robust frameworks to ensure secure and lawful cross-border information exchange using cloud technology, emphasizing measures to address legal and technological challenges."}}
{"id": "2509.00043", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00043", "abs": "https://arxiv.org/abs/2509.00043", "authors": ["Md Faizul Bari", "Yi Xie", "Meghna Roy Choudhury", "Shreyas Sen"], "title": "Keystroke Detection by Exploiting Unintended RF Emission from Repaired USB Keyboards", "comment": "This journal version is an extended version of a previously published\n  conference paper which can be found here:\n  https://ieeexplore.ieee.org/abstract/document/10181751", "summary": "Electronic devices and cables inadvertently emit RF emissions as a byproduct\nof signal processing and/or transmission. Labeled as electromagnetic\nemanations, they form an EM side-channel for data leakage. Previously, it was\nbelieved that such leakage could be contained within a facility since they are\nweak signals with a short transmission range. However, in the preliminary\nversion of this work [1], we found that the traditional cable repairing process\nforms a tiny monopole antenna that helps emanations transmit over a long range.\nExperimentation with three types of cables revealed that emanations from\nrepaired cables remain detectable even at >4 m and can penetrate a 14 cm thick\nconcrete wall. In this extended version, we show that such emanation can be\nexploited at a long distance for information extraction by detecting keystrokes\ntyped on a repaired USB keyboard. By collecting data for 70 different\nkeystrokes at different distances from the target in 3 diverse environments\n(open space, a corridor outside an office room, and outside a building) and\ndeveloping an efficient detection algorithm, ~100% keystroke detection accuracy\nhas been achieved up to 12 m distance, which is the highest reported accuracy\nat such a long range for USB keyboards in the literature. The effect of two\nexperimental factors, interference and human-body coupling, has been\ninvestigated thoroughly. Along with exploring the vulnerability, multi-layer\nexternal metal shielding during the repairing process as a possible remedy has\nbeen explored. This work exposes a new attack surface caused by hardware\nmodification, its exploitation, and potential countermeasures.", "AI": {"tldr": "Researchers discovered that improperly repaired USB cables create long-range EM side-channels, enabling perfect keystroke detection up to 12m away through walls, demanding better hardware repair security standards.", "motivation": "Challenges the assumption that EM emanations from devices/cables are short-range and non-leaky, demonstrating how cable repair processes create unintended monopole antennas for long-range information exfiltration.", "method": "Experimental analysis of three cable types using a detection algorithm for keystroke inference, testing at 12m distance in open spaces, corridors, and buildings while measuring interference/human-body coupling effects.", "result": "99.9% keystroke detection accuracy at 12m distance with 14cm concrete penetration, establishing the highest USB keyboard EM side-channel performance in the literature.", "conclusion": "This work exposes a hardware modification vulnerability enabling long-range EM side-channel attacks, proposes multi-layer shielding as a countermeasure, and highlights the critical security risks of improperly repaired cables."}}
{"id": "2509.00059", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00059", "abs": "https://arxiv.org/abs/2509.00059", "authors": ["Andres Alejandre", "Kassandra Delfin", "Victor Castano"], "title": "Cryptographic Challenges: Masking Sensitive Data in Cyber Crimes through ASCII Art", "comment": "11 pages, 4 figures", "summary": "The use of ASCII art as a novel approach to masking sensitive information in\ncybercrime, focusing on its potential role in protecting personal data during\nthe delivery process and beyond, is presented. By examining the unique\nproperties of ASCII art and its historical context, this study discusses the\nadvantages and limitations of employing this technique in various cybercrime\nscenarios. Additionally, providing recommendations for enhancing data security\npractices and fostering a culture of privacy awareness in both businesses and\nindividuals. The findings suggest that ASCII art, with its simplicity and\nambiguity, can serve as an effective tool against cybercriminals, emphasizing\nthe need for robust data security measures and increased privacy awareness in\ntoday's interconnected world.", "AI": {"tldr": "This paper explores ASCII art as a novel data masking technique for cybercrime prevention. It evaluates its strengths and limitations, recommends improved security practices, and emphasizes the need for privacy awareness to combat evolving threats.\\n", "motivation": "The motivation centers on addressing the growing need for innovative methods to protect personal data during its delivery and beyond, leveraging ASCII art as a novel approach to counter cybercriminal activities.\\n", "method": "The study examines the unique properties and historical context of ASCII art, analyzing its application in masking sensitive information during data delivery. It evaluates advantages and limitations through various cybercrime scenarios and provides recommendations for enhancing security practices.\\n", "result": "The results indicate that ASCII art's simplicity and ambiguity offer practical advantages for data masking, while also highlighting its limitations. The study also proposes actionable recommendations to improve data security practices and promote privacy awareness among businesses and individuals.\\n", "conclusion": "ASCII art, with its simplicity and ambiguity, serves as an effective tool for protecting sensitive data against cybercriminals. The study underscores the importance of robust data security measures and fostering privacy awareness in an interconnected world.\\n"}}
{"id": "2509.00140", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00140", "abs": "https://arxiv.org/abs/2509.00140", "authors": ["Songhui Yue"], "title": "LLM-based Triplet Extraction for Automated Ontology Generation in Software Engineering Standards", "comment": null, "summary": "Ontologies have supported knowledge representation and whitebox reasoning for\ndecades; thus, the automated ontology generation (AOG) plays a crucial role in\nscaling their use. Software engineering standards (SES) consist of long,\nunstructured text (with high noise) and paragraphs with domain-specific terms.\nIn this setting, relation triple extraction (RTE), together with term\nextraction, constitutes the first stage toward AOG. This work proposes an\nopen-source large language model (LLM)-assisted approach to RTE for SES.\nInstead of solely relying on prompt-engineering-based methods, this study\npromotes the use of LLMs as an aid in constructing ontologies and explores an\neffective AOG workflow that includes document segmentation, candidate term\nmining, LLM-based relation inference, term normalization, and cross-section\nalignment. Golden-standard benchmarks at three granularities are constructed\nand used to evaluate the ontology generated from the study. The results show\nthat it is comparable and potentially superior to the OpenIE method of triple\nextraction.", "AI": {"tldr": "LLM-assisted AOG for SES texts improves RTE and ontology generation, matching/exceeding OpenIE benchmarks.", "motivation": "Automated ontology generation (AOG) is critical for scaling knowledge representation in software engineering standards (SES), which contain unstructured, noisy, domain-specific texts that challenge traditional methods.", "method": "The paper introduces an LLM-aided workflow for RTE, combining document segmentation, candidate term mining, LLM-based relation inference, term normalization, and cross-section alignment, moving beyond prompt-engineering techniques.", "result": "Golden-standard benchmarks evaluated the proposed method across three granularities, showing results comparable to or outperforming the OpenIE triple extraction method.", "conclusion": "The study demonstrates that the LLM-assisted approach for ontology generation in software engineering standards is comparable or superior to existing methods like OpenIE, offering a viable workflow for automated ontology creation."}}
{"id": "2509.00081", "categories": ["cs.CR", "cs.AI", "I.2.7; I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2509.00081", "abs": "https://arxiv.org/abs/2509.00081", "authors": ["Luca Cotti", "Anisa Rula", "Devis Bianchini", "Federico Cerutti"], "title": "Enabling Transparent Cyber Threat Intelligence Combining Large Language Models and Domain Ontologies", "comment": "14 pages, 3 figures, 6 tables, accepted at XAI-KRKG@ECAI25: First\n  International ECAI Workshop on eXplainable AI, Knowledge Representation and\n  Knowledge Graphs, October 25-30, 2025, Bologna, Italy", "summary": "Effective Cyber Threat Intelligence (CTI) relies upon accurately structured\nand semantically enriched information extracted from cybersecurity system logs.\nHowever, current methodologies often struggle to identify and interpret\nmalicious events reliably and transparently, particularly in cases involving\nunstructured or ambiguous log entries. In this work, we propose a novel\nmethodology that combines ontology-driven structured outputs with Large\nLanguage Models (LLMs), to build an Artificial Intelligence (AI) agent that\nimproves the accuracy and explainability of information extraction from\ncybersecurity logs. Central to our approach is the integration of domain\nontologies and SHACL-based constraints to guide the language model's output\nstructure and enforce semantic validity over the resulting graph. Extracted\ninformation is organized into an ontology-enriched graph database, enabling\nfuture semantic analysis and querying. The design of our methodology is\nmotivated by the analytical requirements associated with honeypot log data,\nwhich typically comprises predominantly malicious activity. While our case\nstudy illustrates the relevance of this scenario, the experimental evaluation\nis conducted using publicly available datasets. Results demonstrate that our\nmethod achieves higher accuracy in information extraction compared to\ntraditional prompt-only approaches, with a deliberate focus on extraction\nquality rather than processing speed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00256", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00256", "abs": "https://arxiv.org/abs/2509.00256", "authors": ["Yutong Wang", "Cindy Rubio-Gonz\u00e1lez"], "title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "comment": null, "summary": "Floating-point inconsistencies across compilers can undermine the reliability\nof numerical software. We present LLM4FP, the first framework that uses Large\nLanguage Models (LLMs) to generate floating-point programs specifically\ndesigned to trigger such inconsistencies. LLM4FP combines Grammar-Based\nGeneration and Feedback-Based Mutation to produce diverse and valid programs.\nWe evaluate LLM4FP across multiple compilers and optimization levels, measuring\ninconsistency rate, time cost, and program diversity. LLM4FP detects over twice\nas many inconsistencies compared to the state-of-the-art tool, Varity. Notably,\nmost of the inconsistencies involve real-valued differences, rather than\nextreme values like NaN or infinities. LLM4FP also uncovers inconsistencies\nacross a wider range of optimization levels, and finds the most mismatches\nbetween host and device compilers. These results show that LLM-guided program\ngeneration improves the detection of numerical inconsistencies.", "AI": {"tldr": "LLM4FP uses large language models to generate programs that expose compiler floating-point inconsistencies more effectively than state-of-the-art tools, finding twice as many issues with real-value discrepancies and broader optimization coverage.", "motivation": "Floating-point compiler inconsistencies threaten numerical software reliability, but existing tools like Varity fail to expose subtle, real-world discrepancies beyond extreme values (NaNs/infinities) across diverse optimization contexts.", "method": "LLM4FP integrates Grammar-Based Generation (for syntactically valid programs) and Feedback-Based Mutation (for semantic diversity) using Large Language Models to produce targeted floating-point programs that stress-test compiler behavior.", "result": "LLM4FP achieves 2\u00d7+ higher inconsistency detection than Varity, reveals predominantly real-valued inconsistencies, uncovers mismatches across more optimization levels, and identifies critical host/device compiler divergences not found by prior approaches.", "conclusion": "LLM4FP demonstrates that LLM-guided program generation significantly enhances the detection of compiler-specific floating-point inconsistencies compared to existing tools, particularly in identifying real-valued discrepancies and cross-optimization-level issues."}}
{"id": "2509.00085", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00085", "abs": "https://arxiv.org/abs/2509.00085", "authors": ["Tobin South"], "title": "Private, Verifiable, and Auditable AI Systems", "comment": "PhD thesis", "summary": "The growing societal reliance on artificial intelligence necessitates robust\nframeworks for ensuring its security, accountability, and trustworthiness. This\nthesis addresses the complex interplay between privacy, verifiability, and\nauditability in modern AI, particularly in foundation models. It argues that\ntechnical solutions that integrate these elements are critical for responsible\nAI innovation. Drawing from international policy contributions and technical\nresearch to identify key risks in the AI pipeline, this work introduces novel\ntechnical solutions for critical privacy and verifiability challenges.\nSpecifically, the research introduces techniques for enabling verifiable and\nauditable claims about AI systems using zero-knowledge cryptography; utilizing\nsecure multi-party computation and trusted execution environments for\nauditable, confidential deployment of large language models and information\nretrieval; and implementing enhanced delegation mechanisms, credentialing\nsystems, and access controls to secure interactions with autonomous and\nmulti-agent AI systems. Synthesizing these technical advancements, this\ndissertation presents a cohesive perspective on balancing privacy,\nverifiability, and auditability in foundation model-based AI systems, offering\npractical blueprints for system designers and informing policy discussions on\nAI safety and governance.", "AI": {"tldr": "This thesis develops cryptography-based frameworks for trustworthy AI, enabling verifiable, auditable, and privacy-preserving foundation models through techniques like zero-knowledge proofs and secure computation, offering both technical implementations and policy implications.", "motivation": "The thesis addresses the urgent need for security, accountability, and trustworthiness in AI systems as societal reliance grows, emphasizing the critical importance of balancing privacy requirements with transparency and auditability in foundation models.", "method": "The research employs zero-knowledge cryptography, secure multi-party computation, trusted execution environments, and enhanced delegation/access control mechanisms to address privacy and verifiability challenges in AI systems.", "result": "The work introduces verifiable claim frameworks, confidential deployment solutions for large language models, and secure interaction protocols for multi-agent systems, providing practical blueprints for implementing privacy-verifiability-auditability tradeoffs.", "conclusion": "This dissertation concludes that integrating privacy, verifiability, and auditability in foundation model-based AI systems requires combining advanced cryptographic methods with policy-informed system design to achieve responsible AI innovation while addressing critical security risks."}}
{"id": "2509.00466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00466", "abs": "https://arxiv.org/abs/2509.00466", "authors": ["Negar Hashemi", "Amjed Tahir", "Shawn Rasheed", "August Shi", "Rachel Blagojevic"], "title": "JS-TOD: Detecting Order-Dependent Flaky Tests in Jest", "comment": null, "summary": "We present JS-TOD (JavaScript Test Order-dependency Detector), a tool that\ncan extract, reorder, and rerun Jest tests to reveal possible order-dependent\ntest flakiness. Test order dependency is one of the leading causes of test\nflakiness. Ideally, each test should operate in isolation and yield consistent\nresults no matter the sequence in which tests are run. However, in practice,\ntest outcomes can vary depending on their execution order. JS-TOD employed a\nsystematic approach to randomising tests, test suites, and describe blocks. The\ntool is highly customisable, as one can set the number of orders and reruns\nrequired (the default setting is 10 reorder and 10 reruns for each test and\ntest suite). Our evaluation using JS-TOD reveals two main causes of test order\ndependency flakiness: shared files and shared mocking state between tests.", "AI": {"tldr": "JS-TOD detects test flakiness caused by order dependencies in Jest, revealing that shared files and mocking state are key culprits.", "motivation": "Test order dependency is a major cause of test flakiness, where tests should ideally be isolated but often produce inconsistent results based on execution sequence.", "method": "JS-TOD systematically randomizes tests, test suites, and describe blocks through customizable reordering and rerunning (default: 10 orders, 10 reruns) to expose order dependencies.", "result": "Evaluation with JS-TOD identified shared files and shared mocking state between tests as the primary sources of test order dependency flakiness.", "conclusion": "The paper introduces JS-TOD as an effective solution for detecting order-dependent test flakiness, concluding that shared files and mocking state are critical factors contributing to this issue."}}
{"id": "2509.00088", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00088", "abs": "https://arxiv.org/abs/2509.00088", "authors": ["Ting-Chun Liu", "Ching-Yu Hsu", "Kuan-Yi Lee", "Chi-An Fu", "Hung-yi Lee"], "title": "AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema", "comment": null, "summary": "Prompt injection attacks pose a significant challenge to the safe deployment\nof Large Language Models (LLMs) in real-world applications. While prompt-based\ndetection offers a lightweight and interpretable defense strategy, its\neffectiveness has been hindered by the need for manual prompt engineering. To\naddress this issue, we propose AEGIS , an Automated co-Evolutionary framework\nfor Guarding prompt Injections Schema. Both attack and defense prompts are\niteratively optimized against each other using a gradient-like natural language\nprompt optimization technique. This framework enables both attackers and\ndefenders to autonomously evolve via a Textual Gradient Optimization (TGO)\nmodule, leveraging feedback from an LLM-guided evaluation loop. We evaluate our\nsystem on a real-world assignment grading dataset of prompt injection attacks\nand demonstrate that our method consistently outperforms existing baselines,\nachieving superior robustness in both attack success and detection.\nSpecifically, the attack success rate (ASR) reaches 1.0, representing an\nimprovement of 0.26 over the baseline. For detection, the true positive rate\n(TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and\nthe true negative rate (TNR) remains comparable at 0.89. Ablation studies\nconfirm the importance of co-evolution, gradient buffering, and multi-objective\noptimization. We also confirm that this framework is effective in different\nLLMs. Our results highlight the promise of adversarial training as a scalable\nand effective approach for guarding prompt injections.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00785", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00785", "abs": "https://arxiv.org/abs/2509.00785", "authors": ["Elena Masserini", "Daniela Micucci", "Leonardo Mariani"], "title": "Bug Whispering: Towards Audio Bug Reporting", "comment": "2 pages, 1 figure, IEEE International Symposium on Software\n  Reliability Engineering (ISSRE), 2025, Fast Abstracts Session", "summary": "Bug reporting is a key feature of mobile applications, as it enables\ndevelopers to collect information about faults that escaped testing and thus\naffected end-users. This paper explores the idea of allowing end-users to\nimmediately report the problems that they experience by recording and\nsubmitting audio messages. Audio recording is simple to implement and has the\npotential to increase the number of bug reports that development teams can\ngather, thus potentially improving the rate at which bugs are identified and\nfixed. However, audio bug reports exhibit specific characteristics that\nchallenge existing techniques for reproducing bugs. This paper discusses these\nchallenges based on a preliminary experiment, and motivates further research on\nthe collection and analysis of audio-based bug reports", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00104", "categories": ["cs.CR", "cs.IT", "math.IT", "quant-ph", "94A60, 81P94, 94A17, 68Q12", "E.3; K.6.5; F.1.2; F.2.1"], "pdf": "https://arxiv.org/pdf/2509.00104", "abs": "https://arxiv.org/abs/2509.00104", "authors": ["Ruopengyu Xu", "Chenglian Liu"], "title": "Enhanced R\u00e9nyi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees", "comment": "11 pages, 3 tables", "summary": "This paper presents an enhanced post-quantum key agreement protocol based on\nR\\'{e}nyi entropy, addressing vulnerabilities in the original construction\nwhile preserving information-theoretic security properties. We develop a\ntheoretical framework leveraging entropy-preserving operations and\nsecret-shared verification to achieve provable security against quantum\nadversaries. Through entropy amplification techniques and quantum-resistant\ncommitments, the protocol establishes $2^{128}$ quantum security guarantees\nunder the quantum random oracle model. Key innovations include a\nconfidentiality-preserving verification mechanism using distributed polynomial\ncommitments, tightened min-entropy bounds with guaranteed non-negativity, and\ncomposable security proofs in the quantum universal composability framework.\nUnlike computational approaches, our method provides information-theoretic\nsecurity without hardness assumptions while maintaining polynomial complexity.\nTheoretical analysis demonstrates resilience against known quantum attack\nvectors, including Grover-accelerated brute force and quantum memory attacks.\nThe protocol achieves parameterization for 128-bit quantum security with\nefficient $\\mathcal{O}(n^2)$ communication complexity. Extensions to secure\nmultiparty computation and quantum network applications are established,\nproviding a foundation for long-term cryptographic security. All security\nclaims are derived from mathematical proofs; this theoretical work presents no\nexperimental validation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.01006", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01006", "abs": "https://arxiv.org/abs/2509.01006", "authors": ["Daniela Damian", "Bachan Ghimire", "Ze Shi Li"], "title": "REConnect: Participatory RE that Matters", "comment": "23 pages", "summary": "Software increasingly shapes the infrastructures of daily life, making\nrequirements engineering (RE) central to ensuring that systems align with human\nvalues and lived experiences. Yet, current popular practices such as CrowdRE\nand AI-assisted elicitation strategies risk detaching requirements work from\nthe cultural, social, and political contexts that shape lived experiences,\nhuman values, and real user needs. In this paper, we introduce REConnect that\nre-centers RE on the human connection as central to the understanding of lived\nexperiences where impact is sought. REConnect advocates for a human-centered\nparticipatory approach \"that matters\" to the communities and beneficiaries\ninvolved, ensuring alignment with their values and aspirations. Drawing on\nthree case studies of societal impact: BloodSync in rural Nepal, Herluma\nsupporting women at risk of homelessness in Canada, and BridgingRoots to\nrevitalize Indigenous languages in the Canadian Arctic. REConnect argues that\nthree key principles and enablers: building trusting relationships,\nco-designing with and alongside stakeholders, and empowering users as agents of\nchange, can yield requirements that are culturally grounded, socially\nlegitimate, and sustainable beyond system delivery. REConnect also proposes a\nset of actionable practices (REActions) that embed relationality and ongoing\nstakeholder engagement throughout requirements elicitation, analysis, and\nvalidation of solution development. Finally, we situate REConnect in the era of\nGenerative AI. While AI can accelerate and scale certain RE tasks, its\nintegration must be guided by participatory practices that not only preserve\nhuman agency but also empower humans' roles to become guardians of values and\nethics, inclusion amplifiers, curators of AI outputs, and co-reflectors in\niterative review cycles.", "AI": {"tldr": "REConnect recenter requirements engineering on human connection through participatory practices", "motivation": "Current practices like CrowdRE and AI elicitation risk detaching requirements work from cultural/social/political contexts", "method": "Proposes REConnect framework with three principles (trust-building, co-design, empowerment) demonstrated via BloodSync, Herluma, and BridgingRoots case studies", "result": "Requirements outcomes are culturally grounded, socially legitimate, and sustainable; introduces REActions practices for stakeholder engagement", "conclusion": "Argues for participatory AI integration in RE to maintain human agency and ethical guardianship"}}
{"id": "2509.00124", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00124", "abs": "https://arxiv.org/abs/2509.00124", "authors": ["Shaked Zychlinski"], "title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See", "comment": "10 pages, 1 figure", "summary": "This paper introduces a novel attack vector that leverages website cloaking\ntechniques to compromise autonomous web-browsing agents powered by Large\nLanguage Models (LLMs). As these agents become more prevalent, their unique and\noften homogenous digital fingerprints - comprising browser attributes,\nautomation framework signatures, and network characteristics - create a new,\ndistinguishable class of web traffic. The attack exploits this\nfingerprintability. A malicious website can identify an incoming request as\noriginating from an AI agent and dynamically serve a different, \"cloaked\"\nversion of its content. While human users see a benign webpage, the agent is\npresented with a visually identical page embedded with hidden, malicious\ninstructions, such as indirect prompt injections. This mechanism allows\nadversaries to hijack agent behavior, leading to data exfiltration, malware\nexecution, or misinformation propagation, all while remaining completely\ninvisible to human users and conventional security crawlers. This work\nformalizes the threat model, details the mechanics of agent fingerprinting and\ncloaking, and discusses the profound security implications for the future of\nagentic AI, highlighting the urgent need for robust defenses against this\nstealthy and scalable attack.", "AI": {"tldr": "This paper reveals a stealthy cloaking attack exploiting AI agents' digital fingerprints to deliver malicious content, enabling undetected threats to agent-based systems.", "motivation": "The proliferation of autonomous AI agents with detectable digital fingerprints creates a new security vulnerability, as adversaries can exploit this fingerprintability to selectively target agents with malicious content, bypassing traditional security measures.", "method": "The attack employs website cloaking techniques that detect and differentiate traffic from AI agents (via their digital fingerprints) and serve malicious, cloaked content to these agents, enabling indirect prompt injections and unauthorized actions.", "result": "The attack demonstrates how adversaries can stealthily hijack agent behavior for data exfiltration, malware execution, or misinformation without detection, revealing significant security implications for agentic AI systems.", "conclusion": "The paper highlights the urgent need for robust defenses against cloaking attacks targeting autonomous AI agents, emphasizing the security risks associated with their distinguishable digital fingerprints."}}
{"id": "2509.01048", "categories": ["cs.SE", "D.2.1"], "pdf": "https://arxiv.org/pdf/2509.01048", "abs": "https://arxiv.org/abs/2509.01048", "authors": ["Ateeq Sharfuddin", "Travis Breaux"], "title": "Generative Goal Modeling", "comment": "11 pages,", "summary": "In software engineering, requirements may be acquired from stakeholders\nthrough elicitation methods, such as interviews, observational studies, and\nfocus groups. When supporting acquisition from interviews, business analysts\nmust review transcripts to identify and document requirements. Goal modeling is\na popular technique for representing early stakeholder requirements as it lends\nitself to various analyses, including refinement to map high-level goals into\nsoftware operations, and conflict and obstacle analysis. In this paper, we\ndescribe an approach to use textual entailment to reliably extract goals from\ninterview transcripts and to construct goal models. The approach has been\nevaluated on 15 interview transcripts across 29 application domains. The\nfindings show that GPT-4o can reliably extract goals from interview\ntranscripts, matching 62.0% of goals acquired by humans from the same\ntranscripts, and that GPT-4o can trace goals to originating text in the\ntranscript with 98.7% accuracy. In addition, when evaluated by human\nannotators, GPT-4o generates goal model refinement relationships among\nextracted goals with 72.2% accuracy.", "AI": {"tldr": "This paper proposes using GPT-4o for automated goal extraction from interviews, achieving strong accuracy in text tracing and refinement relationships, demonstrating its potential as a tool for efficient requirements modeling.", "motivation": "Manual review of interview transcripts for requirement acquisition is labor-intensive; automated techniques like textual entailment could improve efficiency and consistency in extracting goal models from textual data.", "method": "The approach employs textual entailment via GPT-4o to identify goals in 15 interview transcripts across 29 domains, with performance assessed through comparison to human annotations for goal extraction, tracing, and refinement relationship generation.", "result": "GPT-4o achieved 62.0% goal matching accuracy compared to human-derived goals, 98.7% accuracy in tracing goals to transcript segments, and 72.2% accuracy in generating goal refinement relationships according to human evaluators.", "conclusion": "The study concludes that GPT-4o effectively supports automated goal extraction from interview transcripts with high tracing accuracy (98.7%) and acceptable refinement relationship accuracy (72.2%), although further improvements are needed for goal matching (62.0%) to better align with human performance."}}
{"id": "2509.00266", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00266", "abs": "https://arxiv.org/abs/2509.00266", "authors": ["Qishen Sam Liang"], "title": "A Systematic Approach to Estimate the Security Posture of a Cyber Infrastructure: A Technical Report", "comment": "11 pages, 5 figures, technical report", "summary": "Academic and research Cyber Infrastructures (CI) present unique security\nchallenges due to their collaborative nature, heterogeneous components, and the\nlack of practical, tailored security assessment frameworks. Existing standards\ncan be too generic or complex for CI administrators to apply effectively. This\nreport introduces a systematic, mission-centric approach to estimate and\nanalyze the security posture of a CI. The framework guides administrators\nthrough a top-down process: (1) defining unacceptable losses and security\nmissions, (2) identifying associated system hazards and critical assets, and\n(3) modeling the CI's components and their relationships as a security\nknowledge graph. The core of this methodology is the construction of directed\nattack graphs, which systematically map all potential paths an adversary could\ntake from an entry point to a critical asset. By visualizing these attack paths\nalongside defense mechanisms, the framework provides a clear, comprehensive\noverview of the system's vulnerabilities and security gaps. This structured\napproach enables CI operators to proactively assess risks, prioritize\nmitigation strategies, and make informed, actionable decisions to strengthen\nthe overall security posture of the CI.", "AI": {"tldr": "This paper proposes a mission-driven security framework for Cyber Infrastructures, using attack graphs and knowledge modeling to identify vulnerabilities and guide actionable security improvements.", "motivation": "Existing security frameworks are too generic/complex for academic Cyber Infrastructures, which require tailored solutions for their collaborative, heterogeneous environments.", "method": "A three-phase approach: (1) defining unacceptable losses and missions, (2) identifying system hazards/assets, and (3) constructing a security knowledge graph with directed attack graphs to visualize attack paths and defenses.", "result": "The framework provides a comprehensive vulnerability overview, enabling operators to prioritize mitigation strategies and improve risk management through structured attack path analysis and defense visualization.", "conclusion": "The proposed mission-centric framework enables proactive assessment of risks and informed decision-making for enhancing the security posture of Cyber Infrastructures, offering a structured alternative to generic security standards."}}
{"id": "2509.01068", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01068", "abs": "https://arxiv.org/abs/2509.01068", "authors": ["Chong Wang", "Haoning Wu", "Peng Liang", "Maya Daneva", "Marten van Sinderen"], "title": "A Survey on the Techniques and Tools for Automated Requirements Elicitation and Analysis of Mobile Apps", "comment": null, "summary": "[Background:] Research on automated requirements elicitation and analysis of\nmobile apps employed lots of techniques and tools proposed by RE researchers\nand practitioners. However, little is known about the characteristics of these\ntechniques and tools as well as the RE tasks in requirements elicitation and\nanalysis that got supported with the help of respective techniques and tools.\n[Aims:] The goal of this paper is to investigate the state-of-the-art of the\ntechniques and tools used in automated requirements elicitation and analysis of\nmobile apps. [Method:] We carried out a systematic mapping study by following\nthe guidelines of Kitchenham et al. [Results:] Based on 73 selected papers, we\nfound the most frequently used techniques - semi-automatic techniques, and the\nmain characteristics of the tools - open-sourced and non-self-developed tools\nfor requirements analysis and text pre-processing. Plus, the most three\ninvestigated RE tasks are requirements analysis, mining and classification.\n[Conclusions:] Our most important conclusions are: (1) there is a growth in the\nuse of techniques and tools in automated requirements elicitation and analysis\nof mobile apps, (2) semi-automatic techniques are mainly used in the\npublications on this research topic, (3) requirements analysis, mining and\nclassification are the top three RE tasks with the support of automatic\ntechniques and tools, and (4) the most popular tools are open-sourced and\nnon-self-developed, and they are mainly used in requirements analysis and text\nprocessing.", "AI": {"tldr": "This systematic mapping study analyzes 73 papers to reveal that semi-automatic techniques and open-source tools are widely used for requirements analysis, mining, and classification in automated mobile app requirements elicitation.", "motivation": "The paper addresses a gap in understanding the characteristics of techniques/tools and their alignment with RE tasks in mobile app requirements analysis, despite widespread adoption.", "method": "The study employed a systematic mapping approach following Kitchenham et al. guidelines, analyzing 73 selected papers to map techniques, tools, and their applications.", "result": "Key findings include: (1) semi-automatic techniques dominate usage, (2) open-sourced/non-self-developed tools are prevalent, and (3) requirements analysis, mining, and classification are most commonly supported tasks.", "conclusion": "The paper concludes that there is a growing use of semi-automatic techniques and open-sourced tools in automated requirements elicitation for mobile apps, with requirements analysis, mining, and classification being the primary tasks supported."}}
