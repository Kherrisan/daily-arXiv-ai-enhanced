<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 1]
- [cs.SE](#cs.SE) [Total: 4]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Lightweight MobileNetV1+GRU for ECG Biometric Authentication: Federated and Adversarial Evaluation](https://arxiv.org/abs/2509.20382)
*Dilli Hang Rai,Sabin Kafley*

Main category: cs.CR

TL;DR: This paper proposes a lightweight deep learning model (MobileNetV1+GRU) for secure ECG biometric authentication, evaluates its performance across datasets, and highlights challenges like adversarial attacks and dataset diversity needs.


<details>
  <summary>Details</summary>
Motivation: ECG biometrics face challenges in real-time processing, privacy, and spoofing vulnerability when deployed on wearable devices, necessitating efficient and secure solutions.

Method: A lightweight MobileNetV1+GRU model is designed with 20dB Gaussian noise injection and custom preprocessing. Evaluated on four datasets (ECGID, MIT-BIH, CYBHi, PTB) under wearable conditions and edge deployment, including adversarial FGSM attack testing.

Result: Achieved 99.34% accuracy on ECGID (EER=0.0009, ROC-AUC=0.9999), 99.31% on MIT-BIH (EER=0.00013, ROC-AUC=0.9999), and similar strong metrics. Under FGSM attacks, accuracy drops to as low as 0.80%.

Conclusion: The paper stresses the importance of federated learning, adversarial robustness testing, and diverse wearable physiology datasets to ensure secure, scalable biometric systems.

Abstract: ECG biometrics offer a unique, secure authentication method, yet their
deployment on wearable devices faces real-time processing, privacy, and
spoofing vulnerability challenges. This paper proposes a lightweight deep
learning model (MobileNetV1+GRU) for ECG-based authentication, injection of
20dB Gaussian noise & custom preprocessing. We simulate wearable conditions and
edge deployment using the ECGID, MIT-BIH, CYBHi, and PTB datasets, achieving
accuracies of 99.34%, 99.31%, 91.74%, and 98.49%, F1-scores of 0.9869, 0.9923,
0.9125, and 0.9771, Precision of 0.9866, 0.9924, 0.9180 and 0.9845, Recall of
0.9878, 0.9923, 0.9129, and 0.9756, equal error rates (EER) of 0.0009, 0.00013,
0.0091, and 0.0009, and ROC-AUC values of 0.9999, 0.9999, 0.9985, and 0.9998,
while under FGSM adversarial attacks, accuracy drops from 96.82% to as low as
0.80%. This paper highlights federated learning, adversarial testing, and the
need for diverse wearable physiological datasets to ensure secure and scalable
biometrics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM fine-tuned LLMs outperform baselines in generating accurate OpenACC pragmas, enabling practical GPU offloading automation.


<details>
  <summary>Details</summary>
Motivation: GPU parallel programming remains complex despite abstraction tools like OpenACC; reducing required expertise for effective directive usage is critical for broader adoption.

Method: Developed ACCeLLiuM using a dataset of 4,033 OpenACC pragma-loop pairs via supervised fine-tuning. Models were evaluated using precision metrics for directive generation.

Result: Fine-tuned LLMs achieved 87% valid directive-type accuracy and 50% exact pragma matches. Generated pragmas included useful clause variations even in non-exact cases.

Conclusion: The study presents ACCeLLiuM, two fine-tuned LLMs for generating OpenACC directives, aiming to establish a reproducible benchmark and reduce barriers for automated GPU programming.

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [3] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: This paper systematically reviews software security visualization techniques, categorizing them into four types (graph-based, notation-based, matrix-based, metaphor-based) through analysis of 60 research papers, while identifying two main areas (software development and operational/cybersecurity visualization).


<details>
  <summary>Details</summary>
Motivation: Traditional text-based/normative security analysis methods are becoming ineffective with system complexity and evolving threats.

Method: Systematic review of over 60 recent key research papers to create a taxonomy and identify patterns.

Result: A comprehensive taxonomy of four visualization types, identification of two core research areas, and analysis of key issues/advancements.

Conclusion: Innovative adaptive visualization techniques are urgently needed to improve threat detection and security responses through evolving visualization methods.

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [4] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: Dynamic ReAct enables efficient tool selection for large-scale AI agents by introducing a hierarchical system that reduces computational overhead by 50% while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Traditional ReAct agents fail with extensive tool sets due to memory limitations and computational infeasibility of loading all tools simultaneously.

Method: Five iterative architectures culminating in a context-aware search-and-load mechanism for progressive tool selection refinement.

Result: 50% reduction in tool loading overhead with preserved task completion accuracy across diverse environments.

Conclusion: Dynamic ReAct advances general-purpose AI agents by enabling intelligent, low-overhead adaptation to large tool environments.

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [5] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: This paper proposes a knowledge graph-based framework to address fairness requirements in software systems, aiming to bridge gaps in formalizing and verifying fairness, which differ from existing approaches focused on algorithmic bias or data issues.


<details>
  <summary>Details</summary>
Motivation: The study addresses the lack of well-specified fairness requirements and their verification, highlighting that discrimination in software systems often stems from implicit expert knowledge and unaddressed fairness requirements, unlike prior focuses on biased data or algorithms.

Method: The authors leverage knowledge graphs, inspired by security engineering applications, to formalize fairness knowledge and create a verifiable framework for fairness requirements, outlining challenges and a research roadmap.

Result: The paper presents a framework for fairness knowledge graphs, identifies research challenges, formulates research questions, and proposes a roadmap for addressing these challenges.

Conclusion: The framework enables systematic specification and verification of fairness requirements, offering a structured approach to mitigate discrimination risks in software systems through formalized, domain-agnostic knowledge representation.

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>
