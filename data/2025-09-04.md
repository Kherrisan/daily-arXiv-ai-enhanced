<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 6]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Secure Password Generator Based on Secure Pseudo-Random Number Generator](https://arxiv.org/abs/2509.02578)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: This paper proposes a secure password generation method using HMAC, CMAC, and KMAC-based PRNG, validated by NIST standards for optimal randomness and protection against breaches.


<details>
  <summary>Details</summary>
Motivation: Recent account and password leaks highlight the risks of weak passwords and vulnerabilities in website infrastructures. Strong password generation is critical for system security and preventing personal information exposure.

Method: The study introduces a password generation method based on a cryptographically secure Pseudo-Random Number Generator (PRNG) implemented with HMAC, CMAC, and KMAC algorithms. The generated random values undergo NIST SP 800-90B validation for entropy estimation and IID property confirmation.

Result: Empirical evaluations demonstrate the proposed method satisfies NIST-defined entropy and IID criteria, proving its ability to generate highly random and secure passwords.

Conclusion: The proposed method effectively generates secure passwords by utilizing a cryptographically secure PRNG with HMAC, CMAC, and KMAC, meeting NIST entropy and IID requirements. This approach enhances system security and personal data protection.

Abstract: In recent years, numerous incidents involving the leakage of website accounts
and text passwords (referred to as passwords) have raised significant concerns
regarding the potential exposure of personal information. These events
underscore the critical importance of both information security and password
protection. While many of these breaches are attributable to vulnerabilities
within website infrastructure, the strength and security of the passwords
themselves also play a crucial role. Consequently, the creation of secure
passwords constitutes a fundamental aspect of enhancing overall system security
and protecting personal data. In response to these challenges, this study
presents a secure password generation approach utilizing a cryptographically
secure Pseudo-Random Number Generator (PRNG). The generator is implemented
using a range of Message Authentication Code (MAC) algorithms, including the
Keyed-Hash Message Authentication Code (HMAC), Cipher-based Message
Authentication Code (CMAC), and KECCAK Message Authentication Code (KMAC), to
produce robust random values suitable for password generation. To evaluate the
proposed method, empirical assessments were conducted in accordance with the
guidelines provided in the National Institute of Standards and Technology
(NIST) Special Publication (SP) 800-90B. The evaluation focused on two primary
aspects: entropy estimation and verification of independent and identically
distributed (IID) properties. Experimental results indicate that the proposed
method satisfies both entropy and IID requirements, thereby demonstrating its
ability to generate passwords with a high degree of randomness and security.

</details>


### [2] [Managing Correlations in Data and Privacy Demand](https://arxiv.org/abs/2509.02856)
*Syomantak Chaudhuri,Thomas A. Courtade*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Previous works in the differential privacy literature that allow users to
choose their privacy levels typically operate under the heterogeneous
differential privacy (HDP) framework with the simplifying assumption that user
data and privacy levels are not correlated. Firstly, we demonstrate that the
standard HDP framework falls short when user data and privacy demands are
allowed to be correlated. Secondly, to address this shortcoming, we propose an
alternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that
jointly accounts for user data and privacy preference. We show that AHDP is
robust to possible correlations between data and privacy. Thirdly, we formalize
the guarantees of the proposed AHDP framework through an operational hypothesis
testing perspective. The hypothesis testing setup may be of independent
interest in analyzing other privacy frameworks as well. Fourthly, we show that
there exists non-trivial AHDP mechanisms that notably do not require prior
knowledge of the data-privacy correlations. We propose some such mechanisms and
apply them to core statistical tasks such as mean estimation, frequency
estimation, and linear regression. The proposed mechanisms are simple to
implement with minimal assumptions and modeling requirements, making them
attractive for real-world use. Finally, we empirically evaluate proposed AHDP
mechanisms, highlighting their trade-offs using LLM-generated synthetic
datasets, which we release for future research.

</details>


### [3] [Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption](https://arxiv.org/abs/2509.03024)
*Moontaha Nishat Chowdhury,Andr√© Bauer,Minxuan Zhou*

Main category: cs.CR

TL;DR: Presents CSR-based FHE matrix factorization for privacy-preserving recommendation systems to address sparsity and communication costs.


<details>
  <summary>Details</summary>
Motivation: Recommendation systems use sensitive data, but FHE's high computational cost for sparse matrices and communication overhead in encrypted domains hinders adoption.

Method: Combines Compressed Sparse Row (CSR)-based FHE matrix factorization to handle matrix sparsity and reduce communication overhead in encrypted domains.

Result: Experimental results show high recommendation accuracy on encrypted data with minimal communication costs, effectively preserving user privacy.

Conclusion: The CSR-FHE approach efficiently addresses FHE's computational and communication challenges in recommendation systems while maintaining user privacy.

Abstract: In today's data-driven world, recommendation systems personalize user
experiences across industries but rely on sensitive data, raising privacy
concerns. Fully homomorphic encryption (FHE) can secure these systems, but a
significant challenge in applying FHE to recommendation systems is efficiently
handling the inherently large and sparse user-item rating matrices. FHE
operations are computationally intensive, and naively processing various sparse
matrices in recommendation systems would be prohibitively expensive.
Additionally, the communication overhead between parties remains a critical
concern in encrypted domains. We propose a novel approach combining Compressed
Sparse Row (CSR) representation with FHE-based matrix factorization that
efficiently handles matrix sparsity in the encrypted domain while minimizing
communication costs. Our experimental results demonstrate high recommendation
accuracy with encrypted data while achieving the lowest communication costs,
effectively preserving user privacy.

</details>


### [4] [TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum](https://arxiv.org/abs/2509.03037)
*Shuzheng Wang,Yue Huang,Zhuoer Xu,Yuming Huang,Jing Tang*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet
comprehensive security analysis remains difficult due to unverified code,
proxy-based architectures, and the reliance on manual inspection of complex
execution traces. Existing approaches fall into two main categories: anomaly
transaction detection, which flags suspicious transactions but offers limited
insight into specific attack strategies hidden in execution traces inside
transactions, and code vulnerability detection, which cannot analyze unverified
contracts and struggles to show how identified flaws are exploited in real
incidents. As a result, analysts must still manually align transaction traces
with contract code to reconstruct attack scenarios and conduct forensics. To
address this gap, TraceLLM is proposed as a framework that leverages LLMs to
integrate execution trace-level detection with decompiled contract code. We
introduce a new anomaly execution path identification algorithm and an
LLM-refined decompile tool to identify vulnerable functions and provide
explicit attack paths to LLM. TraceLLM establishes the first benchmark for
joint trace and contract code-driven security analysis. For comparison, proxy
baselines are created by jointly transmitting the results of three
representative code analysis along with raw traces to LLM. TraceLLM identifies
attacker and victim addresses with 85.19\% precision and produces automated
reports with 70.37\% factual precision across 27 cases with ground truth expert
reports, achieving 25.93\% higher accuracy than the best baseline. Moreover,
across 148 real-world Ethereum incidents, TraceLLM automatically generates
reports with 66.22\% expert-verified accuracy, demonstrating strong
generalizability.

</details>


### [5] [EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint](https://arxiv.org/abs/2509.03058)
*Zhenhua Xu,Meng Han,Wenpeng Xing*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of large language models (LLMs) has intensified concerns
over model theft and license violations, necessitating robust and stealthy
ownership verification. Existing fingerprinting methods either require
impractical white-box access or introduce detectable statistical anomalies. We
propose EverTracer, a novel gray-box fingerprinting framework that ensures
stealthy and robust model provenance tracing. EverTracer is the first to
repurpose Membership Inference Attacks (MIAs) for defensive use, embedding
ownership signals via memorization instead of artificial trigger-output
overfitting. It consists of Fingerprint Injection, which fine-tunes the model
on any natural language data without detectable artifacts, and Verification,
which leverages calibrated probability variation signal to distinguish
fingerprinted models. This approach remains robust against adaptive
adversaries, including input level modification, and model-level modifications.
Extensive experiments across architectures demonstrate EverTracer's
state-of-the-art effectiveness, stealthness, and resilience, establishing it as
a practical solution for securing LLM intellectual property. Our code and data
are publicly available at https://github.com/Xuzhenhua55/EverTracer.

</details>


### [6] [Compressed verification for post-quantum signatures with long-term public keys](https://arxiv.org/abs/2509.03098)
*Gustavo Banegas,Ana√´lle Le D√©v√©hat,Benjamin Smith*

Main category: cs.CR

TL;DR: A novel method compresses large public keys in post-quantum signature schemes (e.g., Wave, Squirrels) by replacing them with compact private keys, achieving 94‚Äì97% storage reduction and faster verification.


<details>
  <summary>Details</summary>
Motivation: Long-lived public keys in post-quantum signature schemes often require large storage and slow verification, creating inefficiencies even when bandwidth is not constrained. This problem is critical for applications like root certificates and secure software updates, where key longevity is essential for long-term security.

Method: The paper proposes a method to replace large public keys with smaller, private verification keys in GPV-style signatures. This approach optimizes verifier storage and verification speed without compromising the security guarantees of the underlying lattice-based schemes.

Result: For the Squirrels-I scheme, public key size is reduced from 665 kB to 20.7 kB. For Wave822, the reduction is from 3.5 MB to 207.97 kB. These improvements preserve security against quantum attacks while enabling practical deployment in storage- and speed-sensitive scenarios.

Conclusion: The study introduces a technique to reduce the size of public keys in GPV-style post-quantum signature schemes by using smaller private verification keys, achieving significant storage and runtime improvements while maintaining security. Applied to Wave and Squirrels, it reduces key sizes by 97% and 94.3%, respectively.

Abstract: Many signature applications-such as root certificates, secure software
updates, and authentication protocols-involve long-lived public keys that are
transferred or installed once and then used for many verifications. This key
longevity makes post-quantum signature schemes with conservative assumptions
(e.g., structure-free lattices) attractive for long-term security. But many
such schemes, especially those with short signatures, suffer from extremely
large public keys. Even in scenarios where bandwidth is not a major concern,
large keys increase storage costs and slow down verification. We address this
with a method to replace large public keys in GPV-style signatures with
smaller, private verification keys. This significantly reduces verifier storage
and runtime while preserving security. Applied to the conservative,
short-signature schemes Wave and Squirrels, our method compresses Squirrels-I
keys from 665 kB to 20.7 kB and Wave822 keys from 3.5 MB to 207.97 kB.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems](https://arxiv.org/abs/2509.02860)
*Connor Wojtak,Darek Gajewski,Tomas Cerny*

Main category: cs.SE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Microservice systems are becoming increasingly adopted due to their
scalability, decentralized development, and support for continuous integration
and delivery (CI/CD). However, this decentralized development by separate teams
and continuous evolution can introduce miscommunication and incompatible
implementations, undermining system maintainability and reliability across
aspects from security policy to system architecture. We propose a novel
methodology that statically reconstructs microservice source code into a formal
system model. From this model, a Satisfiability Modulo Theories (SMT)
constraint set can be derived, enabling formal verification. Our methodology is
extensible, supporting software verification across multiple cross-cutting
concerns. We focus on applying the methodology to verify the system
architecture concern, presenting formal reasoning to validate the methodology's
correctness and applicability for this concern. Additional concerns such as
security policy implementation are considered. Future directions are
established to extend and evaluate the methodology.

</details>


### [8] [Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations](https://arxiv.org/abs/2509.03093)
*Fatih Pehlivan,Ar√ßin √úlk√º Erg√ºzen,Sahand Moslemi Yengejeh,Mayasah Lami,Anil Koyuncu*

Main category: cs.SE

TL;DR: This paper evaluates LLMs' ability to detect SOLID design principle violations through tailored prompts, demonstrating that optimal detection requires matching models and prompting strategies to specific design challenges, with GPT-4o Mini showing strongest but imperfect performance.


<details>
  <summary>Details</summary>
Motivation: Traditional static analysis methods inadequately detect semantic SOLID principle violations that require nuanced understanding of object-oriented design. Existing tools are limited by focusing on single principles or specific languages, creating a gap in analyzing multi-language codebases comprehensively.

Method: The method involves leveraging tailored prompt engineering to evaluate four leading LLMs (CodeLlama, DeepSeekCoder, QwenCoder, GPT-4o Mini) on their ability to detect SOLID violations. A new benchmark dataset of 240 manually validated code examples was used, testing four prompt strategies derived from zero-shot, few-shot, and chain-of-thought techniques.

Result: Results revealed a performance hierarchy among models (GPT-4o Mini leading) but all struggled with complex principles like DIP. Prompt strategies significantly impacted accuracy, with no universal best strategy ‚Äì e.g., ENSEMBLE excelled at OCP while EXAMPLE was best for DIP. Accuracy declined sharply with increasing code complexity.

Conclusion: The paper concludes that effective AI-driven design analysis requires a tailored approach combining the right LLMs with appropriate prompting strategies for specific design contexts, highlighting the potential of LLMs to improve maintainability through code analysis.

Abstract: Traditional static analysis methods struggle to detect semantic design flaws,
such as violations of the SOLID principles, which require a strong
understanding of object-oriented design patterns and principles. Existing
solutions typically focus on individual SOLID principles or specific
programming languages, leaving a gap in the ability to detect violations across
all five principles in multi-language codebases. This paper presents a new
approach: a methodology that leverages tailored prompt engineering to assess
LLMs on their ability to detect SOLID violations across multiple languages. We
present a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,
and GPT-4o Mini-on their ability to detect violations of all five SOLID
principles. For this evaluation, we construct a new benchmark dataset of 240
manually validated code examples. Using this dataset, we test four distinct
prompt strategies inspired by established zero-shot, few-shot, and
chain-of-thought techniques to systematically measure their impact on detection
accuracy. Our emerging results reveal a stark hierarchy among models, with
GPT-4o Mini decisively outperforming others, yet even struggles with
challenging principles like DIP. Crucially, we show that prompt strategy has a
dramatic impact, but no single strategy is universally best; for instance, a
deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE
prompt is superior for DIP violations. Across all experiments, detection
accuracy is heavily influenced by language characteristics and degrades sharply
with increasing code complexity. These initial findings demonstrate that
effective, AI-driven design analysis requires not a single best model, but a
tailored approach that matches the right model and prompt to the specific
design context, highlighting the potential of LLMs to support maintainability
through AI-assisted code analysis.

</details>
