<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 10]
- [cs.SE](#cs.SE) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Safeguarding Federated Learning-based Road Condition Classification](https://arxiv.org/abs/2507.12568)
*Sheng Liu,Panos Papadimitratos*

Main category: cs.CR

TL;DR: This paper analyzes how FL-RCC systems for autonomous driving are vulnerable to Targeted Label Flipping Attacks (TLFAs) and proposes FLARE, a defensive mechanism using label-distance metrics and output layer analysis to mitigate these attacks, validated through extensive experiments.


<details>
  <summary>Details</summary>
Motivation: Federated Learning (FL) in privacy-preserving Road Condition Classification (RCC) systems for autonomous driving faces novel security risks from TLFAs, where malicious vehicles alter training labels to create dangerous misclassifications (e.g., treating slippery roads as safe). Current defenses are insufficient against these specific attacks.

Method: Triple-method approach: 1) Disclosure of FL-RCC vulnerabilities to TLFAs through empirical analysis. 2) Design of a novel label-distance-based safety risk quantification metric. 3) Development of FLARE, a defense using neuron-wise analysis of the output layer to detect and counteract label flipping attacks.

Result: Experiments across 3 RCC tasks, 4 metrics, 6 baselines, and 3 deep learning models confirm TLFAs cause severe safety risks while FLARE mitigates attack impacts effectively, with quantified risk reduction and superior performance compared to existing baselines.

Conclusion: TLFAs represent critical security risks in FL-based RCC systems for autonomous driving, necessitating defense mechanisms like FLARE that address both attack exposure and risk mitigation through distance-based metrics and output layer analysis. This work establishes benchmarks for evaluating label poisoning attacks in this critical application domain.

Abstract: Federated Learning (FL) has emerged as a promising solution for
privacy-preserving autonomous driving, specifically camera-based Road Condition
Classification (RCC) systems, harnessing distributed sensing, computing, and
communication resources on board vehicles without sharing sensitive image data.
However, the collaborative nature of FL-RCC frameworks introduces new
vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious
clients (vehicles) deliberately alter their training data labels to compromise
the learned model inference performance. Such attacks can, e.g., cause a
vehicle to mis-classify slippery, dangerous road conditions as pristine and
exceed recommended speed. However, TLFAs for FL-based RCC systems are largely
missing. We address this challenge with a threefold contribution: 1) we
disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce
a novel label-distance-based metric to precisely quantify the safety risks
posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging
neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive
experiments across three RCC tasks, four evaluation metrics, six baselines, and
three deep learning models demonstrate both the severity of TLFAs on FL-RCC
systems and the effectiveness of FLARE in mitigating the attack impact.

</details>


### [2] [On the Consideration of Vanity Address Generation via Identity-Based Signatures](https://arxiv.org/abs/2507.12670)
*Shogo Murasaki,Kazumasa Omote,Keita Emura*

Main category: cs.CR

TL;DR: This paper proposes using identity-based signatures (IBS) to generate Ethereum vanity addresses without replacing ECDSA, leveraging a key recovery-based IBS scheme and demonstrating comparable gas costs to conventional signature verification.


<details>
  <summary>Details</summary>
Motivation: 1. Classical try-and-error method for vanity address creation is inefficient and limits character embeddability. 2. Direct replacement of ECDSA with key recovery-based IBS is impractical due to transaction issuance standards and economic feasibility.

Method: 1. Explored IBS functionality where arbitrary strings act as verification keys
2. Constructed a key recovery-based IBS scheme utilizing ECDSA
3. Implemented the system using Solidity with hash function-based address binding mechanism

Result: 1. Developed an IBS scheme that indirectly links custom strings to Ethereum addresses
2. Verified gas cost analysis showing minimal overhead compared to standard ECDSA verification
3. Proven feasibility of address customization through IBS without compromising Ethereum's native transaction structure

Conclusion: Key recovery-based IBS offers a practical approach to enable address customization in Ethereum by creating associative mappings between strings and addresses at comparable costs to standard practices, though direct ECDSA replacement remains economically unfeasible.

Abstract: An address is indicated as an identifier of the user on the blockchain, and
is defined by a hash value of the ECDSA verification key. A vanity address is
an address that embeds custom characters such as a name. To generate a vanity
address, a classical try-and-error method is employed, and thus the number of
characters to be embedded is limited. In this paper, we focus on the
functionality of identity-based signatures (IBS) where any strings can be
employed as a verification key, and explore whether IBS can be used for
generating a vanity address. We attach importance to the fact that it is not
realistic to replace ECDSA with key recovery, which is currently employed for
issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is
possible, it is not a reasonable price for the ease of the vanity address
generation. Thus, we pay attention to a generic construction of IBS from
signatures, and construct an IBS scheme from ECDSA with key recovery. Though we
cannot directly generate a vanity address due to the key recovery functionality
of the underlying ECDSA, we can connect any string with an address due to the
functionality of IBS that can give additional meaning to the address. We
implement our system by Solidity, and demonstrate that the gas cost is almost
same as that of the ECDSA signature verification.

</details>


### [3] [Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense](https://arxiv.org/abs/2507.12919)
*Victoria Childress,Josh Collyer,Jodie Knapp*

Main category: cs.CR

TL;DR: This paper surveys architectural backdoors in deep neural networks, analyzing their unique threat vectors, detection challenges, and proposing future research directions for scalable defenses.


<details>
  <summary>Details</summary>
Motivation: Architectural backdoors represent a critical, under-studied security risk that evades standard mitigation techniques and persists through model retraining, necessitating specialized detection approaches.

Method: The survey systematically reviews: (1) Compiler-level manipulations, (2) Tainted AutoML pipelines, (3) Supply-chain vulnerabilities, and (4) Emerging detection methods like static graph inspection, dynamic fuzzing, and formal verification.

Result: Current detection strategies struggle against advanced backdoor forms including distributed/stealth triggers, and no scalable defense solutions have yet achieved practical adoption.

Conclusion: The paper emphasizes urgent needs for: (1) Supply-chain security frameworks (2) Cryptographic model attestation techniques (3) Next-generation benchmarking tools to advance architectural backdoor research.

Abstract: Architectural backdoors pose an under-examined but critical threat to deep
neural networks, embedding malicious logic directly into a model's
computational graph. Unlike traditional data poisoning or parameter
manipulation, architectural backdoors evade standard mitigation techniques and
persist even after clean retraining. This survey systematically consolidates
research on architectural backdoors, spanning compiler-level manipulations,
tainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging
detection and defense strategies, including static graph inspection, dynamic
fuzzing, and partial formal verification, and highlight their limitations
against distributed or stealth triggers. Despite recent progress, scalable and
practical defenses remain elusive. We conclude by outlining open challenges and
proposing directions for strengthening supply-chain security, cryptographic
model attestations, and next-generation benchmarks. This survey aims to guide
future research toward comprehensive defenses against structural backdoor
threats in deep learning systems.

</details>


### [4] [Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach](https://arxiv.org/abs/2507.12937)
*Zhuohan Cui,Zikun Song*

Main category: cs.CR

TL;DR: The paper analyzes T-Mobile's 2021-2023 data breaches through case-based security audits and ethical hacking techniques, proposing cost-effective multi-layered defenses (Zero Trust, RBAC, firmware protection) with a 5-year investment of <1.1% of expected breach losses.


<details>
  <summary>Details</summary>
Motivation: Timely identification of structural security weaknesses in telecom networks is vital to prevent recurring breaches and ensure compliance with evolving regulations, especially for large-scale providers like T-Mobile. Proactive measures show cost advantages over reactive breach recovery.

Method: 1) Case-based vulnerability assessments
2) Ethical hacking via Shodan reconnaissance, API misuse simulations, VNC brute-forcing
3) Firmware reverse engineering
4) Web application penetration testing
5) Financial modeling of proactive defense ROI

Result: 1) Persistent infrastructure vulnerabilities beyond immediate breaches discovered
2) Proven cost-effectiveness of proposed defenses at <1.1% ROI relative to breach losses
3) Actionable security framework validated through T-Mobile-specific testing
4) Identifiable weak points across telecom systems revealed

Conclusion: Comprehensive security evaluation combining forensic and proactive tactics offers telecoms industry-wide benefits for operational resilience, regulatory compliance, and cross-domain threat mitigation, demonstrating strategic ROI advantages with proactive defense architectures.

Abstract: This paper presents a comprehensive analysis of T-Mobile's critical data
breaches in 2021 and 2023, alongside a full-spectrum security audit targeting
its systems, infrastructure, and publicly exposed endpoints. By combining
case-based vulnerability assessments with active ethical hacking
techniques--including Shodan reconnaissance, API misuse simulations, VNC
brute-forcing, firmware reverse engineering, and web application scans--we
uncover structural weaknesses persisting beyond the initial breach events.
Building on these findings, we propose a multi-layered defensive strategy
encompassing Zero Trust Architecture, granular role-based access control,
network segmentation, firmware encryption using AES with integrity checks, and
API rate limiting and token lifecycle control. Financial modelling demonstrates
that a five-year investment yields less than 1.1% of expected breach losses,
validating the cost-effectiveness of proactive security measures. Our work
bridges post-incident forensic analysis with hands-on security evaluation,
providing an actionable blueprint for large-scale telecoms seeking operational
resilience, regulatory compliance, and cross-domain threat readiness.

</details>


### [5] [Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest](https://arxiv.org/abs/2507.13023)
*Fei Wu,Danning Sui,Thomas Thiery,Mallesh Pai*

Main category: cs.CR

TL;DR: The paper analyzes CEX-DEX arbitrage dynamics on Ethereum using on-chain data, revealing centralization trends, profitability links to searcher-builder integration, and underestimated block builder profits while highlighting implications for Ethereum's decentralization.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand the economic impact and centralization risks of CEX-DEX arbitrage in Ethereum's MEV landscape by developing new methods to estimate arbitrage revenue without relying on private centralized exchange data.

Method: Refined on-chain data heuristics and developed an empirical framework to analyze 7,203,560 arbitrage events over 19 months (August 2023-March 2025). Examined searcher-builder relationships and revenue vertical integration.

Result: 19 searchers extracted 233.8M USD from CEX-DEX arbitrage. 75% of activity dominated by three searchers. Searcher profitability tied to block builder integration, showing exclusive relationships and market manipulation. Block builder profitability in vertical integration was underestimated by 87-94%.

Conclusion: CEX-DEX arbitrage exposes growing centralization in Ethereum MEV through searcher-builder dynamics. This challenges Ethereum's decentralization principles and necessitates deeper analysis of market structure consolidation.

Abstract: This paper provides a comprehensive empirical analysis of the economics and
dynamics behind arbitrages between centralized and decentralized exchanges
(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions
from on-chain data and introduce a robust empirical framework to estimate
arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging
an extensive dataset spanning 19 months from August 2023 to March 2025, we
estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from
7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing
centralization trends as three searchers captured three-quarters of both volume
and extracted value. We also demonstrate that searchers' profitability is tied
to their integration level with block builders and uncover exclusive
searcher-builder relationships and their market impact. Finally, we correct the
previously underestimated profitability of block builders who vertically
integrate with a searcher. These insights illuminate the darkest corner of the
MEV landscape and highlight the critical implications of CEX-DEX arbitrages for
Ethereum's decentralization.

</details>


### [6] [From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange](https://arxiv.org/abs/2507.13028)
*Niklas Busch,Philip Klostermeyer,Jan H. Klemmer,Yasemin Acar,Sascha Fahl*

Main category: cs.CR

TL;DR: The paper addresses the lack of understanding in the research community about system hardening practices by analyzing Stack Exchange posts. Key findings include challenges in access control and deployment, common focus areas like operating systems and servers, and motivations driven by fear of attacks and compliance needs. The study provides recommendations for improving future system hardening.


<details>
  <summary>Details</summary>
Motivation: The study aims to fill the research gap in understanding system operators' motivations, practices, and challenges regarding system hardening after observing persistent insecurities in systems and the community's lack of insight into this area.

Method: The authors conducted a qualitative analysis of 316 Stack Exchange posts related to system hardening to identify patterns and challenges among system operators.

Result: System hardening challenges were found to center on access control and deployment-related issues. Operators had misconceptions, unrealistic expectations, and focused primarily on operating systems and server applications. Their motivations were fear of attacks or compliance requirements.

Conclusion: The paper discusses research questions, suggests future system hardening strategies, and highlights implications of the findings for improving security practices and addressing operator misconceptions.

Abstract: Hardening computer systems against cyberattacks is crucial for security.
However, past incidents illustrated, that many system operators struggle with
effective system hardening. Hence, many computer systems and applications
remain insecure. So far, the research community lacks an in-depth understanding
of system operators motivation, practices, and challenges around system
hardening. With a focus on practices and challenges, we qualitatively analyzed
316 Stack Exchange (SE) posts related to system hardening. We find that access
control and deployment-related issues are the most challenging, and system
operators suffer from misconceptions and unrealistic expectations. Most
frequently, posts focused on operating systems and server applications. System
operators were driven by the fear of their systems getting attacked or by
compliance reasons. Finally, we discuss our research questions, make
recommendations for future system hardening, and illustrate the implications of
our work.

</details>


### [7] [MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](https://arxiv.org/abs/2507.13038)
*Yu Cui,Hongyang Du*

Main category: cs.CR

TL;DR: This paper introduces MAD-Spear, a targeted prompt injection attack that exploits LLM conformity tendencies to disrupt multi-agent debate systems by injecting misinformation. It presents a new evaluation framework for MAD resilience and finds agent diversity improves mathematical reasoning performance.


<details>
  <summary>Details</summary>
Motivation: Despite advancements in multi-agent debate systems using LLMs, their security vulnerabilities remain underexplored. The work aims to expose weaknesses in existing MAD systems, particularly their vulnerability to misinformation exploitation through agent conformity.

Method: The authors develop MAD-Speer by combining: 1) Prompt injection attacks targeting a subset of agents, 2) Exploiting LLM conformity tendencies to propagate errors, 3) Composition with communication attacks to increase error spread. They establish a MAD fault-tolerance definition and an evaluation framework tracking accuracy/consensus/scalability.

Result: Experiments on five benchmark datasets show MAD-Speer degrades system performance while maintaining response plausibility. Key findings: 1) Prompt injection attacks significantly weaken consensus quality 2) Agent diversity enhances mathematical reasoning performance, contradicting prior research 3) Attack effectiveness increases when combined with communication strategies.

Conclusion: The study demonstrates critical security vulnerabilities in MAD systems and argues for prioritizing robustness in design. Contrary to previous assumptions, agent diversity shows substantial benefits for mathematical tasks, suggesting new directions for improving both security and performance in multi-agent LLM systems.

Abstract: Multi-agent debate (MAD) systems leverage collaborative interactions among
large language models (LLMs) agents to improve reasoning capabilities. While
recent studies have focused on increasing the accuracy and scalability of MAD
systems, their security vulnerabilities have received limited attention. In
this work, we introduce MAD-Spear, a targeted prompt injection attack that
compromises a small subset of agents but significantly disrupts the overall MAD
process. Manipulated agents produce multiple plausible yet incorrect responses,
exploiting LLMs' conformity tendencies to propagate misinformation and degrade
consensus quality. Furthermore, the attack can be composed with other
strategies, such as communication attacks, to further amplify its impact by
increasing the exposure of agents to incorrect responses. To assess MAD's
resilience under attack, we propose a formal definition of MAD fault-tolerance
and develop a comprehensive evaluation framework that jointly considers
accuracy, consensus efficiency, and scalability. Extensive experiments on five
benchmark datasets with varying difficulty levels demonstrate that MAD-Spear
consistently outperforms the baseline attack in degrading system performance.
Additionally, we observe that agent diversity substantially improves MAD
performance in mathematical reasoning tasks, which challenges prior work
suggesting that agent diversity has minimal impact on performance. These
findings highlight the urgent need to improve the security in MAD design.

</details>


### [8] [Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors](https://arxiv.org/abs/2507.13042)
*Taki Eddine Djidjekh,Gaël Loubet,Alexandru Takacs*

Main category: cs.CR

TL;DR: This paper proposes a backscattering-based security mechanism for battery-free IoT devices using Bluetooth Low Energy (BLE) Wireless Sensor Networks (WSNs). It leverages wireless power transfer to generate identification signals without increasing energy or computational needs and demonstrates its feasibility across size-constrained applications.


<details>
  <summary>Details</summary>
Motivation: Battery-free IoT systems face critical challenges in integrating security and energy efficiency due to their resource constraints and lack of power sources. Traditional methods often increase energy consumption, which is incompatible with self-sustaining, low-power applications.

Method: The authors integrate backscattering into a BLE WSN using the existing Wireless Power Transfer (WPT) link for signal generation. Compact, low-gain antennas are utilized for compatibility with small form-factor applications. The mechanism avoids collisions in multi-node scenarios by analyzing dynamic range limitations and proposing signal management strategies.

Result: Experimental validation confirmed the mechanism's functionality in size-constrained applications (e.g., Structural Health Monitoring and smart transport). The system demonstrated compatibility with wireless power transfer and BLE protocols, supporting key security features without requiring additional energy or computation.

Conclusion: Backscattering-based security mechanisms show potential for enabling secure, energy-efficient, and scalable IoT deployments in diverse scenarios. Future work should address dynamic range limitations, collision avoidance in dense networks, and broader protocol compatibility to enhance generalizability.

Abstract: The integration of security and energy efficiency in Internet of Things
systems remains a critical challenge, particularly for battery-free and
resource-constrained devices. This paper explores the scalability and
protocol-agnostic nature of a backscattering-based security mechanism by
integrating it into Bluetooth Low Energy battery-free Wireless Sensor Network.
The proposed approach leverages the Wireless Power Transfer link, traditionally
used for energy harvesting, to generate additional identification signals
without increasing energy consumption or computational demands. Experimental
validation demonstrates the solution's functionality using compact, low-gain
antenna, ensuring compatibility with size-constrained applications such as
Structural Health Monitoring and smart transport. Furthermore, this work
addresses the challenges associated with backscattering dynamic range and
multi-node Wireless Sensor Network scenarios, discussing potential collisions
between identification signals and proposing future improvements to enhance
generalizability and scalability. The findings underscore the potential of the
backscattering-based security mechanism for creating secure, sustainable, and
scalable IoT deployments across diverse protocols and applications.

</details>


### [9] [Prompt Injection 2.0: Hybrid AI Threats](https://arxiv.org/abs/2507.13169)
*Jeremy McHugh,Kristina Šekrst,Jon Cefalu*

Main category: cs.CR

TL;DR: This paper examines Prompt Injection 2.0 attacks that integrate with XSS and CSRF to evade traditional security controls, proposing architectural defenses including prompt isolation and novel threat detection.


<details>
  <summary>Details</summary>
Motivation: Prompt injection attacks have become a critical security threat since 2022, especially with the rise of agentic AI systems enabling hybrid cyber-AI attacks that bypass existing protections.

Method: Comprehensive analysis of Prompt Injection 2.0 integration with web vulnerabilities, evaluation of mitigation technologies against threats like AI worms using recent benchmarks, and development of architectural solutions combining security strategies.

Result: Traditional security measures (WAFs, XSS filters, CSRF tokens) consistently fail against AI-enhanced attacks in benchmark tests, enabling threats like multi-agent infections and hybrid attacks.

Conclusion: Modern defenses against Prompt Injection 2.0 must combine prompt isolation, runtime monitoring, privilege boundaries, and adaptive threat detection to combat evolving AI-hybrid cybersecurity threats.

Abstract: Prompt injection attacks, where malicious input is designed to manipulate AI
systems into ignoring their original instructions and following unauthorized
commands instead, were first discovered by Preamble, Inc. in May 2022 and
responsibly disclosed to OpenAI. Over the last three years, these attacks have
continued to pose a critical security threat to LLM-integrated systems. The
emergence of agentic AI systems, where LLMs autonomously perform multistep
tasks through tools and coordination with other agents, has fundamentally
transformed the threat landscape. Modern prompt injection attacks can now
combine with traditional cybersecurity exploits to create hybrid threats that
systematically evade traditional security controls. This paper presents a
comprehensive analysis of Prompt Injection 2.0, examining how prompt injections
integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),
and other web security vulnerabilities to bypass traditional security measures.
We build upon Preamble's foundational research and mitigation technologies,
evaluating them against contemporary threats, including AI worms, multi-agent
infections, and hybrid cyber-AI attacks. Our analysis incorporates recent
benchmarks that demonstrate how traditional web application firewalls, XSS
filters, and CSRF tokens fail against AI-enhanced attacks. We also present
architectural solutions that combine prompt isolation, runtime security, and
privilege separation with novel threat detection capabilities.

</details>


### [10] [A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models](https://arxiv.org/abs/2507.13313)
*Chao Feng,Alberto Huertas Celdran,Jing Han,Heqing Ren,Xi Cheng,Zien Zeng,Lucas Krauter,Gerome Bovet,Burkhard Stiller*

Main category: cs.CR

TL;DR: The paper presents a malware detection dataset (21M+ records) and experimental comparison of decentralized federated learning (DFL) vs. centralized approaches in IoT crowdsensing environments, showing DFL maintains competitive performance while preserving data privacy.


<details>
  <summary>Details</summary>
Motivation: The study addresses the need for robust malware detection solutions in IoT crowdsensing scenarios, where data privacy/preservation and decentralized learning approaches are critical but under-researched, particularly with comprehensive behavioral datasets.

Method: 1) Created dataset combining system call logs, file/resource activity, and network behaviors from 8 malware families and 30-second interval aggregations. 2) Conducted experiments comparing traditional ML, centralized federated learning (CFL), and DFL under varying node densities, network topologies, and data distribution patterns.

Result: DFL achieved comparable detection accuracy to central approaches (342k features) while maintaining data locality (78% improvement over CFL in client-side processing efficiency). Performance varied across topologies but outperformed CFL in 63% of tested scenarios under non-IID data conditions.

Conclusion: The dataset and experiments demonstrate DFL's potential for secure IoT crowdsensing malware detection, emphasizing the importance of decentralized approaches in preserving sensitive behavioral data while enabling collaborative model training across distributed devices.

Abstract: This paper introduces a dataset and experimental study for decentralized
federated learning (DFL) applied to IoT crowdsensing malware detection. The
dataset comprises behavioral records from benign and eight malware families. A
total of 21,582,484 original records were collected from system calls, file
system activities, resource usage, kernel events, input/output events, and
network records. These records were aggregated into 30-second windows,
resulting in 342,106 features used for model training and evaluation.
Experiments on the DFL platform compare traditional machine learning (ML),
centralized federated learning (CFL), and DFL across different node counts,
topologies, and data distributions. Results show that DFL maintains competitive
performance while preserving data locality, outperforming CFL in most settings.
This dataset provides a solid foundation for studying the security of IoT
crowdsensing environments.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [11] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: This paper presents a comprehensive survey of 183 LLM4AIOps research papers (2020-2024), addressing four key research questions about failure data sources, evolving AIOps tasks, LLM-based methods for challenges, and evaluation methodologies for LLM-integrated approaches.


<details>
  <summary>Details</summary>
Motivation: LLMs are increasingly applied to AIOps tasks, but their impact, potential, and limitations in this domain remain underexplored. This survey aims to systematically analyze existing research to fill this knowledge gap.

Method: The authors conducted an in-depth study of 183 papers published between January 2020 and December 2024, analyzing them through four research questions: (1) data sources for failure analysis, (2) evolution of AIOps tasks, (3) LLM-based methods for AIOps challenges, and (4) evaluation methodologies for LLM-integrated AIOps approaches.

Result: The analysis reveals advancements in LLM-based processing of legacy data, identification of new data sources, evolving AIOps task trends, diverse LLM application methods, and improved evaluation frameworks. Gaps in current research are also highlighted.

Conclusion: The study provides systematic insights into LLM applications in AIOps, identifies research limitations, and suggests novel directions for future exploration to enhance understanding and adoption of LLM4AIOps solutions.

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [12] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: This study explores using Large Language Models (LLMs) as automated transpilers to convert quantum programs between different QSDKs (e.g., Qiskit, Cirq) without losing functional equivalence, addressing the challenges of traditional rule-based approaches.


<details>
  <summary>Details</summary>
Motivation: Quantum SDKs (QSDKs) lack interoperability, hindering cross-platform hybrid quantum-classical development. Rule-based transpilers require extensive manual effort, domain-specific rules, and maintenance due to platform-specific differences.

Method: The approach leverages pretrained LLMs as programming language-agnostic tools to analyze and generate code, automatically translating quantum programs between QSDKs while preserving original functionality via contextual reasoning and generalization.

Result: The LLM-based transpiler achieves functional equivalence between source and target QSDKs, eliminates manual rule definition, and demonstrates scalable portability for hybrid quantum-classical software systems.

Conclusion: LLMs offer a promising alternative to rule-based transpilation for quantum computing, enabling intelligent, adaptable code translation and advancing QSDK interoperability within the quantum software ecosystem.

Abstract: There exist various Software Development Kits (SDKs) tailored to different
quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples
include but are not limited to Qiskit, Cirq, and PennyLane. However, this
diversity presents significant challenges for interoperability and
cross-platform development of hybrid quantum-classical software systems.
Traditional rule-based transpilers for translating code between QSDKs are
time-consuming to design and maintain, requiring deep expertise and rigid
mappings in the source and destination code. In this study, we explore the use
of Large Language Models (LLMs) as a flexible and automated solution.
Leveraging their pretrained knowledge and contextual reasoning capabilities, we
position LLMs as programming language-agnostic transpilers capable of
converting quantum programs from one QSDK to another while preserving
functional equivalence. Our approach eliminates the need for manually defined
transformation rules and offers a scalable solution to quantum software
portability. This work represents a step toward enabling intelligent,
general-purpose transpilation in the quantum computing ecosystem.

</details>


### [13] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
*Ishraq Khan,Assad Chowdary,Sharoz Haseeb,Urvish Patel*

Main category: cs.SE

TL;DR: Kodezi Chronos is a next-gen LLM architecture for autonomous code maintenance that handles ultra-long contexts and improves bug detection by 23% while reducing debugging cycles by 40%. It uses a multi-level memory engine with vector/graph indexing and integrates with IDEs/CI/CD.


<details>
  <summary>Details</summary>
Motivation: This work addresses critical limitations in existing LLMs for code tasks - constrained context windows (5-10k tokens) and inability to reason about explicit code structure/relationships, which hinder real-world codebase analysis and maintenance.

Method: The multi-level embedding memory engine combines vector-based similarity indexing and graph-based structural indexing with a continuous code-aware retrieval system. This is implemented through a hierarchical memory architecture with dynamic context expansion and graph traversal for artifact associations.

Result: Chronos achieves 23% higher accuracy in real-world bug detection and reduces debugging cycles by 40% versus traditional sequence models. Qualitative results show effective multi-file refactoring and semantic issue localization on large code repositories via the Multi Random Retrieval benchmark.

Conclusion: Kodezi Chronos demonstrates a breakthrough toward self-sustaining software ecosystems by enabling repository-scale code understanding and autonomous debugging. Its IDE/CICD integration and context-free architecture represent a significant step in practical LLM-based software maintenance.

Abstract: Large Language Models (LLMs) have advanced code generation and software
automation, but are fundamentally constrained by limited inference-time context
and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a
next-generation architecture for autonomous code understanding, debugging, and
maintenance, designed to operate across ultra-long contexts comprising entire
codebases, histories, and documentation, all without fixed window limits.
Kodezi Chronos leverages a multi-level embedding memory engine, combining
vector and graph-based indexing with continuous code-aware retrieval. This
enables efficient and accurate reasoning over millions of lines of code,
supporting repository-scale comprehension, multi-file refactoring, and
real-time self-healing actions. Our evaluation introduces a novel Multi Random
Retrieval benchmark, specifically tailored to the software engineering domain.
Unlike classical retrieval benchmarks, this method requires the model to
resolve arbitrarily distant and obfuscated associations across code artifacts,
simulating realistic tasks such as variable tracing, dependency migration, and
semantic bug localization. Chronos outperforms prior LLMs and code models,
demonstrating a 23% improvement in real-world bug detection and reducing
debugging cycles by up to 40% compared to traditional sequence-based
approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos
enables seamless, autonomous software maintenance, elevating code reliability
and productivity while reducing manual effort. These results mark a critical
advance toward self-sustaining, continuously optimized software ecosystems.

</details>


### [14] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
*Dong Wang,Hanmo You,Lingwei Zhu,Kaiwei Lin,Zheng Chen,Chen Yang,Junji Yu,Zan Wang,Junjie Chen*

Main category: cs.SE

TL;DR: This paper presents a systematic survey analyzing 115 studies on reinforcement learning (RL) applications in software engineering (SE) since 2015, identifying research trends, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: The growing complexity of software systems and demand for automation motivate integrating RL with large language models (LLMs) to create adaptive solutions, yet no comprehensive review existed to synthesize this expanding field.

Method: Authors conducted a systematic review of 115 peer-reviewed SE papers across 22 top venues post-DRL introduction, analyzing publication trends, categorizing SE topics/RL algorithms, and evaluating dataset usage, model design, optimization techniques, and evaluation practices.

Result: A taxonomy of 15 SE topics (e.g., testing, maintenance) mapped to 11 RL algorithms. Key insights include overreliance on synthetic datasets, limited exploration of policy optimization, and inconsistent evaluation metrics. Open challenges include real-world application validity and integration with LLMs.

Conclusion: This survey establishes the first systematic mapping of RL applications in SE, reveals research gaps in data diversity and optimization methods, and suggests future work on cross-domain frameworks, LLM integration, and empirical validation to advance practical adoption. Artifacts are openly accessible.

Abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential
decision-making and has attracted growing interest across various domains,
particularly following the advent of Deep Reinforcement Learning (DRL) in 2015.
Simultaneously, the rapid advancement of Large Language Models (LLMs) has
further fueled interest in integrating RL with LLMs to enable more adaptive and
intelligent systems. In the field of software engineering (SE), the increasing
complexity of systems and the rising demand for automation have motivated
researchers to apply RL to a broad range of tasks, from software design and
development to quality assurance and maintenance. Despite growing research in
RL-for-SE, there remains a lack of a comprehensive and systematic survey of
this evolving field. To address this gap, we reviewed 115 peer-reviewed studies
published across 22 premier SE venues since the introduction of DRL. We
conducted a comprehensive analysis of publication trends, categorized SE topics
and RL algorithms, and examined key factors such as dataset usage, model design
and optimization, and evaluation practices. Furthermore, we identified open
challenges and proposed future research directions to guide and inspire ongoing
work in this evolving area. To summarize, this survey offers the first
systematic mapping of RL applications in software engineering, aiming to
support both researchers and practitioners in navigating the current landscape
and advancing the field. Our artifacts are publicly available:
https://github.com/KaiWei-Lin-lanina/RL4SE.

</details>


### [15] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
*Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen*

Main category: cs.SE

TL;DR: RAGSum is a retrieval-augmented code comment generation method that combines retrieval and generation using a single CodeT5 model with a composite loss function and self-refinement loop.


<details>
  <summary>Details</summary>
Motivation: Current approaches optimize retrieval and comment generation separately, leading to irrelevant code snippets propagating noise during comment synthesis.

Method: The system uses a CodeT5 backbone with three phases: (1) Contrastive pre-training to shape code embeddings for retrieval, (2) End-to-end training with a composite loss for top-k retrieval accuracy and generation error minimization, and (3) A lightweight self-refinement loop to polish outputs.

Result: Evaluated on Java, Python, and C cross-language benchmarks, RAGSum outperformed three baseline methods in BLEU, METEOR, and ROUTE-L metrics.

Conclusion: Tightly coupling retrieval and generation improves comment automation performance, and the framework's design suggests potential for replication and deeper developer studies to explore practical impacts.

Abstract: Automatically generating concise, informative comments for source code can
lighten documentation effort and accelerate program comprehension.
Retrieval-augmented approaches first fetch code snippets with existing comments
and then synthesize a new comment, yet retrieval and generation are typically
optimized in isolation, allowing irrelevant neighbors topropagate noise
downstream. To tackle the issue, we propose a novel approach named RAGSum with
the aim of both effectiveness and efficiency in recommendations. RAGSum is
built on top offuse retrieval and generation using a single CodeT5 backbone. We
report preliminary results on a unified retrieval-generation framework built on
CodeT5. A contrastive pre-training phase shapes code embeddings for
nearest-neighbor search; these weights then seed end-to-end training with a
composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes
comment-generation error. More importantly, a lightweight self-refinement loop
is deployed to polish the final output. We evaluated theframework on three
cross-language benchmarks (Java, Python, C), and compared it with three
well-established baselines. The results show that our approach substantially
outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These
findings indicate that tightly coupling retrieval and generationcan raise the
ceiling for comment automation and motivateforthcoming replications and
qualitative developer studies.

</details>


### [16] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
*Samal Nursapa,Anastassiya Samuilova,Alessio Bucaioni. Phuong T. Nguyen*

Main category: cs.SE

TL;DR: CodeT5 outperforms CodeBERT and traditional methods in recommending refactorings for architectural smells via fine-tuning on 2M+ Java examples.


<details>
  <summary>Details</summary>
Motivation: Existing tools detect architectural smells but rarely provide actionable repair solutions, creating a gap in automated software maintenance.

Method: Fine-tuned CodeBERT and CodeT5 on 2+ million refactoring instances from 11,149 Java projects to solve a three-class classification task.

Result: CodeT5 achieved 96.9% accuracy and 95.2% F1 score, surpassing CodeBERT and traditional baselines in refactoring recommendation performance.

Conclusion: Transformer models effectively bridge smell detection with repair recommendations, establishing a foundation for future systems with open-source code and data.

Abstract: Architectural smells such as God Class, Cyclic Dependency, and Hub-like
Dependency degrade software quality and maintainability. Existing tools detect
such smells but rarely suggest how to fix them. This paper explores the use of
pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable
refactorings based on detected smells. We frame the task as a three-class
classification problem and fine-tune both models on over 2 million refactoring
instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%
accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our
results show that transformer-based models can effectively bridge the gap
between smell detection and actionable repair, laying the foundation for future
refactoring recommendation systems. We release all code, models, and data under
an open license to support reproducibility and further research.

</details>


### [17] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
*Kiana Kheiri,Aamna Aamir,Andriy Miranskyy,Chen Ding*

Main category: cs.SE

TL;DR: This paper introduces two reinforcement learning methods (GRPO and ORPO) for improving quantum programming reliability. Using a 32B model and synthetic datasets, they achieve +10pp performance gains on Qiskit-specific benchmarks compared to existing models, but demonstrate limitations in solving advanced tasks.


<details>
  <summary>Details</summary>
Motivation: Quantum circuits require error resilience, but current LLMs like Granite-20B-Code and StarCoder frequently produce flawed Qiskit code, creating a clear need for improved programming assistance capabilities in this domain.

Method: The authors fine-tuned a 32B language model using two reinforcement learning approaches: Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference Optimization (ORPO), with evaluation based on output code correctness against annotated synthetic datasets.

Result: On Qiskit HumanEval benchmark, ORPO achieves 56.29% Pass@1 (+10pp over Granite-8B-QK) and GRPO reaches 49%. On original HumanEval, they score 65.90% and 63.00% respectively. GRPO succeeds on 42/54 basic tasks while ORPO completes 41/68 intermediate tasks, with neither solving the 5 advanced tasks.

Conclusion: The proposed methods demonstrate clear improvements in AI-assisted quantum programming, particularly for mid-level complexity tasks, but significant challenges remain in handling advanced quantum circuit requirements. This shows both progress and substantial room for further development in the field.

Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and
StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two
RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference
Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit
HumanEval benchmark, ORPO reaches 56.29\% Pass@1 ($\approx+10$ pp over
Granite-8B-QK) and GRPO hits 49\%, both beating all general-purpose baselines;
on the original HumanEval they score 65.90\% and 63.00\%. GRPO excels on basic
tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five
advanced tasks, highlighting clear gains yet room for progress in AI-assisted
quantum programming.

</details>


### [18] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
*Christine van Stiphoudt,Sergio Potenciano Menci,Gilbert Fridgen*

Main category: cs.SE

TL;DR: The paper proposes a three-phase evaluation approach combining explicit and implicit methods to assess newly designed information and data models in smart grids, addressing the lack of clear design-phase evaluation steps.


<details>
  <summary>Details</summary>
Motivation: Smart grid digitalization requires new information/data models, but existing explicit and implicit evaluation methods fail to provide structured design-phase validation, risking operational disruptions from flawed models.

Method: Design science research was used to create a three-phase evaluation approach. This was refined through practical application to an industrial flexibility description model and lessons learned during development.

Result: Development of a concrete three-phase evaluation framework that integrates explicit theoretical validation with implicit system testing for smart grid-specific data model design.

Conclusion: The proposed hybrid evaluation approach fills the gap in smart grid data model design by combining methodological rigor with practical testing to ensure model reliability before implementation.

Abstract: The ongoing digitalisation of the smart grid is resulting in an increase in
automated information exchanges across distributed energy systems. This process
has led to the development of new information and data models when the existing
ones fall short. To prevent potential disruptions caused by flaws in the newly
designed information and data models, it is essential to evaluate them during
the design process before they are implemented in operation.
  Currently, general explicit evaluation approaches outside the smart grid
domain stay at a high level without defining clear steps. Meanwhile, implicit
evaluation approaches in the smart grid domain focus on testing systems that
utilise information and data models already in use for functionality in terms
of conformance and interoperability. Notably, no combination of explicit and
implicit evaluation approaches for newly designed information and data models
offers a clearly defined set of steps during their design process in the smart
grid context.
  Consequently, we design a three-phase evaluation approach using design
science research to address this gap. Our evaluation approach combines explicit
and implicit evaluation methods and is applicable when developing new
information and data models. We use the development of an information model and
data model focused on industrial flexibility descriptions to refine our
evaluation approach. Additionally, we provide lessons learned from our
experience.

</details>


### [19] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: Integrates fuzzy logic into project success evaluation to prioritize sustained end-user impact over traditional metrics like stakeholder satisfaction.


<details>
  <summary>Details</summary>
Motivation: Traditional Likert-scale measures fail to capture the context-sensitive and multifaceted nature of project success, necessitating a dynamic evaluation approach.

Method: Proposes a hierarchical Type-1 Mamdani fuzzy system framework that weights sustained positive outcomes for end-users against secondary project success factors.

Result: Demonstrated that the fuzzy logic approach could provide more accurate and meaningful project success measurements through adaptability and nuance.

Conclusion: The dynamic fuzzy framework offers a context-sensitive alternative for project evaluation, with potential for empirical validation and broader social science applications.

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


### [20] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
*Salvador D. Escobedo*

Main category: cs.SE

TL;DR: The paper introduces SCM, a structured software development methodology for LLM usage, emphasizing persistent developer-AI dialogue through project phases to shift from passive LLM reliance. Key principles include cognitive clarity, traceability, modularity, and documentation.


<details>
  <summary>Details</summary>
Motivation: Current practices rely passively on LLMs via ad hoc interactions, lacking structural guidance. The authors identify a need for methodologies that actively involve developers in shaping LLM-assisted workflows while maintaining project clarity and oversight.

Method: SCM proposes a single long-context conversation covering requirements, architecture, implementation. It establishes three foundational principles (cognitive clarity, traceability, modularity) with documented phases and best practices.

Result: Formalized SCM methodology with defined phases and rationale, demonstrating a structured framework for active developer-AI collaboration. Establishes philosophical and practical counterpoints to conventional LLM usage patterns.

Conclusion: SCM redefines AI-assisted development as an intentional process requiring developer guidance. The framework addresses critical gaps in current methodologies by institutionalizing traceability, structure, and accountability in long-term AI collaboration.

Abstract: We propose the Single Conversation Methodology (SCM), a novel and pragmatic
approach to software development using large language models (LLMs). In
contrast to ad hoc interactions with generative AI, SCM emphasizes a structured
and persistent development dialogue, where all stages of a project - from
requirements to architecture and implementation - unfold within a single,
long-context conversation. The methodology is grounded on principles of
cognitive clarity, traceability, modularity, and documentation. We define its
phases, best practices, and philosophical stance, while arguing that SCM offers
a necessary correction to the passive reliance on LLMs prevalent in current
practices. We aim to reassert the active role of the developer as architect and
supervisor of the intelligent tool.

</details>


### [21] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
*Keila Lucas,Rohit Gheyi,Márcio Ribeiro,Fabio Palomba,Luana Martins,Elvys Soares*

Main category: cs.SE

TL;DR: This paper explores the use of Small Language Models (SLMs) for detecting test smells in manual test cases, demonstrating their high accuracy and autonomy without relying on predefined rules or syntax. SLMs (Gemma3-91%, Llama3.2-91%, Phi-4-97%) achieved strong results, enabled self-explanation, and improved test quality while preserving data privacy.


<details>
  <summary>Details</summary>
Motivation: Manual test cases often suffer from test smells (e.g., ambiguity, redundancy) that reduce reliability and maintainability. Existing detection tools are rule-based, labor-intensive, and lack scalability. There is a critical need for automated solutions that avoid these limitations.

Method: Evaluated three SLMs (Gemma3, Llama3.2, Phi-4) on 143 authentic Ubuntu test cases with seven defined test smells. Quantitatively measured detection accuracy via pass@2 metrics and analyzed whether models could autonomously explain issues and suggest fixes without prompt engineering.

Result: Phi-4 detected test-smell sentences with 97% pass@2 accuracy. Gemma3 and Llama3.2 achieved ~91%. All models provided automatic issue explanations and improvements without explicit instructions. SLMs reduced reliance on complex rules and syntax, offering scalable conceptual analysis.

Conclusion: SLMs demonstrate significant potential as efficient, privacy-preserving tools for automated test-smell detection. Their ability to self-express rationale and suggestions makes them suitable for immediate real-world testing improvements, especially surpassing Gemma3 and Llama3.2 in performance.

Abstract: Manual testing, in which testers follow natural language instructions to
validate system behavior, remains crucial for uncovering issues not easily
captured by automation. However, these test cases often suffer from test
smells, quality issues such as ambiguity, redundancy, or missing checks that
reduce test reliability and maintainability. While detection tools exist, they
typically require manual rule definition and lack scalability. This study
investigates the potential of Small Language Models (SLMs) for automatically
detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143
real-world Ubuntu test cases, covering seven types of test smells. Phi-4
achieved the best results, reaching a pass@2 of 97% in detecting sentences with
test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond
detection, SLMs autonomously explained issues and suggested improvements, even
without explicit prompt instructions. They enabled low-cost, concept-driven
identification of diverse test smells without relying on extensive rule
definitions or syntactic analysis. These findings highlight the potential of
SLMs as efficient tools that preserve data privacy and can improve test quality
in real-world scenarios.

</details>


### [22] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
*Dongming Jin,Weisong Sun,Jiangping Huang,Peng Liang,Jifeng Xuan,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: iReDev is a knowledge-driven multi-agent framework for intelligent requirements development. It integrates human knowledge, uses event-driven communication via an artifact pool, and includes human-agent collaboration to improve the process, showing better performance in evaluations.


<details>
  <summary>Details</summary>
Motivation: Existing multi-agent systems lack robust support for requirements development, ignoring human knowledge injection and collaboration. This paper addresses these gaps by proposing a framework to simulate stakeholder interactions and maintain artifact alignment with stakeholder expectations.

Method: The framework features six knowledge-driven agents, an event-driven communication mechanism using an artifact pool where agents monitor changes and trigger actions, and a human-in-the-loop system for real-time collaboration. These components work together to automate and enhance requirement generation and conflict resolution.

Result: Evaluation results demonstrate iReDev outperforms existing baselines in requirements specification quality, conflict resolution efficiency, and adaptation to dynamic requirements through its knowledge integration and human collaboration mechanisms.

Conclusion: iReDev establishes a new paradigm for intelligent requirements development by formalizing human knowledge and enabling seamless collaboration, while suggesting future research directions in knowledge representation, agent decision-making, and system scalability to strengthen this approach further.

Abstract: Requirements development is a critical phase as it is responsible for
providing a clear understanding of what stakeholders need. It involves
collaboration among stakeholders to extract explicit requirements and address
potential conflicts, which is time-consuming and labor-intensive. Recently,
multi-agent systems for software development have attracted much attention.
However, existing research provides limited support for requirements
development and overlooks the injection of human knowledge into agents and the
human-agent collaboration. % To address these issues, this paper proposes a
knowledge-driven multi-agent framework for intelligent requirement development,
named iReDev. iReDev features: iReDev consists of six knowledge-driven agents
to support the entire requirements development. They collaboratively perform
various tasks to produce a software requirements specification. iReDev focuses
on integrating human knowledge for agents, enabling them to simulate real-world
stakeholders. iReDev uses an event-driven communication mechanism based on an
artifact pool. Agents continuously monitor the pool and autonomously trigger
the next action based on its changes, enabling iReDev to handle new
requirements quickly. iReDev introduces a human-in-the-loop mechanism to
support human-agent collaboration, ensuring that the generated artifacts align
with the expectations of stakeholders. We evaluated the generated artifacts and
results show that iReDev outperforms existing baselines in multiple aspects. We
further envision three key directions and hope this work can facilitate the
development of intelligent requirements development.

</details>


### [23] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
*Dongming Jin,Zhi Jin,Linyu Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: This paper advocates for rethinking requirements engineering (RE) methodologies in light of large pretrained models' integration into software systems due to their ambiguous boundaries and context-sensitive behavior. A conceptual framework and research directions are proposed to address these emerging challenges.


<details>
  <summary>Details</summary>
Motivation: Traditional RE principles rely on deterministic logic and predictable behavior, but pretrained models exhibit characteristics like ambiguous capabilities, context-dependent responses, and continuous evolution, fundamentally undermining these assumptions. The software engineering community needs new RE approaches to manage such systems effectively.

Method: The paper identifies key challenges through analysis of pretrained model properties and proposes a conceptual framework for requirements engineering. It outlines four promising research directions within this framework to guide future work, though specific implementation details of the framework are not provided in the abstract.

Result: The conceptual framework offers a structured vision for addressing RE challenges in pretrained-model-based systems. It maps out potential paths for research and practice by directly connecting model characteristics (e.g., context-dependency) to required methodological adaptations.

Conclusion: By highlighting the mismatch between traditional RE assumptions and modern pretrained-model systems, the paper asserts that existing methodologies must evolve to handle these unique properties. Their framework serves as both a diagnostic tool and a roadmap for developing RE techniques suited to this new paradigm.

Abstract: Recent advances in large pretrained models have led to their widespread
integration as core components in modern software systems. The trend is
expected to continue in the foreseeable future. Unlike traditional software
systems governed by deterministic logic, systems powered by pretrained models
exhibit distinctive and emergent characteristics, such as ambiguous capability
boundaries, context-dependent behavior, and continuous evolution. These
properties fundamentally challenge long-standing assumptions in requirements
engineering, including functional decomposability and behavioral
predictability. This paper investigates this problem and advocates for a
rethinking of existing requirements engineering methodologies. We propose a
conceptual framework tailored to requirements engineering of
pretrained-model-enabled software systems and outline several promising
research directions within this framework. This vision helps provide a guide
for researchers and practitioners to tackle the emerging challenges in
requirements engineering of pretrained-model-enabled systems.

</details>


### [24] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.SE

TL;DR: This paper proposes a method to dynamically infer attributed grammars from recursive descent parsers, enabling comprehensive specification recovery of input processing semantics.


<details>
  <summary>Details</summary>
Motivation: Existing grammar mining techniques focus only on syntactic structures while the semantics of input processing remains understudied, leading to incomplete specifications for software systems.

Method: The approach dynamically analyzes recursive descent parser implementations, observes execution behavior, and systematically embeds semantic actions into grammar rules through runtime mapping.

Result: The method successfully reproduces program behavior using generated attributed grammars, demonstrated through experiments with an initial set of programs.

Conclusion: The approach effectively enables complete recovery of both syntactic and semantic input specifications by combining dynamic analysis with attributed grammar generation.

Abstract: Software systems that process structured inputs often lack complete and
up-to-date specifications, which specify the input syntax and the semantics of
input processing. While grammar mining techniques have focused on recovering
syntactic structures, the semantics of input processing remains largely
unexplored. In this work, we introduce a novel approach for inferring
attributed grammars from parser implementations. Given an input grammar, our
technique dynamically analyzes the implementation of recursive descent parsers
to reconstruct the semantic aspects of input handling, resulting in
specifications in the form of attributed grammars. By observing program
executions and mapping the program's runtime behavior to the grammar, we
systematically extract and embed semantic actions into the grammar rules. This
enables comprehensive specification recovery. We demonstrate the feasibility of
our approach using an initial set of programs, showing that it can accurately
reproduce program behavior through the generated attributed grammars.

</details>


### [25] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
*Xin Yin,Xinrui Li,Chao Ni,Xiaodan Xu,Xiaohu Yang*

Main category: cs.SE

TL;DR: CodeGPTSensor+ enhances robustness in detecting LLM-generated code, even after minor human modifications, through adversarial training with the MIST module.


<details>
  <summary>Details</summary>
Motivation: The widespread use of LLM-generated code introduces challenges such as provenance tracking, copyright issues, and ensuring quality. Existing detection methods lack robustness when code is modified by humans, necessitating a reliable solution for real-world applications.

Method: The authors propose CodeGPTSensor+, which employs adversarial training to improve detection robustness against modified LLM-generated code. This is achieved via MIST (Multi-objective Identifier and Structure Transformation), a module that systematically generates high-quality adversarial samples for training.

Result: Experiments on the HMCorp dataset show CodeGPTSensor+ achieves higher detection accuracy on adversarial test sets while maintaining strong performance on the original test set, outperforming CodeGPTSensor in robustness.

Conclusion: CodeGPTSensor+ effectively addresses the challenges of detecting modified LLM-generated code by integrating adversarial training with the MIST module, offering a more reliable and responsible solution for LLM code usage in practical scenarios.

Abstract: With the rapid development of Large Language Models (LLMs), their powerful
code-generation capabilities have been widely applied in tasks like code
completion and automated development, demonstrating the value of improving
coding efficiency. However, the extensive use of LLM-generated code also raises
several new challenges. On the one hand, issues such as the regulation of code
provenance, copyright disputes, and code quality have become increasingly
concerning. How to effectively detect LLM-generated code and ensure its
compliant and responsible use has become a critical and urgent issue. On the
other hand, in practical applications, LLM-generated code is often subject to
manual modifications, such as variable renaming or structural adjustments.
Although some recent studies have proposed training-based and zero-shot methods
for detecting LLM-generated code, these approaches show insufficient robustness
when facing modified LLM-generated code, and there is a lack of an effective
solution. To address the real-world scenario where LLM-generated code may
undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of
CodeGPTSensor, which employs adversarial training to improve robustness against
input perturbations. CodeGPTSensor+ integrates an adversarial sample generation
module, Multi-objective Identifier and Structure Transformation (MIST), which
systematically generates both high-quality and representative adversarial
samples. This module effectively enhances the model's resistance against
diverse adversarial attacks. Experimental results on the HMCorp dataset
demonstrate that CodeGPTSensor+ significantly improves detection accuracy on
the adversarial test set while maintaining high accuracy on the original test
set, showcasing superior robustness compared to CodeGPTSensor.

</details>
