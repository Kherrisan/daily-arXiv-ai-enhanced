{"id": "2510.02387", "categories": ["cs.SE", "cs.AI", "cs.LG", "68T07", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.02387", "abs": "https://arxiv.org/abs/2510.02387", "authors": ["FAIR CodeGen team", "Quentin Carbonneaux", "Gal Cohen", "Jonas Gehring", "Jacob Kahn", "Jannik Kossen", "Felix Kreuk", "Emily McMilin", "Michel Meyer", "Yuxiang Wei", "David Zhang", "Kunhao Zheng", "Jordi Armengol-Estap\u00e9", "Pedram Bashiri", "Maximilian Beck", "Pierre Chambon", "Abhishek Charnalia", "Chris Cummins", "Juliette Decugis", "Zacharias V. Fisches", "Fran\u00e7ois Fleuret", "Fabian Gloeckle", "Alex Gu", "Michael Hassid", "Daniel Haziza", "Badr Youbi Idrissi", "Christian Keller", "Rahul Kindi", "Hugh Leather", "Gallil Maimon", "Aram Markosyan", "Francisco Massa", "Pierre-Emmanuel Mazar\u00e9", "Vegard Mella", "Naila Murray", "Keyur Muzumdar", "Peter O'Hearn", "Matteo Pagliardini", "Dmitrii Pedchenko", "Tal Remez", "Volker Seeker", "Marco Selvi", "Oren Sultan", "Sida Wang", "Luca Wehrstedt", "Ori Yoran", "Lingming Zhang", "Taco Cohen", "Yossi Adi", "Gabriel Synnaeve"], "title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "comment": "58 pages", "summary": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,\nto advance research on code generation with world models. To improve code\nunderstanding beyond what can be learned from training on static code alone, we\nmid-train CWM on a large amount of observation-action trajectories from Python\ninterpreter and agentic Docker environments, and perform extensive multi-task\nreasoning RL in verifiable coding, math, and multi-turn software engineering\nenvironments. With CWM, we provide a strong testbed for researchers to explore\nthe opportunities world modeling affords for improving code generation with\nreasoning and planning in computational environments. We present first steps of\nhow world models can benefit agentic coding, enable step-by-step simulation of\nPython code execution, and show early results of how reasoning can benefit from\nthe latter. CWM is a dense, decoder-only LLM trained with a context size of up\nto 131k tokens. Independent of its world modeling capabilities, CWM offers\nstrong performance on general coding and math tasks: it reaches pass@1 scores\nof 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on\nLiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further\nresearch on code world modeling, we release model checkpoints after\nmid-training, SFT, and RL.", "AI": {"tldr": "The paper introduces Code World Model (CWM), a 32B-parameter open-weights LLM trained with world modeling and multi-task RL to improve code generation. It achieves strong results in coding/math benchmarks and releases model checkpoints for research.", "motivation": "Static code training alone limits code understanding. The authors aim to advance research by integrating dynamic environments (e.g., Python interpreter, Docker agents) and reasoning planning via world modeling.", "method": "CWM is mid-trained on 131k-token-sized observation-action trajectories from computational environments. Multi-task reinforcement learning is applied across verifiable coding, math, and software engineering. The model is a dense decoder-only architecture.", "result": "Achieves 65.8%\u202fSWE-bench Verified, 68.6%\u202fLiveCodeBench, 96.6%\u202fMath-500, 76.0%\u202fAIME 2024. Demonstrates early step-by-step Python simulation and reasoning benefits.", "conclusion": "Provides a research testbed for world modeling in code generation. Releases model checkpoints (mid-training/SFT/RL). Shows world modeling enhances reasoning/planning in computational environments."}}
{"id": "2510.02389", "categories": ["cs.SE", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02389", "abs": "https://arxiv.org/abs/2510.02389", "authors": ["Haoran Xi", "Minghao Shao", "Brendan Dolan-Gavitt", "Muhammad Shafique", "Ramesh Karri"], "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "comment": null, "summary": "Large language models show promise for vulnerability discovery, yet\nprevailing methods inspect code in isolation, struggle with long contexts, and\nfocus on coarse function- or file-level detections - offering limited\nactionable guidance to engineers who need precise line-level localization and\ntargeted patches in real-world software development. We present T2L-Agent\n(Trace-to-Line Agent), a project-level, end-to-end framework that plans its own\nanalysis and progressively narrows scope from modules to exact vulnerable\nlines. T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer\n(ATA) that fuses runtime evidence - crash points, stack traces, and coverage\ndeltas - with AST-based code chunking, enabling iterative refinement beyond\nsingle pass predictions and translating symptoms into actionable, line-level\ndiagnoses. To benchmark line-level vulnerability discovery, we introduce\nT2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash\nfamilies and real-world projects. T2L-ARVO is specifically designed to support\nboth coarse-grained detection and fine-grained localization, enabling rigorous\nevaluation of systems that aim to move beyond file-level predictions. On\nT2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level\nlocalization, substantially outperforming baselines. Together, the framework\nand benchmark push LLM-based vulnerability detection from coarse identification\ntoward deployable, robust, precision diagnostics that reduce noise and\naccelerate patching in open-source software workflows.", "AI": {"tldr": "This paper introduces T2L-Agent and T2L-ARVO for improved line-level vulnerability discovery in software projects.", "motivation": "This research addresses the challenge of achieving accurate, line-level vulnerability detection with prevailing methods that inspect code in isolation, struggle with long contexts, and offer limited actionable guidance for engineers.", "method": "The paper presents T2L-Agent, an end-to-end framework that progressively narrows analysis scope from modules to specific vulnerable lines using multi-round feedback and an Agentic Trace Analyzer (ATA). This couples runtime evidence (crash points, stack traces, coverage deltas) with AST-based code chunking. They also introduce T2L-ARVO, a benchmark for evaluating line-level vulnerability discovery that includes diverse, expert-verified crash cases from real-world projects.", "result": "On the T2L-ARVO benchmark, T2L-Agent achieves up to 58.0% detection and 54.8% line-level localization rates, which is a substantial improvement over baseline methods.", "conclusion": "T2L-Agent and T2L-ARVO advance LLM-based vulnerability detection from coarse identification to deployable, precise diagnostics that reduce noise and accelerate patching in open-source software workflows."}}
{"id": "2510.02393", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02393", "abs": "https://arxiv.org/abs/2510.02393", "authors": ["Jianqing Zhang", "Wei Xia", "Hande Dong", "Qiang Lin", "Jian Cao"], "title": "AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization", "comment": null, "summary": "LLMs' code generation capabilities have yielded substantial improvements in\nthe effectiveness of programming tasks. However, LLM-generated code still\nsuffers from compilation and runtime errors. Existing offline preference\noptimization methods primarily focus on enhancing LLMs' coding abilities using\npass/fail signals in the preference data, overlooking the deep-level error\ntypes in the failed codes. To address this, we propose Adaptively Progressive\nPreference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that\nguides LLMs adaptively and methodically to reduce code errors for code\ngeneration. Specifically, we construct an error notebook from failed codes and\nprogressively optimize the LLM to correct errors type by type. Furthermore, we\nadaptively replay error types to tailor to the LLM's changing weaknesses\nthroughout the training process. Through extensive experiments on both code and\ngeneral LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from\n0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in\npass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O", "AI": {"tldr": "AP2O-Coder improves LLM code generation by systematically addressing deep-level code errors through progressive optimization and adaptive error replay, achieving 3% better performance with less training data", "motivation": "Despite advancements in LLM coding capabilities, generated code still has compilation/runtime errors. Existing preference optimization methods rely on pass/fail signals and ignore detailed error types, necessitating a more refined error-aware optimization approach.", "method": "AP2O-Coder constructs an error notebook from failed codes and employs progressive optimization to address error types systematically. It also adaptively replays error types during training to respond to the model's evolving weaknesses.", "result": "Experiments on Llama, Qwen, and DeepSeek models (0.5B-34B parameters) demonstrate up to 3% improvements in pass@k metrics with reduced preference data requirements compared to prior methods.", "conclusion": "The study presents AP2O-Coder, an adaptively progressive preference optimization method that systematically improves LLM-generated code by addressing error types through progressive optimization and adaptive replay. This results in a 3% improvement in code generation performance (pass@k) across multiple LLM architectures while using less preference data."}}
{"id": "2510.02404", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02404", "abs": "https://arxiv.org/abs/2510.02404", "authors": ["Siddharth Agarwal", "Maria A. Rodriguez", "Rajkumar Buyya"], "title": "Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions", "comment": "34 pages, 2 figures, 2 tables, journal", "summary": "The serverless cloud computing model offers a framework where the service\nprovider abstracts the underlying infrastructure management from developers. In\nthis serverless model, FaaS provides an event-driven, function-oriented\ncomputing service characterised by fine-grained, usage-based pricing that\neliminates cost for idle resources. Platforms like AWS Lambda, Azure Functions,\nand Cloud Run Functions require developers to configure their function(s) with\nminimum operational resources for its successful execution. This resource\nallocation influences both the operational expense and the performance quality\nof these functions. However, a noticeable lack of platform transparency forces\ndevelopers to rely on expert knowledge or experience-based ad-hoc decisions to\nrequest desired function resources. This makes optimal resource configuration a\nnon-trivial task while adhering to performance constraints. Furthermore, while\ncommercial platforms often scale resources like CPU and network bandwidth\nproportional to memory, open-source frameworks permit independent configuration\nof function resources, introducing additional complexity for developers aiming\nto optimise their functions. These complexities have directed researchers to\nresolve developer challenges and advance towards an efficient server-less\nexecution model. In this article, we identify different aspects of resource\nconfiguration techniques in FaaS settings and propose a taxonomy of factors\nthat influence function design, configuration, run-time cost, and performance\nguarantees. We conduct an analysis of existing literature on resource\nconfiguration to present a comprehensive review of current studies on function\nconfiguration. We also identify existing research gaps and suggest future\nresearch directions to enhance function configuration and strengthen the\ncapabilities of serverless computing environments to drive its broader\nadoption.", "AI": {"tldr": "This paper addresses challenges in Function-as-a-Service (FaaS) resource configuration by proposing a taxonomy of factors influencing design, cost, and performance, while identifying research gaps and future directions to optimize serverless computing environments.", "motivation": "The serverless model's lack of platform transparency forces developers to make ad-hoc resource configuration decisions, impacting cost and performance. Commercial platforms further complicate optimization by scaling resources proportionally, while open frameworks allow independent configuration but increase complexity. This hinders efficient function execution and broader serverless adoption.", "method": "The authors analyze existing literature on FaaS resource configuration, categorizing factors that affect function design, configuration, operational costs, and performance guarantees. They synthesize findings to identify patterns and gaps in current research.", "result": "A comprehensive taxonomy of resource configuration factors is proposed, supported by a literature review that highlights existing solutions and unresolved challenges. Research gaps are identified, such as dynamic workload adaptation and cross-platform optimization strategies.", "conclusion": "The paper provides a structured understanding of FaaS configuration challenges, emphasizing the need for systematic research to enhance developer tools and platform capabilities, ultimately improving serverless cost-efficiency, performance predictability, and scalability."}}
{"id": "2510.02317", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02317", "abs": "https://arxiv.org/abs/2510.02317", "authors": ["Anais Jaikissoon"], "title": "Hybrid Horizons: Policy for Post-Quantum Security", "comment": "18 pages, 3 figures, 1 image", "summary": "The Age of Artificial Intelligence is here. In 2025, there are few\nregulations governing artificial intelligence. While the expansion of\nartificial intelligence is going in a relatively good direction, there is a\nrisk that it can be misused. Misuse of technology is nothing new and will\ncontinue to happen. The lack of regulation in artificial intelligence is\nnecessary because it raises the question of how we can move forward without\nknowing what the limits are. While artificial intelligence dominates the\ntechnology industry, new technology is starting to emerge. Quantum cryptography\nis expected to replace classical cryptography; however, the transition from\nclassical to quantum cryptography is expected to occur within the next 10\nyears. The ability to transition from classical to quantum cryptography\nrequires hybrid cryptography. Hybrid cryptography can be used now; however,\nsimilar to artificial intelligence, there is no regulation or support for the\nregulatory infrastructure regarding hybrid machines. This paper will explore\nthe regulatory gaps in hybrid cryptography. The paper will also offer solutions\nto fix the gaps and ensure the transition from classical to quantum\ncryptography is safely and effectively completed.", "AI": {"tldr": "This paper highlights regulatory gaps in hybrid cryptography as AI and quantum cryptography emerge, proposing solutions to ensure a secure transition while addressing risks from unregulated technologies.", "motivation": "The motivation stems from the lack of regulation in AI and hybrid cryptography, which poses risks of misuse and hinders the secure adoption of emerging quantum cryptographic technologies.", "method": "The paper explores existing regulatory gaps in hybrid cryptography through analysis of current technological shifts and proposes solutions to address these gaps, ensuring a safe and effective transition to quantum cryptography.", "result": "The paper identifies critical regulatory gaps in hybrid cryptography and offers actionable solutions to bridge these gaps, facilitating a timely and secure transition to quantum cryptography within the next decade.", "conclusion": "The paper concludes that regulatory frameworks are essential to address the gaps in hybrid cryptography and ensure a secure transition to quantum cryptography, emphasizing the need for proactive measures to prevent misuse and establish support infrastructure."}}
{"id": "2510.02504", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02504", "abs": "https://arxiv.org/abs/2510.02504", "authors": ["Mara Ulloa", "Jenna L. Butler", "Sankeerti Haniyur", "Courtney Miller", "Barrett Amos", "Advait Sarkar", "Margaret-Anne Storey"], "title": "Product Manager Practices for Delegating Work to Generative AI: \"Accountability must not be delegated to non-human actors\"", "comment": "12 pages, 4 figures, 1 table", "summary": "Generative AI (GenAI) is changing the nature of knowledge work, particularly\nfor Product Managers (PMs) in software development teams. While much software\nengineering research has focused on developers' interactions with GenAI, there\nis less understanding of how the work of PMs is evolving due to GenAI. To\naddress this gap, we conducted a mixed-methods study at Microsoft, a large,\nmultinational software company: surveying 885 PMs, analyzing telemetry data for\na subset of PMs (N=731), and interviewing a subset of 15 PMs. We contribute:\n(1) PMs' current GenAI adoption rates, uses cases, and perceived benefits and\nbarriers and; (2) a framework capturing how PMs assess which tasks to delegate\nto GenAI; (3) PMs adaptation practices for integrating GenAI into their roles\nand perceptions of how their role is evolving. We end by discussing\nimplications on the broader GenAI workflow adoption process and software\ndevelopment roles.", "AI": {"tldr": "This paper investigates how Generative AI (GenAI) impacts Product Managers (PMs)' workflows and roles in software development, presenting a mixed-methods study at Microsoft (885 PMs surveyed, 731 telemetry cases, 15 interviews). Key contributions include adoption patterns, a task-delegation framework, and PM adaptation practices.", "motivation": "Existing software engineering research focuses on developers' GenAI use, but PMs' evolving role in this context remains underexplored. This gaps understanding of knowledge work transformation in AI-augmented environments.", "method": "Mixed-methods analysis at Microsoft combining: 1. Large-scale survey (885 PMs), 2. Telemetry data analysis (731 PMs), 3. Qualitative interviews (15 PMs). Triangulation of quantitative adoption metrics and qualitative role adaptation insights.", "result": "Three contributions: 1. Quantified PM GenAI adoption rates with use cases/benefits/barriers, 2. Task delegation framework (AI-readiness criteria), 3. Adaptation strategies and evolving role perceptions among PMs.", "conclusion": "PMs are actively integrating GenAI through strategic task delegation, but face adaptation challenges. The study reveals role evolution in AI-extended workflows and suggests workflow redesign implications for software development roles."}}
