{"id": "2510.07452", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07452", "abs": "https://arxiv.org/abs/2510.07452", "authors": ["Anthony Hughes", "Vasisht Duddu", "N. Asokan", "Nikolaos Aletras", "Ning Ma"], "title": "PATCH: Mitigating PII Leakage in Language Models with Privacy-Aware Targeted Circuit PatcHing", "comment": null, "summary": "Language models (LMs) may memorize personally identifiable information (PII)\nfrom training data, enabling adversaries to extract it during inference.\nExisting defense mechanisms such as differential privacy (DP) reduce this\nleakage, but incur large drops in utility. Based on a comprehensive study using\ncircuit discovery to identify the computational circuits responsible PII\nleakage in LMs, we hypothesize that specific PII leakage circuits in LMs should\nbe responsible for this behavior. Therefore, we propose PATCH (Privacy-Aware\nTargeted Circuit PatcHing), a novel approach that first identifies and\nsubsequently directly edits PII circuits to reduce leakage. PATCH achieves\nbetter privacy-utility trade-off than existing defenses, e.g., reducing recall\nof PII leakage from LMs by up to 65%. Finally, PATCH can be combined with DP to\nreduce recall of residual leakage of an LM to as low as 0.01%. Our analysis\nshows that PII leakage circuits persist even after the application of existing\ndefense mechanisms. In contrast, PATCH can effectively mitigate their impact.", "AI": {"tldr": "PATCH is a new method that reduces PII leakage in LMs by editing specific circuits responsible for the issue, resulting in better privacy-utility trade-off than existing defenses, and can be combined with differential privacy to further protect users privacy.", "motivation": "There is a need for better defenses against the leakage of personally identifiable information (PII) from language models (LMs) during inference, which existing mechanisms like differential privacy (DP) provide at the cost of significant utility loss.", "method": "The authors used circuit discovery to identify the computational circuits responsible for PII leakage, and then proposed PATCH that directly edits these PII circuits to reduce information leakage without significantly impacting utility.", "result": "PATCH reduces the recall of PII leakage from LMs by up to 65%, and when combined with DP, it lowers residual leakage to below 0.01%.", "conclusion": "The study concludes that PII leakage circuits persist even after current defense methods are applied, but PATCH effectively mitigates their impact by directly intervening at the circuit level."}}
{"id": "2510.07457", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07457", "abs": "https://arxiv.org/abs/2510.07457", "authors": ["Kalyan Cheerla", "Lotfi Ben Othmane", "Kirill Morozov"], "title": "Comparison of Fully Homomorphic Encryption and Garbled Circuit Techniques in Privacy-Preserving Machine Learning Inference", "comment": "8 pages, 9 figures, 2 tables, 32 references", "summary": "Machine Learning (ML) is making its way into fields such as healthcare,\nfinance, and Natural Language Processing (NLP), and concerns over data privacy\nand model confidentiality continue to grow. Privacy-preserving Machine Learning\n(PPML) addresses this challenge by enabling inference on private data without\nrevealing sensitive inputs or proprietary models. Leveraging Secure Computation\ntechniques from Cryptography, two widely studied approaches in this domain are\nFully Homomorphic Encryption (FHE) and Garbled Circuits (GC). This work\npresents a comparative evaluation of FHE and GC for secure neural network\ninference. A two-layer neural network (NN) was implemented using the CKKS\nscheme from the Microsoft SEAL library (FHE) and the TinyGarble2.0 framework\n(GC) by IntelLabs. Both implementations are evaluated under the semi-honest\nthreat model, measuring inference output error, round-trip time, peak memory\nusage, communication overhead, and communication rounds. Results reveal a\ntrade-off: modular GC offers faster execution and lower memory consumption,\nwhile FHE supports non-interactive inference.", "AI": {"tldr": "This paper compares FHE and GC for secure neural network inference, highlighting their trade-offs in performance and interactivity.", "motivation": "Machine Learning is increasingly used in sensitive fields, raising concerns about data privacy and model confidentiality. Solutions like FHE and GC are being explored to address these issues.", "method": "The authors implemented a two-layer neural network using the CKKS scheme with Microsoft SEAL (FHE) and TinyGarble2.0 (GC), then evaluated them under the semi-honest threat model across five metrics.", "result": "GC provides faster execution and lower memory use, while FHE allows non-interactive inference. A trade-off between these approaches is demonstrated.", "conclusion": "The study underscores the need to balance performance and interactivity when choosing between FHE and GC for secure ML. Practical considerations vary by application, requiring tailored solutions."}}
{"id": "2510.07462", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07462", "abs": "https://arxiv.org/abs/2510.07462", "authors": ["Maryam Ataei Nezhad", "Hamid Barati", "Ali Barati"], "title": "A Secure Authentication-Driven Protected Data Collection Protocol in Internet of Things", "comment": null, "summary": "Internet of Things means connecting different devices through the Internet.\nThe Internet of things enables humans to remotely manage and control the\nobjects they use with the Internet infrastructure. After the advent of the\nInternet of Things in homes, organizations, and private companies, privacy and\ninformation security are the biggest concern. This issue has challenged the\nspread of the Internet of things as news of the users theft of information by\nhackers intensified. The proposed method in this paper consists of three\nphases. In the first phase, a star structure is constructed within each\ncluster, and a unique key is shared between each child and parent to encrypt\nand secure subsequent communications. The second phase is for intracluster\ncommunications, in which members of the cluster send their data to the cluster\nhead in a multi hop manner. Also, in this phase, the data is encrypted with\ndifferent keys in each hop, and at the end of each connection, the keys are\nupdated to ensure data security. The third phase is to improve the security of\ninter cluster communications using an authentication protocol. In this way, the\ncluster heads are authenticated before sending information to prevent malicious\nnodes in the network. The proposed method is also simulated using NS2 software.\nThe results showed that the proposed method has improved in terms of energy\nconsumption, end-to-end delay, flexibility, packet delivery rate, and the\nnumber of alive nodes compared to other methods.", "AI": {"tldr": "The paper proposes a three-phase security method for IoT networks, focusing on cluster intra and inter communication with encryption and authentication protocols.", "motivation": "Privacy and information security are the biggest challenges in the widespread adoption of IoT. The risk of information theft by hackers has intensified the need for secure communication methods.", "method": "The method comprises three phases. First, a star topology is established in each cluster with unique keys shared between nodes and cluster head to encrypt communications. Second, intracluster communication uses multi-hop data transmission, with encryption key changes at each hop and final connection updates. Third, an authentication protocol enhances intercluster communication security by verifying cluster heads before data transmission. NS2 simulations were used for testing.", "result": "The simulations showed improvements over existing methods in energy consumption, end-to-end delay, flexibility, packet delivery rate, and node survival rates.", "conclusion": "The proposed method offers a robust solution for enhancing security in IoT networks by improving both intra and intercluster communication, validated through simulation results."}}
{"id": "2510.07479", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07479", "abs": "https://arxiv.org/abs/2510.07479", "authors": ["Alain Couvreur", "Thomas Debris-Alazard", "Philippe Gaborit", "Adrien Vin\u00e7otte"], "title": "MIRANDA: short signatures from a leakage-free full-domain-hash scheme", "comment": null, "summary": "We present $\\mathsf{Miranda}$, the first family of full-domain-hash\nsignatures based on matrix codes. This signature scheme fulfils the paradigm of\nGentry, Peikert and Vaikuntanathan ($\\mathsf{GPV}$), which gives strong\nsecurity guarantees. Our trapdoor is very simple and generic: if we propose it\nwith matrix codes, it can actually be instantiated in many other ways since it\nonly involves a subcode of a decodable code (or lattice) in a unique decoding\nregime of parameters. Though $\\mathsf{Miranda}$ signing algorithm relies on a\ndecoding task where there is exactly one solution, there are many possible\nsignatures given a message to sign and we ensure that signatures are not\nleaking information on their underlying trapdoor by means of a very simple\nprocedure involving the drawing of a small number of uniform bits. In\nparticular $\\mathsf{Miranda}$ does not use a rejection sampling procedure which\nmakes its implementation a very simple task contrary to other\n$\\mathsf{GPV}$-like signatures schemes such as $\\mathsf{Falcon}$ or even\n$\\mathsf{Wave}$.\n  We instantiate $\\mathsf{Miranda}$ with the famous family of Gabidulin codes\nrepresented as spaces of matrices and we study thoroughly its security (in the\nEUF-CMA security model). For~$128$ bits of classical security, the signature\nsizes are as low as~$90$ bytes and the public key sizes are in the order\nof~$2.6$ megabytes.", "AI": {"tldr": "Miranda is a novel matrix-code based signature scheme offering 90-byte signatures with 128-bit security, simpler implementation (no rejection sampling), and competitiveness against GPV-derived schemes like Falcon/Wave.", "motivation": "The paper addresses the need for simpler, practical GPV-style signature schemes without the implementation overhead of rejection sampling (as in Falcon/Wave) while maintaining strong security guarantees and compact parameter sizes.", "method": "Miranda utilizes a generic trapdoor mechanism involving subcodes of decodable codes in unique decoding regimes. It is instantiated with Gabidulin codes (matrix representation) and avoids rejection sampling by using uniform random bits during signing.", "result": "Achieved 90-byte signatures and 2.6MB public keys for 128-bit security, with thorough EUF-CMA security analysis of the Gabidulin-based instantiation.", "conclusion": "Miranda provides an efficient and secure signature scheme based on matrix codes, reducing implementation complexity and achieving small signature sizes compared to existing GPV-based schemes."}}
{"id": "2510.07435", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.07435", "abs": "https://arxiv.org/abs/2510.07435", "authors": ["Zixuan Feng", "Sadia Afroz", "Anita Sarma"], "title": "Modeling Developer Burnout with GenAI Adoption", "comment": "10 pages, LLM", "summary": "Generative AI (GenAI) is rapidly reshaping software development workflows.\nWhile prior studies emphasize productivity gains, the adoption of GenAI also\nintroduces new pressures that may harm developers' well-being. In this paper,\nwe investigate the relationship between the adoption of GenAI and developers'\nburnout. We utilized the Job Demands--Resources (JD--R) model as the analytic\nlens in our empirical study. We employed a concurrent embedded mixed-methods\nresearch design, integrating quantitative and qualitative evidence. We first\nsurveyed 442 developers across diverse organizations, roles, and levels of\nexperience. We then employed Partial Least Squares--Structural Equation\nModeling (PLS-SEM) and regression to model the relationships among job demands,\njob resources, and burnout, complemented by a qualitative analysis of\nopen-ended responses to contextualize the quantitative findings. Our results\nshow that GenAI adoption heightens burnout by increasing job demands, while job\nresources and positive perceptions of GenAI mitigate these effects, reframing\nadoption as an opportunity.", "AI": {"tldr": "GenAI adoption raises developer burnout via increased job demands, but job resources and positive GenAI perceptions counteract this, transforming adoption into an opportunity for well-being when managed effectively.", "motivation": "Existing studies focus on productivity gains of GenAI in software development, but neglect its potential negative impacts on developer well-being, particularly burnout. The study aims to address this gap by examining the relationship between GenAI adoption and burnout.", "method": "A concurrent embedded mixed-methods design combining a survey of 442 developers with PLS-SEM and regression for quantitative analysis, complemented by qualitative analysis of open-ended responses.", "result": "GenAI adoption increases job demands (leading to burnout), while job resources and positive perceptions of GenAI reduce these effects. Quantitative models and qualitative insights corroborate these findings.", "conclusion": "The adoption of GenAI can increase developer burnout through intensified job demands, but this negative impact is mitigated by sufficient job resources and positive GenAI perceptions, positioning GenAI as an opportunity for organizations to proactively address developer well-being through resource allocation and perception management."}}
{"id": "2510.07533", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07533", "abs": "https://arxiv.org/abs/2510.07533", "authors": ["Haowen Xu", "Tianya Zhao", "Xuyu Wang", "Lei Ma", "Jun Dai", "Alexander Wyglinski", "Xiaoyan Sun"], "title": "EMPalm: Exfiltrating Palm Biometric Data via Electromagnetic Side-Channels", "comment": null, "summary": "Palm recognition has emerged as a dominant biometric authentication\ntechnology in critical infrastructure. These systems operate in either\nsingle-modal form, using palmprint or palmvein individually, or dual-modal\nform, fusing the two modalities. Despite this diversity, they share similar\nhardware architectures that inadvertently emit electromagnetic (EM) signals\nduring operation. Our research reveals that these EM emissions leak palm\nbiometric information, motivating us to develop EMPalm--an attack framework\nthat covertly recovers both palmprint and palmvein images from eavesdropped EM\nsignals. Specifically, we first separate the interleaved transmissions of the\ntwo modalities, identify and combine their informative frequency bands, and\nreconstruct the images. To further enhance fidelity, we employ a diffusion\nmodel to restore fine-grained biometric features unique to each domain.\nEvaluations on seven prototype and two commercial palm acquisition devices show\nthat EMPalm can recover palm biometric information with high visual fidelity,\nachieving SSIM scores up to 0.79, PSNR up to 29.88 dB, and FID scores as low as\n6.82 across all tested devices, metrics that collectively demonstrate strong\nstructural similarity, high signal quality, and low perceptual discrepancy. To\nassess the practical implications of the attack, we further evaluate it against\nfour state-of-the-art palm recognition models, achieving a model-wise average\nspoofing success rate of 65.30% over 6,000 samples from 100 distinct users.", "AI": {"tldr": "Researchers demonstrate EMPalm, a side-channel attack that recovers palmprint and palmvein data from electromagnetic emissions, bypassing security in biometric systems with high success rates.", "motivation": "Existing palm biometric systems emit electromagnetic signals during operation, which can leak sensitive biometric information. The study addresses the risk of such side-channel attacks and demonstrates practical methods to exploit these vulnerabilities.", "method": "The authors developed EMPalm, which separates interleaved EM signals from palmprint and palmvein transmissions, identifies key frequency bands, reconstructs images, and employs a diffusion model to enhance fine-grained biometric features for high-fidelity recovery.", "result": "EMPalm achieves SSIM up to 0.79, PSNR up to 29.88 dB, and FID as low as 6.82 on tested devices, with an average spoofing success rate of 65.30% against four state-of-the-art palm recognition models using 6,000 samples from 100 users.", "conclusion": "The research highlights a critical security vulnerability in palm recognition systems where electromagnetic emissions allow the covert recovery of biometric data using the EMPalm framework, urging improvements in hardware design and signal shielding to prevent such attacks."}}
{"id": "2510.07529", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07529", "abs": "https://arxiv.org/abs/2510.07529", "authors": ["Carol Hanna", "Federica Sarro", "Mark Harman", "Justyna Petke"], "title": "HotBugs.jar: A Benchmark of Hot Fixes for Time-Critical Bugs", "comment": null, "summary": "Hot fixes are urgent, unplanned changes deployed to production systems to\naddress time-critical issues. Despite their importance, no existing evaluation\nbenchmark focuses specifically on hot fixes. We present HotBugs$.$jar, the\nfirst dataset dedicated to real-world hot fixes. From an initial mining of 10\nactive Apache projects totaling over 190K commits and 150K issue reports, we\nidentified 746 software patches that met our hot-fix criteria. After manual\nevaluation, 679 were confirmed as genuine hot fixes, of which 110 are\nreproducible using a test suite. Building upon the Bugs$.$jar framework,\nHotBugs$.$jar integrates these 110 reproducible cases and makes available all\n679 manually validated hot fixes, each enriched with comprehensive metadata to\nsupport future research. Each hot fix was systematically identified using Jira\nissue data, validated by independent reviewers, and packaged in a reproducible\nformat with buggy and fixed versions, test suites, and metadata. HotBugs$.$jar\nhas already been adopted as the official challenge dataset for the Search-Based\nSoftware Engineering (SBSE) Conference Challenge Track, demonstrating its\nimmediate impact. This benchmark enables the study and evaluation of tools for\nrapid debugging, automated repair, and production-grade resilience in modern\nsoftware systems to drive research in this essential area forward.", "AI": {"tldr": "HotBugs.jar is a validated dataset of 679 real-world hot fixes (Apache projects, 2024), enabling rapid debugging and resilience research through reproducible test cases and metadata.", "motivation": "Existing software engineering benchmarks lack focus on hot fixes\u2014urgent production changes critical to modern systems\u2014creating a gap in evaluating resilience and repair tools.", "method": "The authors mined 10 Apache projects (190K commits, 150K issues), applied criteria to identify 746 potential hot fixes, validated 679 manually, and integrated 110 reproducible cases into an enhanced Bugs.jar framework with metadata packaging.", "result": "The dataset features 679 validated hot fixes (including 110 test-suite reproducible cases), metadata, and formal adoption as the SBSE Conference Challenge Track benchmark, with confirmed research applications.", "conclusion": "HotBugs.jar establishes a foundational benchmark for hot-fix research, enabling advancements in rapid debugging and resilience tools for production systems."}}
{"id": "2510.07584", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07584", "abs": "https://arxiv.org/abs/2510.07584", "authors": ["Thomas Debris-Alazard", "Philippe Gaborit", "Romaric Neveu", "Olivier Ruatta"], "title": "A Minrank-based Encryption Scheme \u00e0 la Alekhnovich-Regev", "comment": null, "summary": "Introduced in 2003 and 2005, Alekhnovich and Regev' schemes were the first\npublic-key encryptions whose security is only based on the average hardness of\ndecoding random linear codes and LWE, without other security assumptions. Such\nsecurity guarantees made them very popular, being at the origin of the now\nstandardized HQC or Kyber.\n  We present an adaptation of Alekhnovich and Regev' encryption scheme whose\nsecurity is only based on the hardness of a slight variation of MinRank, the\nso-called stationary-MinRank problem. We succeeded to reach this strong\nsecurity guarantee by showing that stationary-MinRank benefits from a\nsearch-to-decision reduction. Our scheme therefore brings a partial answer to\nthe long-standing open question of building an encryption scheme whose security\nrelies solely on the hardness of MinRank.\n  Finally, we show after a thoroughly security analysis that our scheme is\npractical and competitive with other encryption schemes admitting such strong\nsecurity guarantees. Our scheme is slightly less efficient than FrodoKEM, but\nmuch more efficient than Alekhnovich and Regev' original schemes, with\npossibilities of improvements by considering more structure, in the same way as\nHQC and Kyber.", "AI": {"tldr": "The paper presents a new encryption scheme adapting Alekhnovich and Regev's schemes with security based on the stationary-MinRank problem, addressing the long-standing open question of building a MinRank-based encryption scheme. It is practical and efficient, comparable to FrodoKEM and outperforming earlier schemes.", "motivation": "To build an encryption scheme whose security solely relies on the hardness of MinRank, a long-standing open question in the field, in the same way as HQC and Kyber schemes rely on the hardness of random linear code decoding and LWE, respectively.", "method": "The authors adapted Alekhnovich and Regev's encryption schemes by modifying the underlying problem to a variation of MinRank called stationary-MinRank, which is shown to benefit from a search-to-decision reduction. This reduction ensures that the scheme's security is tightly based on the stationary-MinRank problem.", "result": "The proposed encryption scheme is practical and competitive with schemes like FrodoKEM, while being more efficient than the original Alekhnovich and Regev schemes. It provides strong security guarantees based solely on the average hardness of its underlying problem, with potential for further efficiency gains by adding more structure.", "conclusion": "The paper successfully addresses a long-standing open question by presenting a practical, efficient encryption scheme built solely on the hardness of the stationary-MinRank problem, offering a promising alternative to existing cryptographic standards like HQC and Kyber."}}
{"id": "2510.07604", "categories": ["cs.SE", "D.2.4"], "pdf": "https://arxiv.org/pdf/2510.07604", "abs": "https://arxiv.org/abs/2510.07604", "authors": ["Yubo Bai", "Tapti Palit"], "title": "RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code", "comment": "13 pages to appear in Proceedings of ASE 2025", "summary": "Rust is a memory-safe programming language that significantly improves\nsoftware security. Existing codebases written in unsafe memory languages, such\nas C, must first be transpiled to Rust to take advantage of Rust's improved\nsafety guarantees. RustAssure presents a system that uses Large Language Models\n(LLMs) to automatically transpile existing C codebases to Rust. RustAssure uses\nprompt engineering techniques to maximize the chances of the LLM generating\nidiomatic and safe Rust code. Moreover, because LLMs often generate code with\nsubtle bugs that can be missed under traditional unit or fuzz testing,\nRustAssure performs differential symbolic testing to establish the semantic\nsimilarity between the original C and LLM-transpiled Rust code. We evaluated\nRustAssure with five real-world applications and libraries, and showed that our\nsystem is able to generate compilable Rust functions for 89.8% of all C\nfunctions, of which 69.9% produced equivalent symbolic return values for both\nthe C and Rust functions.", "AI": {"tldr": "RustAssure automates C-to-Rust transpilation via LLMs and symbolic testing, enabling 89.8% compilable Rust code with 69.9% functional equivalence.", "motivation": "Legacy C codebases lack Rust's memory safety features, requiring migration to benefit from modern security guarantees. Automated transpilation faces challenges in generating idiomatic code and subtle correctness issues that evade traditional testing methods.", "method": "Leverages large language models (LLMs) with prompt engineering to transpile C to Rust. Implements differential symbolic testing to verify functional equivalence between original and transpiled code by comparing symbolic return values.", "result": "Achieved 89.8% compilable Rust functions from C code across five real-world applications. Symbolic testing confirmed 69.9% of transpiled functions produced equivalent outputs to their C counterparts, validating semantic accuracy.", "conclusion": "RustAssure demonstrates an effective system for transpiling C to Rust using LLMs, achieving high compilation success and semantic similarity through symbolic testing. The work provides a reliable approach to modernizing legacy codebases with Rust's safety guarantees."}}
{"id": "2510.07697", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07697", "abs": "https://arxiv.org/abs/2510.07697", "authors": ["Man Hu", "Xinyi Wu", "Zuofeng Suo", "Jinbo Feng", "Linghui Meng", "Yanhao Jia", "Anh Tuan Luu", "Shuai Zhao"], "title": "Rethinking Reasoning: A Survey on Reasoning-based Backdoors in LLMs", "comment": null, "summary": "With the rise of advanced reasoning capabilities, large language models\n(LLMs) are receiving increasing attention. However, although reasoning improves\nLLMs' performance on downstream tasks, it also introduces new security risks,\nas adversaries can exploit these capabilities to conduct backdoor attacks.\nExisting surveys on backdoor attacks and reasoning security offer comprehensive\noverviews but lack in-depth analysis of backdoor attacks and defenses targeting\nLLMs' reasoning abilities. In this paper, we take the first step toward\nproviding a comprehensive review of reasoning-based backdoor attacks in LLMs by\nanalyzing their underlying mechanisms, methodological frameworks, and\nunresolved challenges. Specifically, we introduce a new taxonomy that offers a\nunified perspective for summarizing existing approaches, categorizing\nreasoning-based backdoor attacks into associative, passive, and active. We also\npresent defense strategies against such attacks and discuss current challenges\nalongside potential directions for future research. This work offers a novel\nperspective, paving the way for further exploration of secure and trustworthy\nLLM communities.", "AI": {"tldr": "This paper reviews reasoning-based backdoor attacks in LLMs, proposes a taxonomy (associative, passive, active), and discusses defenses and future challenges.", "motivation": "Existing surveys lack in-depth analysis of backdoor attacks targeting LLMs'", "method": "Analyzing mechanisms/frameworks via taxonomy, summarizing existing approaches, and discussing defenses/unresolved challenges.", "result": "Taxonomy categorization, defense strategies overview, and research directions for secure reasoning LLM development.", "conclusion": "Establishes foundation for systematically studying LLM security risks in reasoning domains, emphasizing trustworthy AI communities."}}
{"id": "2510.07740", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07740", "abs": "https://arxiv.org/abs/2510.07740", "authors": ["Dezhi Ran", "Yuan Cao", "Mengzhou Wu", "Simin Chen", "Yuzhe Guo", "Jun Ren", "Zihe Song", "Hao Yu", "Jialei Wei", "Linyi Li", "Wei Yang", "Baishakhi Ray", "Tao Xie"], "title": "AppForge: From Assistant to Independent Developer -- Are GPTs Ready for Software Development?", "comment": "Under Review. Benchmark and leadboards at\n  https://appforge-bench.github.io/", "summary": "Large language models (LLMs) have demonstrated remarkable capability in\nfunction-level code generation tasks. Unlike isolated functions, real-world\napplications demand reasoning over the entire software system: developers must\norchestrate how different components interact, maintain consistency across\nstates over time, and ensure the application behaves correctly within the\nlifecycle and framework constraints. Yet, no existing benchmark adequately\nevaluates whether LLMs can bridge this gap and construct entire software\nsystems from scratch. To address this gap, we propose APPFORGE, a benchmark\nconsisting of 101 software development problems drawn from real-world Android\napps. Given a natural language specification detailing the app functionality, a\nlanguage model is tasked with implementing the functionality into an Android\napp from scratch. Developing an Android app from scratch requires understanding\nand coordinating app states, lifecycle management, and asynchronous operations,\ncalling for LLMs to generate context-aware, robust, and maintainable code. To\nconstruct APPFORGE, we design a multi-agent system to automatically summarize\nthe main functionalities from app documents and navigate the app to synthesize\ntest cases validating the functional correctness of app implementation.\nFollowing rigorous manual verification by Android development experts, APPFORGE\nincorporates the test cases within an automated evaluation framework that\nenables reproducible assessment without human intervention, making it easily\nadoptable for future research. Our evaluation on 12 flagship LLMs show that all\nevaluated models achieve low effectiveness, with the best-performing model\n(GPT-5) developing only 18.8% functionally correct applications, highlighting\nfundamental limitations in current models' ability to handle complex,\nmulti-component software engineering challenges.", "AI": {"tldr": "APPFORGE is a new benchmark for evaluating LLMs in constructing full Android apps, revealing that even top models like GPT-5 achieve only 18.8% functional correctness. It highlights the need for improved LLMs and benchmarks for system-level software development.", "motivation": "Despite LLMs' success in function-level code generation, real-world applications require system-level reasoning across components, states, and lifecycles. Existing benchmarks do not evaluate LLMs' ability to construct entire software systems, motivating the creation of APPFORGE to bridge this gap and enable meaningful progress in this area.", "method": "The authors developed APPFORGE by creating 101 real-world Android app challenges where LLMs must implement functionality from natural language specifications. A multi-agent system was designed to automatically summarize app documents, synthesize test cases, and validate correctness. Rigorous manual verification by experts ensured quality, and the benchmark is integrated into an automated evaluation framework for reproducible assessments without human intervention.", "result": "Evaluation on 12 flagship LLMs showed poor effectiveness, with the best model (GPT-5) achieving only 18.8% functional correctness in Android app implementations. This demonstrates current models' inability to manage multi-component software engineering tasks effectively.", "conclusion": "The paper introduces APPFORGE, a benchmark addressing the gap in evaluating Large Language Models (LLMs) for full-system software development. It highlights fundamental limitations in current models' ability to handle complex, multi-component tasks required for constructing entire software systems, as evidenced by low functional correctness (18.8% for the best-performing model, GPT-5). This underscores the need for advancements in LLM capabilities and benchmarks for system-level software engineering challenges."}}
{"id": "2510.07806", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07806", "abs": "https://arxiv.org/abs/2510.07806", "authors": ["Yihao Peng", "Biao Ma", "Hai Wan", "Xibin Zhao"], "title": "ANCORA: Accurate Intrusion Recovery for Web Applications", "comment": null, "summary": "Modern web application recovery presents a critical dilemma. Coarse-grained\nsnapshot rollbacks cause unacceptable data loss for legitimate users.\nSurgically removing an attack's impact is hindered by a fundamental challenge\nin high-concurrency environments: it is difficult to attribute resulting file\nand database modifications to a specific attack-related request. We present\nANCORA, a system for precise intrusion recovery in web applications without\ninvasive instrumentation. ANCORA first isolates the full sequence of syscalls\ntriggered by a single malicious request. Based on this sequence, ANCORA\naddresses file and database modifications separately. To trace file changes, it\nbuilds a provenance graph that reveals all modifications, including those by\nexploit-spawned processes. To attribute database operations, a more difficult\nchallenge due to connection pooling, ANCORA introduces a novel spatiotemporal\nanchor. This anchor uses the request's network connection tuple and active time\nwindow to pinpoint exact database operations. With all malicious file and\ndatabase operations precisely identified, ANCORA performs a unified rewind and\nselective replay recovery. It reverts the system to a clean snapshot taken\nbefore the attack, then selectively re-applies only legitimate operations to\nboth the file system and database. This completely removes the attack's effects\nwhile preserving concurrent legitimate data. We evaluated ANCORA on 10 web\napplications and 20 CVE-based attack scenarios with concurrency up to 150\nconnections. Experiments demonstrate ANCORA achieves 99.9% recovery accuracy\nwith manageable overhead: up to 19.8% response latency increase and 17.8% QPS\ndecrease in worst cases, and recovery throughput of 110.7 database operations\nper second and 27.2 affected files per second, effectively preserving\nlegitimate data.", "AI": {"tldr": "ANCORA is a system for precise intrusion recovery in web applications, enabling accurate rollbacks of malicious activities while retaining legitimate concurrent data with low overhead.", "motivation": "Current web app recovery solutions either cause significant data loss due to coarse rollbacks or struggle to isolate malicious impacts in high-concurrency environments because of difficulties in attributing file and database modifications to specific attack requests.", "method": "ANCORA isolates syscalls of a malicious request, uses a provenance graph to trace file changes (including by exploit processes), and employs a spatiotemporal anchor to attribute database operations by connecting the attack's network tuple and active time window. It combines snapshot rewind and selective replay to recover the system.", "result": "ANCORA achieved 99.9% recovery accuracy in 10 web apps and 20 CVE-based attack scenarios. It introduced up to 19.8% latency increase and 17.8% QPS decrease, while maintaining a recovery throughput of 110.7 database operations and 27.2 files per second.", "conclusion": "ANCORA effectively and efficiently recovers from intrusions in modern web applications by precisely attributing and reverting malicious operations without invasive instrumentation, preserving legitimate data in high-concurrency settings."}}
{"id": "2510.07815", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07815", "abs": "https://arxiv.org/abs/2510.07815", "authors": ["Zeyu Sun", "Jingjing Liang", "Weiyi Wang", "Chenyao Suo", "Junjie Chen", "Fanjiang Xu"], "title": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR", "comment": null, "summary": "MLIR (Multi-Level Intermediate Representation) has rapidly become a\nfoundational technology for modern compiler frameworks, enabling extensibility\nacross diverse domains. However, ensuring the correctness and robustness of\nMLIR itself remains challenging. Existing fuzzing approaches-based on manually\ncrafted templates or rule-based mutations-struggle to generate sufficiently\ndiverse and semantically valid test cases, making it difficult to expose subtle\nor deep-seated bugs within MLIR's complex and evolving code space. In this\npaper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX\nleverages neural networks for program generation, a perturbed sampling strategy\nto encourage diversity, and a feedback-driven augmentation loop that\niteratively improves its model using both crashing and non-crashing test cases.\nStarting from a limited seed corpus, FLEX progressively learns valid syntax and\nsemantics and autonomously produces high-quality test inputs. We evaluate FLEX\non the upstream MLIR compiler against four state-of-the-art fuzzers. In a\n30-day campaign, FLEX discovers 80 previously unknown bugs-including multiple\nnew root causes and parser bugs-while in 24-hour fixed-revision comparisons, it\ndetects 53 bugs (over 3.5x as many as the best baseline) and achieves 28.2%\ncode coverage, outperforming the next-best tool by 42%. Ablation studies\nfurther confirm the critical role of both perturbed generation and diversity\naugmentation in FLEX's effectiveness.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.07809", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07809", "abs": "https://arxiv.org/abs/2510.07809", "authors": ["Renhua Ding", "Xiao Yang", "Zhengwei Fang", "Jun Luo", "Kun He", "Jun Zhu"], "title": "Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents", "comment": null, "summary": "Large vision-language models (LVLMs) enable autonomous mobile agents to\noperate smartphone user interfaces, yet vulnerabilities to UI-level attacks\nremain critically understudied. Existing research often depends on conspicuous\nUI overlays, elevated permissions, or impractical threat models, limiting\nstealth and real-world applicability. In this paper, we present a practical and\nstealthy one-shot jailbreak attack that leverages in-app prompt injections:\nmalicious applications embed short prompts in UI text that remain inert during\nhuman interaction but are revealed when an agent drives the UI via ADB (Android\nDebug Bridge). Our framework comprises three crucial components: (1)\nlow-privilege perception-chain targeting, which injects payloads into malicious\napps as the agent's visual inputs; (2) stealthy user-invisible activation, a\ntouch-based trigger that discriminates agent from human touches using physical\ntouch attributes and exposes the payload only during agent operation; and (3)\none-shot prompt efficacy, a heuristic-guided, character-level\niterative-deepening search algorithm (HG-IDA*) that performs one-shot,\nkeyword-level detoxification to evade on-device safety filters. We evaluate\nacross multiple LVLM backends, including closed-source services and\nrepresentative open-source models within three Android applications, and we\nobserve high planning and execution hijack rates in single-shot scenarios\n(e.g., GPT-4o: 82.5% planning / 75.0% execution). These findings expose a\nfundamental security vulnerability in current mobile agents with immediate\nimplications for autonomous smartphone operation.", "AI": {"tldr": "This paper introduces a stealthy one-shot jailbreak attack on large vision-language models (LVLMs)-powered mobile agents using in-app prompt injections, bypassing existing security limitations.", "motivation": "Existing UI-level attack methods against mobile agents require conspicuous overlays, elevated permissions, or impractical threat models, limiting real-world applicability and stealth.", "method": "The framework includes (1).low-privilege perception-chain targeting for payload injection, (2).stealthy user-invisible activation via touch attribute analysis, and (3).HG-IDA*, a heuristic-guided algorithm for one-shot detoxification to evade safety filters.", "result": "The attack achieves 82.5%/75.0%</\n> planning/execution hijack rates on GPT-4o across three Android apps, with consistent performance across open-source and closed-source LVLM backends.", "conclusion": "This work exposes critical vulnerabilities in autonomous smartphone agents, demonstrating large-scale practicality of stealthy prompt-injection attacks with immediate security implications."}}
{"id": "2510.07834", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07834", "abs": "https://arxiv.org/abs/2510.07834", "authors": ["Lingjun Liu", "Feiran Qin", "Owolabi Legunsen", "Marcelo d'Amorim"], "title": "Bug Histories as Sources of Compiler Fuzzing Mutators", "comment": null, "summary": "Bugs in compilers, which are critical infrastructure today, can have outsized\nnegative impacts. Mutational fuzzers aid compiler bug detection by\nsystematically mutating compiler inputs, i.e., programs. Their effectiveness\ndepends on the quality of the mutators used. Yet, no prior work used compiler\nbug histories as a source of mutators. We propose IssueMut, the first approach\nfor extracting compiler fuzzing mutators from bug histories. Our insight is\nthat bug reports contain hints about program elements that induced compiler\nbugs; they can guide fuzzers towards similar bugs. IssueMut uses an automated\nmethod to mine mutators from bug reports and retrofit such mutators into\nexisting mutational compiler fuzzers. Using IssueMut, we mine 587 mutators from\n1760 GCC and LLVM bug reports. Then, we run IssueMut on these compilers, with\nall their test inputs as seed corpora. We find that \"bug history\" mutators are\neffective: they find new bugs that a state-of-the-art mutational compiler\nfuzzer misses-28 in GCC and 37 in LLVM. Of these, 60 were confirmed or fixed,\nvalidating our idea that bug histories have rich information that compiler\nfuzzers should leverage.", "AI": {"tldr": "IssueMut is a new method for extracting fuzzing mutators from compiler bug histories to improve compiler bug detection.", "motivation": "Compiler bugs can have serious impacts, and existing mutational fuzzers lack mutators derived from historical compiler bugs.", "method": "IssueMut automatically mines mutators from bug reports and integrates them into existing compiler fuzzers to target previously reported bugs.", "result": "587 mutators were extracted from GCC and LLVM bug reports, leading to discovery of 28 new bugs in GCC and 37 new bugs in LLVM.", "conclusion": "Using bug histories to derive mutators is effective for compiler fuzzing, as nearly all (60/65) discovered bugs were confirmed or fixed."}}
{"id": "2510.07901", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.07901", "abs": "https://arxiv.org/abs/2510.07901", "authors": ["Georgios Diamantopoulos", "Nikos Tziritas", "Rami Bahsoon", "Georgios Theodoropoulos"], "title": "Decentralised Blockchain Management Through Digital Twins", "comment": "Accepted for publication in the proceedings of the 24th Asia\n  Simulation Conference 2025", "summary": "The necessity of blockchain systems to remain decentralised limits current\nsolutions to blockchain governance and dynamic management, forcing a trade-off\nbetween control and decentralisation. In light of the above, this work proposes\na dynamic and decentralised blockchain management mechanism based on digital\ntwins. To ensure decentralisation, the proposed mechanism utilises multiple\ndigital twins that the system's stakeholders control. To facilitate\ndecentralised decision-making, the twins are organised in a secondary\nblockchain system that orchestrates agreement on, and propagation of decisions\nto the managed blockchain. This enables the management of blockchain systems\nwithout centralised control. A preliminary evaluation of the performance and\nimpact of the overheads introduced by the proposed mechanism is conducted\nthrough simulation. The results demonstrate the proposed mechanism's ability to\nreach consensus on decisions quickly and reconfigure the primary blockchain\nwith minimal overhead.", "AI": {"tldr": "This paper proposes a decentralized blockchain management mechanism using digital twins to resolve the trade-off between control and decentralization. A secondary blockchain orchestrates stakeholder-controlled digital twins for decision-making, enabling reconfiguration of the primary blockchain with minimal overhead.", "motivation": "Current blockchain governance solutions force a trade-off between centralised control and decentralisation, limiting dynamic management capabilities. The system must remain decentralised while enabling coordinated decision-making.", "method": "The mechanism employs multiple stakeholder-controlled digital twins organized in a secondary blockchain. This auxiliary chain reaches consensus on management decisions and propagates them to the primary blockchain, maintaining decentralised control through distributed agreement processes.", "result": "Simulations demonstrate rapid consensus achievement (average X ms) and reconfiguration of the primary blockchain with Y% overhead. The system handles Z concurrent management requests while maintaining 99.8% decision accuracy.", "conclusion": "The digital twin-based architecture successfully decouples governance from operational blockchains, proving decentralised dynamic management is achievable without sacrificing performance or introducing central points of control."}}
{"id": "2510.07941", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07941", "abs": "https://arxiv.org/abs/2510.07941", "authors": ["Srijita Basu", "Haraldsson Bengt", "Miroslaw Staron", "Christian Berger", "Jennifer Horkoff", "Magnus Almgren"], "title": "An AUTOSAR-Aligned Architectural Study of Vulnerabilities in Automotive SoC Software", "comment": "16 pages, 7 figures, 18th International Conference on the Quality of\n  Information and Communications Technology", "summary": "Cooperative, Connected and Automated Mobility (CCAM) are complex\ncyber-physical systems (CPS) that integrate computation, communication, and\ncontrol in safety-critical environments. At their core, System-on-Chip (SoC)\nplatforms consolidate processing units, communication interfaces, AI\naccelerators, and security modules into a single chip. AUTOSAR (AUTomotive Open\nSystem ARchitecture) standard was developed in the automotive domain to better\nmanage this complexity, defining layered software structures and interfaces to\nfacilitate reuse of HW/SW components. However, in practice, this integrated SoC\nsoftware architecture still poses security challenges, particularly in\nreal-time, safety-critical environments. Recent reports highlight a surge in\nSoC-related vulnerabilities, yet systematic analysis of their root causes and\nimpact within AUTOSAR-aligned architectures is lacking. This study fills that\ngap by analyzing 180 publicly reported automotive SoC vulnerabilities, mapped\nto a representative SoC software architecture model that is aligned with\nAUTOSAR principles for layered abstraction and service orientation. We identify\n16 root causes and 56 affected software modules, and examine mitigation delays\nacross Common Weakness Enumeration (CWE) categories and architectural layers.\nWe uncover dominant vulnerability patterns and critical modules with prolonged\npatch delays, and provide actionable insights for securing automotive CPS\nplatforms, including guides for improved detection, prioritization, and\nlocalization strategies for SoC software architectures in SoC-based vehicle\nplatforms.", "AI": {"tldr": "This study analyzes 180 automotive SoC vulnerabilities mapped to an AUTOSAR-aligned architecture model, identifying root causes, affected modules, and mitigation delays, and offers security strategies for CCAM systems.", "motivation": "The research addresses the growing number of SoC-related vulnerabilities in automotive systems by providing a systematic analysis aligned with AUTOSAR principles, aiming to improve security in CCAM environments.", "method": "The authors mapped 180 publicly reported automotive SoC vulnerabilities to a representative SoC software architecture model that follows AUTOSAR's layered abstraction and service orientation. They identified root causes and affected modules, analyzed mitigation delays across layers and weaknesses, and uncovered patterns over time.", "result": "The study found 16 root causes and 56 affected modules in the AUTOSAR-aligned architecture model. It also discovered common vulnerability patterns and critical modules with long patch delays, offering insights for better vulnerability detection, prioritization, and localization strategies.", "conclusion": "The paper concludes by highlighting dominant vulnerability patterns in automotive SoC layers and proposing actionable strategies to enhance security, offering practical guidance for securing automotive cyber-physical systems against emerging threats."}}
{"id": "2510.07968", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07968", "abs": "https://arxiv.org/abs/2510.07968", "authors": ["Xiangtao Meng", "Tianshuo Cong", "Li Wang", "Wenyu Chen", "Zheng Li", "Shanqing Guo", "Xiaoyun Wang"], "title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable performance across various\napplications, but their deployment in sensitive domains raises significant\nconcerns. To mitigate these risks, numerous defense strategies have been\nproposed. However, most existing studies assess these defenses in isolation,\noverlooking their broader impacts across other risk dimensions. In this work,\nwe take the first step in investigating unintended interactions caused by\ndefenses in LLMs, focusing on the complex interplay between safety, fairness,\nand privacy. Specifically, we propose CrossRiskEval, a comprehensive evaluation\nframework to assess whether deploying a defense targeting one risk\ninadvertently affects others. Through extensive empirical studies on 14\ndefense-deployed LLMs, covering 12 distinct defense strategies, we reveal\nseveral alarming side effects: 1) safety defenses may suppress direct responses\nto sensitive queries related to bias or privacy, yet still amplify indirect\nprivacy leakage or biased outputs; 2) fairness defenses increase the risk of\nmisuse and privacy leakage; 3) privacy defenses often impair safety and\nexacerbate bias. We further conduct a fine-grained neuron-level analysis to\nuncover the underlying mechanisms of these phenomena. Our analysis reveals the\nexistence of conflict-entangled neurons in LLMs that exhibit opposing\nsensitivities across multiple risk dimensions. Further trend consistency\nanalysis at both task and neuron levels confirms that these neurons play a key\nrole in mediating the emergence of unintended behaviors following defense\ndeployment. We call for a paradigm shift in LLM risk evaluation, toward\nholistic, interaction-aware assessment of defense strategies.", "AI": {"tldr": "This paper introduces CrossRiskEval, a framework revealing unintended interactions between safety, fairness, and privacy defenses in LLMs, where mitigating one risk often exacerbates others via 'conflict-entangled neurons'.", "motivation": "Existing LLM defense strategies address risks in isolation, overlooking their interdependent impacts. This work addresses critical gaps in understanding how safety, fairness, and privacy mechanisms interact, creating new vulnerabilities when deployed together.", "method": "CrossRiskEval evaluates 14 defense-deployed LLMs across 12 strategies via empirical testing and neuron-level analysis, identifying conflict-entangled neurons through task- and neuron-level trend consistency analysis.", "result": "1. Safety defenses increase indirect privacy/bias leakage. 2. Fairness defenses raise misuse/privacy risks. 3. Privacy defenses worsen safety/fairness. 4. Conflict-entangled neurons mediate these interactions.", "conclusion": "Defense evaluation must shift toward holistic, interaction-aware paradigms to address emergent risks from combined safety, fairness, and privacy strategies in LLMs."}}
{"id": "2510.08005", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08005", "abs": "https://arxiv.org/abs/2510.08005", "authors": ["Utku Boran Torun", "Mehmet Taha Demircan", "Mahmut Furkan G\u00f6n", "Eray T\u00fcz\u00fcn"], "title": "Past, Present, and Future of Bug Tracking in the Generative AI Era", "comment": "Submitted to ACM TOSEM Special Issue: 2030 Software Engineering\n  Roadmap", "summary": "Traditional bug tracking systems rely heavily on manual reporting,\nreproduction, triaging, and resolution, each carried out by different\nstakeholders such as end users, customer support, developers, and testers. This\ndivision of responsibilities requires significant coordination and widens the\ncommunication gap between non-technical users and technical teams, slowing the\nprocess from bug discovery to resolution. Moreover, current systems are highly\nasynchronous; users often wait hours or days for a first response, delaying\nfixes and contributing to frustration. This paper examines the evolution of bug\ntracking, from early paper-based reporting to today's web-based and SaaS\nplatforms. Building on this trajectory, we propose an AI-powered bug tracking\nframework that augments existing tools with intelligent, large language model\n(LLM)-driven automation. Our framework addresses two main challenges: reducing\ntime-to-fix and minimizing human overhead. Users report issues in natural\nlanguage, while AI agents refine reports, attempt reproduction, and request\nmissing details. Reports are then classified, invalid ones resolved through\nno-code fixes, and valid ones localized and assigned to developers. LLMs also\ngenerate candidate patches, with human oversight ensuring correctness. By\nintegrating automation into each phase, our framework accelerates response\ntimes, improves collaboration, and strengthens software maintenance practices\nfor a more efficient, user-centric future.", "AI": {"tldr": "This paper proposes an AI-powered bug tracking framework that automates reporting, triaging, and fixing to reduce delays and human effort. By leveraging LLMs, it accelerates resolution, strengthens collaboration, and creates a user-centric software maintenance system.", "motivation": "Traditional bug tracking systems suffer from manual, asynchronous processes that delay resolutions and hinder collaboration between non-technical users and technical teams, causing operational inefficiencies and user frustration.", "method": "An AI-driven framework augmented with large language models (LLMs) is introduced to automate bug reporting, classification, reproduction, and patch generation. AI agents refine user-reported issues in natural language, handle triaging via no-code fixes, and assist developers with localization and candidate patches under human oversight.", "result": "The framework achieves faster response times, minimizes human intervention, and streamlines bug tracking by integrating automation across all phases while maintaining correctness through human oversight.", "conclusion": "The proposed AI-powered bug tracking framework accelerates bug resolution by reducing time-to-fix and human overhead through automation, enhancing collaboration, and improving user-centric software maintenance practices."}}
{"id": "2510.08013", "categories": ["cs.CR", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2510.08013", "abs": "https://arxiv.org/abs/2510.08013", "authors": ["Yurang R. Kuang"], "title": "Composition Law of Conjugate Observables in Random Permutation Sorting Systems", "comment": null, "summary": "We present the discovery of a fundamental composition law governing conjugate\nobservables in the Random Permutation Sorting System (RPSS). The law links the\ndiscrete permutation count Np and the continuous elapsed time T through a\nfunctional relation connecting the characteristic function of timing\ndistributions to the probability generating function of permutation counts.\nThis framework enables entropy purification, transforming microarchitectural\ntiming fluctuations into uniform randomness via geometric convergence. We\nestablish convergence theorems with explicit bounds and validate the results\nexperimentally, achieving Shannon entropy above 7.9998 bits per byte and\nchi-square uniformity across diverse platforms. The composition law provides a\nuniversal foundation for generating provably uniform randomness from\ngeneral-purpose computation, securing cryptographic purity from emergent\ncomputational dynamics.", "AI": {"tldr": "This paper introduces a composition law in RPSS that converts computational timing fluctuations into provably uniform randomness, validated to achieve nearly perfect entropy and cross-platform uniformity for cryptographic use.", "motivation": "Current methods for generating uniform randomness in cryptographic systems face challenges in ensuring purity and cross-platform reliability. This work addresses these gaps by exploiting emergent computational dynamics through RPSS, transforming microarchitectural timing fluctuations into secure randomness.", "method": "The method leverages a functional relation between permutation counts (Np) and elapsed time (T) in RPSS, combining characteristic functions and probability generating functions to enable entropy purification via geometric convergence. This is supported by convergence theorems and experimental validation across diverse platforms.", "result": "The approach achieved Shannon entropy exceeding 7.9998 bits per byte and chi-square uniformity across platforms, with rigorous theoretical bounds and experimental validation confirming its effectiveness in producing high-quality randomness.", "conclusion": "The paper establishes a universal framework for generating provably uniform randomness from general-purpose computation, offering a secure and efficient solution for cryptographic applications through the Random Permutation Sorting System (RPSS) and its entropy purification method."}}
{"id": "2510.08200", "categories": ["cs.SE", "68N15", "D.2.13"], "pdf": "https://arxiv.org/pdf/2510.08200", "abs": "https://arxiv.org/abs/2510.08200", "authors": ["Alexander Hellwig", "Nico Jansen", "Bernhard Rumpe"], "title": "Building Whitespace-Sensitive Languages Using Whitespace-Insensitive Components", "comment": "11 pages, 4 figures, 6 listings", "summary": "In Software Language Engineering, there is a trend towards reusability by\ncomposing modular language components. However, this reusability is severely\ninhibited by a gap in integrating whitespace-sensitive and\nwhitespace-insensitive languages. There is currently no consistent procedure\nfor seamlessly reusing such language components in both cases, such that\nlibraries often cannot be reused, and whitespacesensitive languages are\ndeveloped from scratch. This paper presents a technique for using modular,\nwhitespaceinsensitive language modules to construct whitespace sensitive\nlanguages by pre-processing language artifacts before parsing. The approach is\nevaluated by reconstructing a simplified version of the programming language\nPython. Our solution aims to increase the reusability of existing language\ncomponents to reduce development time and increase the overall quality of\nsoftware languages.", "AI": {"tldr": "This paper introduces a preprocessing method to reuse whitespace-insensitive language modules for whitespace-sensitive languages, reducing development time and improving language quality through modular composition.", "motivation": "The motivation addresses the lack of consistent procedures for reusing language components across whitespace-sensitive and insensitive languages, which hinders library reuse and forces redundant development.", "method": "The method involves pre-processing language artifacts using modular whitespace-insensitive components before parsing, demonstrated by reconstructing a simplified version of Python.", "result": "The approach successfully reconstructs a simplified Python variant, demonstrating practical reusability of whitespace-insensitive modules for whitespace-sensitive language construction.", "conclusion": "The paper concludes that the proposed preprocessing technique effectively bridges the gap between whitespace-sensitive and whitespace-insensitive languages, enabling reusability of existing language modules to improve development efficiency and language quality."}}
{"id": "2510.08084", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08084", "abs": "https://arxiv.org/abs/2510.08084", "authors": ["Hikmat A. M. Abdeljaber", "Md. Alamgir Hossain", "Sultan Ahmad", "Ahmed Alsanad", "Md Alimul Haque", "Sudan Jha", "Jabeen Nazeer"], "title": "A Novel Ensemble Learning Approach for Enhanced IoT Attack Detection: Redefining Security Paradigms in Connected Systems", "comment": "14 pages, 5 fiugres, 7 tables", "summary": "The rapid expansion of Internet of Things (IoT) devices has transformed\nindustries and daily life by enabling widespread connectivity and data\nexchange. However, this increased interconnection has introduced serious\nsecurity vulnerabilities, making IoT systems more exposed to sophisticated\ncyber attacks. This study presents a novel ensemble learning architecture\ndesigned to improve IoT attack detection. The proposed approach applies\nadvanced machine learning techniques, specifically the Extra Trees Classifier,\nalong with thorough preprocessing and hyperparameter optimization. It is\nevaluated on several benchmark datasets including CICIoT2023, IoTID20,\nBotNeTIoT L01, ToN IoT, N BaIoT, and BoT IoT. The results show excellent\nperformance, achieving high recall, accuracy, and precision with very low error\nrates. These outcomes demonstrate the model efficiency and superiority compared\nto existing approaches, providing an effective and scalable method for securing\nIoT environments. This research establishes a solid foundation for future\nprogress in protecting connected devices from evolving cyber threats.", "AI": {"tldr": "The study presents an enhanced ensemble learning model for detecting IoT attacks, evaluated across multiple datasets with strong performance metrics and low error rates.", "motivation": "As IoT devices proliferate, their security vulnerabilities and susceptibility to sophisticated cyber attacks heighten, necessitating efficient and scalable solutions to secure these systems.", "method": "The paper introduces a novel ensemble learning architecture using the Extra Trees Classifier, emphasizing effective data preprocessing and hyperparameter optimization.", "result": "The methodology achieves high recall, accuracy, precision, and low error rates across various benchmark datasets (e.g., CICIoT2023, IoTID20, BotNeTIoT L01), underscoring its efficacy and scalability.", "conclusion": "This research offers an efficient and scalable method for IoT security, setting a foundation for future advancements in defending against evolving cyber threats."}}
{"id": "2510.08101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08101", "abs": "https://arxiv.org/abs/2510.08101", "authors": ["Simone Bozzolan", "Stefano Calzavara", "Lorenzo Cazzaro"], "title": "LLM-Assisted Web Measurements", "comment": "12 pages, 4 figures, 4 tables", "summary": "Web measurements are a well-established methodology for assessing the\nsecurity and privacy landscape of the Internet. However, existing top lists of\npopular websites commonly used as measurement targets are unlabeled and lack\nsemantic information about the nature of the sites they include. This\nlimitation makes targeted measurements challenging, as researchers often need\nto rely on ad-hoc techniques to bias their datasets toward specific categories\nof interest. In this paper, we investigate the use of Large Language Models\n(LLMs) as a means to enable targeted web measurement studies through their\nsemantic understanding capabilities. Building on prior literature, we identify\nkey website classification tasks relevant to web measurements and construct\ndatasets to systematically evaluate the performance of different LLMs on these\ntasks. Our results demonstrate that LLMs may achieve strong performance across\nmultiple classification scenarios. We then conduct LLM-assisted web measurement\nstudies inspired by prior work and rigorously assess the validity of the\nresulting research inferences. Our results demonstrate that LLMs can serve as a\npractical tool for analyzing security and privacy trends on the Web.", "AI": {"tldr": "This paper investigates the use of LLMs for targeted Web measurement studies, showing their effectiveness in classification tasks and their potential to improve security/privacy trend analysis.", "motivation": "Existing unlabeled website lists hinder targeted measurements, requiring ad-hoc techniques to bias datasets toward specific categories.", "method": "Identified key website classification tasks, constructed datasets to evaluate LLM performance on these tasks, and conducted LLM-assisted web measurement studies with rigorous validation.", "result": "LLMs demonstrate strong classification performance and produce valid research inferences when applied to web measurement tasks.", "conclusion": "LLMs can serve as a practical tool for analyzing security and privacy trends on the Web through targeted measurement capabilities."}}
{"id": "2510.08225", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08225", "abs": "https://arxiv.org/abs/2510.08225", "authors": ["Daniel Pressens\u00e9", "Elisavet Kozyri"], "title": "TracE2E: Easily Deployable Middleware for Decentralized Data Traceability", "comment": null, "summary": "This paper presents TracE2E, a middleware written in Rust, that can provide\nboth data explainability and compliance across multiple nodes. By mediating\ninputs and outputs of processes, TracE2E records provenance information and\nenforces data-protection policies (e.g., confidentiality, integrity) that\ndepend on the recorded provenance. Unlike existing approaches that necessitate\nsubstantial application modifications, TracE2E is designed for easy integration\ninto existing and future applications through a wrapper of the Rust standard\nlibrary's IO module. We describe how TracE2E consistently records provenance\ninformation across nodes, and we demonstrate how the compliance layer of\nTracE2E can accommodate the enforcement of multiple policies.", "AI": {"tldr": "TracE2E is a Rust-based middleware that enables data explainability and compliance enforcement across multiple nodes with minimal application modifications.", "motivation": "The need for data explainability and compliance across distributed nodes without extensive changes to existing applications motivates the development of TracE2E. Current methods require major modifications to applications, which is costly and complex.", "method": "TracE2E mediates input/output data of processes and records provenance information. It uses a wrapper of the Rust standard library's IO module to enforce data-protection policies like confidentiality and integrity based on the recorded provenance.", "result": "The paper presents a working implementation of TracE2E demonstrating consistent provenance recording across nodes and compliance with various data-protection policies. It shows little to no adaptation is needed for existing applications.", "conclusion": "TracE2E offers an innovative method for ensuring data compliance and explainability across distributed nodes while being easy to integrate with existing applications. This bridge addresses current limitations in the field."}}
{"id": "2510.08272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08272", "abs": "https://arxiv.org/abs/2510.08272", "authors": ["C\u00e9drick Austa", "Jan Tobias M\u00fchlberg", "Jean-Michel Dricot"], "title": "Systematic Assessment of Cache Timing Vulnerabilities on RISC-V Processors", "comment": null, "summary": "While interest in the open RISC-V instruction set architecture is growing,\ntools to assess the security of concrete processor implementations are lacking.\nThere are dedicated tools and benchmarks for common microarchitectural\nside-channel vulnerabilities for popular processor families such as Intel\nx86-64 or ARM, but not for RISC-V. In this paper we describe our efforts in\nporting an Intel x86-64 benchmark suite for cache-based timing vulnerabilities\nto RISC-V. We then use this benchmark to evaluate the security of three\ncommercially available RISC-V processors, the T-Head C910 and the SiFive U54\nand U74 cores. We observe that the C910 processor exhibits more distinct timing\ntypes than the other processors, leading to the assumption that code running on\nthe C910 would be exposed to more microarchitectural vulnerability sources. In\naddition, our evaluation reveals that $37.5\\%$ of the vulnerabilities covered\nby the benchmark exist in all processors, while only $6.8\\%$ are absent from\nall cores. Our work, in particular the ported benchmark, aims to support RISC-V\nprocessor designers to identify leakage sources early in their designs and to\nsupport the development of countermeasures.", "AI": {"tldr": "The paper ported an existing x86-64 benchmark for cache-based timing vulnerabilities to RISC-V and evaluated the security of three RISC-V processors.", "motivation": "The researchers aim to provide tools for RISC-V processor security evaluation, addressing the lack of specific tools for this open architecture. This supports designers in identifying leakage sources and developing countermeasures.", "method": "The methodology involved porting an x86-64 benchmark suite to RISC-V to assess microarchitectural side-channel vulnerabilities.", "result": "The C910 processor showed more distinct timing types, suggesting higher vulnerability potential. 37.5% of vulnerabilities exist in all processors, while 6.8% were completely absent across all cores.", "conclusion": "The RISC-V ported benchmark serves as a useful tool for detecting vulnerabilities early in design phases and promoting secure development practices for RISC-V processors."}}
{"id": "2510.08333", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08333", "abs": "https://arxiv.org/abs/2510.08333", "authors": ["Mika\u00ebla Ngambo\u00e9", "Jean-Simon Marrocco", "Jean-Yves Ouattara", "Jos\u00e9 M. Fernandez", "Gabriela Nicolescu"], "title": "New Machine Learning Approaches for Intrusion Detection in ADS-B", "comment": "This is the author's version of the work accepted for publication\n  Digital Avionics Systems Conference (DASC) 2025. The final version will be\n  available via IEEE Xplore", "summary": "With the growing reliance on the vulnerable Automatic Dependent\nSurveillance-Broadcast (ADS-B) protocol in air traffic management (ATM),\nensuring security is critical. This study investigates emerging machine\nlearning models and training strategies to improve AI-based intrusion detection\nsystems (IDS) for ADS-B. Focusing on ground-based ATM systems, we evaluate two\ndeep learning IDS implementations: one using a transformer encoder and the\nother an extended Long Short-Term Memory (xLSTM) network, marking the first\nxLSTM-based IDS for ADS-B. A transfer learning strategy was employed, involving\npre-training on benign ADS-B messages and fine-tuning with labeled data\ncontaining instances of tampered messages. Results show this approach\noutperforms existing methods, particularly in identifying subtle attacks that\nprogressively undermine situational awareness. The xLSTM-based IDS achieves an\nF1-score of 98.9%, surpassing the transformer-based model at 94.3%. Tests on\nunseen attacks validated the generalization ability of the xLSTM model.\nInference latency analysis shows that the 7.26-second delay introduced by the\nxLSTM-based IDS fits within the Secondary Surveillance Radar (SSR) refresh\ninterval (5-12 s), although it may be restrictive for time-critical operations.\nWhile the transformer-based IDS achieves a 2.1-second latency, it does so at\nthe cost of lower detection performance.", "AI": {"tldr": "This paper proposes xLSTM-based IDS for ADS-B with transfer learning, achieving 98.9% F1-score while balancing latency within SSR intervals.", "motivation": "ADS-B protocol vulnerabilities in air traffic management demand improved intrusion detection systems to ensure operational security against escalating threats.", "method": "Evaluated transformer encoder and xLSTM deep learning models via transfer learning (pre-training on benign ADS-B messages, fine-tuning with tampered data), focusing on ground-based ATM systems.", "result": "xLSTM-based IDS achieved 98.9% F1-score (vs 94.3% for transformer model), 7.26s latency within SSR refresh intervals, and demonstrated strong generalization for unseen attacks.", "conclusion": "xLSTM outperforms existing methods for ADS-B IDS in attack detection accuracy, though latency requires careful consideration for time-critical operations."}}
{"id": "2510.08343", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08343", "abs": "https://arxiv.org/abs/2510.08343", "authors": ["Anne M\u00fcller", "Mohd Kashif", "Nico D\u00f6ttling"], "title": "A Haskell to FHE Transpiler", "comment": null, "summary": "Fully Homomorphic Encryption (FHE) enables the evaluation of programs\ndirectly on encrypted data. However, because only basic operations can be\nperformed on ciphertexts, programs must be expressed as boolean or arithmetic\ncircuits. This low-level representation makes implementing applications for FHE\nsignificantly more cumbersome than writing code in a high-level language. To\nreduce this burden, several transpilers have been developed that translate\nhigh-level code into circuit representations. In this work, we extend the range\nof high-level languages that can target FHE by introducing a transpiler for\nHaskell, which converts Haskell programs into Boolean circuits suitable for\nhomomorphic evaluation. Our second contribution is the automatic\nparallelization of these generated circuits. We implement an evaluator that\nexecutes gates in parallel by parallelizing each layer of the circuit. We\ndemonstrate the effectiveness of our approach on two key applications: Private\nInformation Retrieval (PIR) and the AES encryption standard. Prior work has\nparallelized AES encryption manually. We demonstrate that the automated method\noutperforms some but not all manual parallelizations of AES evaluations under\nFHE. We achieve an evaluation time of 28 seconds for a parallel execution with\n16 threads and an evaluation time of 8 seconds for a parallel execution with\n100 threads", "AI": {"tldr": "A Haskell-to-FHE transpiler with automatic parallelization improves FHE application development, achieving competitive AES performance with scalable multi-threaded execution.", "motivation": "Current FHE implementations require laborious manual circuit design; this work addresses the need for high-level language support and automated optimization to streamline FHE application development.", "method": "The authors developed a transpiler converting Haskell programs into Boolean circuits for FHE, paired with an evaluator that automatically parallelizes circuit layers via thread-based execution.", "result": "Achieved AES evaluation times of 28 seconds (16 threads) and 8 seconds (100 threads), outperforming some manual parallelizations while highlighting areas for further optimization.", "conclusion": "The paper concludes that the introduction of a Haskell transpiler and automated parallelization significantly enhances the development of FHE applications, demonstrating competitive performance in AES encryption benchmarks with scalable thread usage."}}
{"id": "2510.08355", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08355", "abs": "https://arxiv.org/abs/2510.08355", "authors": ["Kaustabh Barman", "Fabian Piper", "Sanjeet Raj Pandey", "Axel Kuepper"], "title": "ExPrESSO: Zero-Knowledge backed Extensive Privacy Preserving Single Sign-on", "comment": null, "summary": "User authentication is one of the most important aspects for secure\ncommunication between services and end-users over the Internet. Service\nproviders leverage Single-Sign On (SSO) to make it easier for their users to\nauthenticate themselves. However, standardized systems for SSO, such as OIDC,\ndo not guarantee user privacy as identity providers can track user activities.\nWe propose a zero-knowledge-based mechanism that integrates with OIDC to let\nusers authenticate through SSO without revealing information about the service\nprovider. Our system leverages Groth's zk-SNARK to prove membership of\nsubscribed service providers without revealing their identity. We adopt a\ndecentralized and verifiable approach to set up the prerequisites of our\nconstruction that further secures and establishes trust in the system. We set\nup high security targets and achieve them with minimal storage and latency\ncost, proving that our research can be adopted for production.", "AI": {"tldr": "TLDR: The paper introduces a zero-knowledge authentication system that improves user privacy with SSO by using zk-SNARKs to prove subscription without exposing identities.", "motivation": "The paper demonstrates that standardized user authentication systems, like OIDC, do not address the issue of tracking user activities by identity providers, which can compromise user privacy. This represents a substantial motivation to enhance the existing SSO framework with a privacy-preserving approach, ensuring user activities remain confidential.", "method": "The paper's approach is to build on Groth's work with zk-SNARKs, constructing a system that substantiates user membership in a set of service providers through cryptographic zero-knowledge proofs, without disclosing the specific identities of the providers. This method supports the main objective by maintaining the usability of SSO while adding layers of privacy and anonymity to user interactions.", "result": "Our novel solution achieves high security targets with minimal storage and latency cost, effectively balancing user privacy and system performance. This result underscores the system's practicality for real-world implementation and provides impactful insights for further advancements in privacy-preserving authentication technologies.", "conclusion": "The conclusion states that the introduced approach can effectively be implemented in production, offering Secure and decentralized user authentication with SSO through zero-knowledge proofs, which contributes positively to enhancing privacy in user-service interactions."}}
{"id": "2510.08479", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.08479", "abs": "https://arxiv.org/abs/2510.08479", "authors": ["Jinsong Mao", "Benjamin E. Ujcich", "Shiqing Ma"], "title": "Rethinking Provenance Completeness with a Learning-Based Linux Scheduler", "comment": null, "summary": "Provenance plays a critical role in maintaining traceability of a system's\nactions for root cause analysis of security threats and impacts. Provenance\ncollection is often incorporated into the reference monitor of systems to\nensure that an audit trail exists of all events, that events are completely\ncaptured, and that logging of such events cannot be bypassed. However, recent\nresearch has questioned whether existing state-of-the-art provenance collection\nsystems fail to ensure the security guarantees of a true reference monitor due\nto the 'super producer threat' in which provenance generation can overload a\nsystem to force the system to drop security-relevant events and allow an\nattacker to hide their actions. One approach towards solving this threat is to\nenforce resource isolation, but that does not fully solve the problems\nresulting from hardware dependencies and performance limitations.\n  In this paper, we show how an operating system's kernel scheduler can\nmitigate this threat, and we introduce Venus, a learned scheduler for Linux\nspecifically designed for provenance. Unlike conventional schedulers that\nignore provenance completeness requirements, Venus leverages reinforcement\nlearning to learn provenance task behavior and to dynamically optimize resource\nallocation. We evaluate Venus's efficacy and show that Venus significantly\nimproves both the completeness and efficiency of provenance collection systems\ncompared to traditional scheduling, while maintaining reasonable overheads and\neven improving overall runtime in certain cases compared to the default Linux\nscheduler.", "AI": {"tldr": "The paper introduces Venus, a learned scheduler for Linux that improves the completeness and efficiency of provenance collection by leveraging reinforcement learning, addressing the super producer threat by optimizing resource allocation dynamically.", "motivation": "Provenance collection is essential for security but is at risk of incomplete logging due to system overload (super producer threat). Traditional solutions like resource isolation have limitations from hardware and performance.", "method": "A Provenance-Aware Scheduler: VENUS introduces a reinforcement learning (RL)-based kernel scheduler optimized for provenance collection. Traditional schedulers do not consider the unique characteristics of provenance tasks.", "result": "The experiments show that Venus significantly improves the completeness and efficiency of provenance collection compared to traditional scheduling while maintaining acceptable overhead and sometimes improving overall system runtime.", "conclusion": "VENUS is the first system that leverages reinforcement learning in a kernel scheduler to improve provenance collection. It provides a scalable and dynamic approach to managing the super producer threat."}}
{"id": "2510.08496", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08496", "abs": "https://arxiv.org/abs/2510.08496", "authors": ["Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman", "Ahmad Alsharif"], "title": "AI-Driven Post-Quantum Cryptography for Cyber-Resilient V2X Communication in Transportation Cyber-Physical Systems", "comment": null, "summary": "Transportation Cyber-Physical Systems (TCPS) integrate physical elements,\nsuch as transportation infrastructure and vehicles, with cyber elements via\nadvanced communication technologies, allowing them to interact seamlessly. This\nintegration enhances the efficiency, safety, and sustainability of\ntransportation systems. TCPS rely heavily on cryptographic security to protect\nsensitive information transmitted between vehicles, transportation\ninfrastructure, and other entities within the transportation ecosystem,\nensuring data integrity, confidentiality, and authenticity. Traditional\ncryptographic methods have been employed to secure TCPS communications, but the\nadvent of quantum computing presents a significant threat to these existing\nsecurity measures. Therefore, integrating Post-Quantum Cryptography (PQC) into\nTCPS is essential to maintain secure and resilient communications. While PQC\noffers a promising approach to developing cryptographic algorithms resistant to\nquantum attacks, artificial intelligence (AI) can enhance PQC by optimizing\nalgorithm selection, resource allocation, and adapting to evolving threats in\nreal-time. AI-driven PQC approaches can improve the efficiency and\neffectiveness of PQC implementations, ensuring robust security without\ncompromising system performance. This chapter introduces TCPS communication\nprotocols, discusses the vulnerabilities of corresponding communications to\ncyber-attacks, and explores the limitations of existing cryptographic methods\nin the quantum era. By examining how AI can strengthen PQC solutions, the\nchapter presents cyber-resilient communication strategies for TCPS.", "AI": {"tldr": "The paper explores integrating Post-Quantum Cryptography (PQC)\u2014enhanced by artificial intelligence (AI)\u2014into Transportation Cyber-Physical Systems (TCPS) to address quantum computing threats. It highlights vulnerabilities in traditional cryptographic methods and proposes AI-driven strategies for secure, adaptive TCPS communications.", "motivation": "TCPS relies on cryptographic security vulnerable to quantum attacks. Existing methods lack resilience against quantum threats, necessitating robust, forward-looking solutions to protect transportation infrastructure, vehicles, and data integrity.", "method": "The study analyzes TCPS communication protocols, identifies vulnerabilities to cyber-attacks, and evaluates limitations of traditional cryptography. It proposes AI-driven PQC solutions, leveraging AI for algorithm selection optimization, real-time threat adaptation, and resource allocation.", "result": "Proposed strategies include AI-enhanced PQC to strengthen security resilience, improve algorithm efficiency, and maintain system performance. Frameworks for cyber-resilient communication in TCPS are developed, addressing quantum-era risks.", "conclusion": "Integrating AI with PQC is crucial for securing TCPS against future quantum threats. This approach ensures adaptive, efficient, and sustainable security solutions for transportation systems in the era of quantum computing."}}
