{"id": "2507.12472", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12472", "abs": "https://arxiv.org/abs/2507.12472", "authors": ["Lingzhe Zhang", "Tong Jia", "Mengxi Jia", "Yifan Wu", "Aiwei Liu", "Yong Yang", "Zhonghai Wu", "Xuming Hu", "Philip S. Yu", "Ying Li"], "title": "A Survey of AIOps in the Era of Large Language Models", "comment": "Accepted By CSUR, an extended version of \"A Survey of AIOps for\n  Failure Management in the Era of Large Language Models\" [arXiv:2406.11213]", "summary": "As large language models (LLMs) grow increasingly sophisticated and\npervasive, their application to various Artificial Intelligence for IT\nOperations (AIOps) tasks has garnered significant attention. However, a\ncomprehensive understanding of the impact, potential, and limitations of LLMs\nin AIOps remains in its infancy. To address this gap, we conducted a detailed\nsurvey of LLM4AIOps, focusing on how LLMs can optimize processes and improve\noutcomes in this domain. We analyzed 183 research papers published between\nJanuary 2020 and December 2024 to answer four key research questions (RQs). In\nRQ1, we examine the diverse failure data sources utilized, including advanced\nLLM-based processing techniques for legacy data and the incorporation of new\ndata sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,\nhighlighting the emergence of novel tasks and the publication trends across\nthese tasks. RQ3 investigates the various LLM-based methods applied to address\nAIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to\nassess LLM-integrated AIOps approaches. Based on our findings, we discuss the\nstate-of-the-art advancements and trends, identify gaps in existing research,\nand propose promising directions for future exploration.", "AI": {"tldr": "This paper surveys 183 LLM4AIOps studies (2020-2024) to systematically analyze LLM applications in IT operations, addressing gaps in understanding their impact through four research questions.", "motivation": "The rapid adoption of LLMs in AIOps has outpaced our understanding of their capabilities, limitations, and transformative potential in optimizing IT operations processes and outcomes.", "method": "A comprehensive literature review analyzing 183 research papers (2020-2024) through four structured research questions examining data sources, task evolution, methodologies, and evaluation frameworks.", "result": "Identified patterns in LLM-based data processing techniques for AIOps, evolutionary trends in operational tasks, methodological approaches to LLM integration, and current evaluation practices, while revealing research gaps.", "conclusion": "The study provides a framework for understanding LLMs' role in AIOps, highlights emerging trends and methodological challenges, and proposes future research directions to advance the field."}}
{"id": "2507.12568", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12568", "abs": "https://arxiv.org/abs/2507.12568", "authors": ["Sheng Liu", "Panos Papadimitratos"], "title": "Safeguarding Federated Learning-based Road Condition Classification", "comment": "Accepted by IEEE Conference on Communications and Network Security\n  (CNS) 2025", "summary": "Federated Learning (FL) has emerged as a promising solution for\nprivacy-preserving autonomous driving, specifically camera-based Road Condition\nClassification (RCC) systems, harnessing distributed sensing, computing, and\ncommunication resources on board vehicles without sharing sensitive image data.\nHowever, the collaborative nature of FL-RCC frameworks introduces new\nvulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious\nclients (vehicles) deliberately alter their training data labels to compromise\nthe learned model inference performance. Such attacks can, e.g., cause a\nvehicle to mis-classify slippery, dangerous road conditions as pristine and\nexceed recommended speed. However, TLFAs for FL-based RCC systems are largely\nmissing. We address this challenge with a threefold contribution: 1) we\ndisclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce\na novel label-distance-based metric to precisely quantify the safety risks\nposed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging\nneuron-wise analysis of the output layer to mitigate TLFA effects. Extensive\nexperiments across three RCC tasks, four evaluation metrics, six baselines, and\nthree deep learning models demonstrate both the severity of TLFAs on FL-RCC\nsystems and the effectiveness of FLARE in mitigating the attack impact.", "AI": {"tldr": "The paper addresses Targeted Label Flipping Attacks (TLFAs) in Federated Learning (FL)-based Road Condition Classification (RCC) systems for autonomous vehicles, proposing a label-distance-based safety metric and a defense mechanism called FLARE to mitigate these attacks.", "motivation": "FL-RCC systems face critical vulnerabilities to TLFAs, where malicious vehicles alter labels to compromise road condition safety classification (e.g., mislabeling dangerous roads as safe), but this threat remains underexplored.", "method": "1) Analyzed existing FL-RCC systems' vulnerability to TLFAs; 2) Introduced a novel label-distance-based metric to quantify safety risks; 3) Proposed FLARE, a defense leveraging neuron-wise output layer analysis for TLFA mitigation.", "result": "Experiments on three RCC tasks, four metrics, six baselines, and three models demonstrated the severity of TLFAs and FLARE's effectiveness in reducing attack impact, with safety risks quantified via the new metric.", "conclusion": "TLFAs pose significant safety threats to FL-RCC systems, but FLARE successfully mitigates them while the proposed metric enables precise risk quantification, enhancing FL-based autonomous driving security."}}
{"id": "2507.12480", "categories": ["cs.SE", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.12480", "abs": "https://arxiv.org/abs/2507.12480", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "LLM-Powered Quantum Code Transpilation", "comment": "IEEE International Conference on Quantum Computing and Engineering\n  (QCE) 2025 - Extended Abstract", "summary": "There exist various Software Development Kits (SDKs) tailored to different\nquantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples\ninclude but are not limited to Qiskit, Cirq, and PennyLane. However, this\ndiversity presents significant challenges for interoperability and\ncross-platform development of hybrid quantum-classical software systems.\nTraditional rule-based transpilers for translating code between QSDKs are\ntime-consuming to design and maintain, requiring deep expertise and rigid\nmappings in the source and destination code. In this study, we explore the use\nof Large Language Models (LLMs) as a flexible and automated solution.\nLeveraging their pretrained knowledge and contextual reasoning capabilities, we\nposition LLMs as programming language-agnostic transpilers capable of\nconverting quantum programs from one QSDK to another while preserving\nfunctional equivalence. Our approach eliminates the need for manually defined\ntransformation rules and offers a scalable solution to quantum software\nportability. This work represents a step toward enabling intelligent,\ngeneral-purpose transpilation in the quantum computing ecosystem.", "AI": {"tldr": "The paper proposes using Large Language Models (LLMs) as automated transpilers to address interoperability challenges between Quantum SDKs (QSDKs), eliminating the need for rigid, rule-based mappings.", "motivation": "Quantum SDKs (QSDKs) vary across platforms, creating barriers to cross-platform development for hybrid quantum-classical systems. Rule-based transpilers are labor-intensive, requiring expertise and inflexible mappings for accurate code translation between QSDKs.", "method": "The authors explore LLMs as language-agnostic transpilers, leveraging their pre-trained knowledge and contextual reasoning to convert quantum programs between QSDKs while maintaining functional equivalence, without manual transformation rules.", "result": "The approach demonstrates scalable quantum software portability by automating code translation between QSDKs, achieving functional equivalence without explicitly defined rules or platform-specific rigid mappings.", "conclusion": "LLMs offer a general-purpose, intelligent solution for quantum transpilation, advancing cross-platform development and reducing reliance on expertise for maintaining interoperability in quantum computing ecosystems."}}
{"id": "2507.12670", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.12670", "abs": "https://arxiv.org/abs/2507.12670", "authors": ["Shogo Murasaki", "Kazumasa Omote", "Keita Emura"], "title": "On the Consideration of Vanity Address Generation via Identity-Based Signatures", "comment": null, "summary": "An address is indicated as an identifier of the user on the blockchain, and\nis defined by a hash value of the ECDSA verification key. A vanity address is\nan address that embeds custom characters such as a name. To generate a vanity\naddress, a classical try-and-error method is employed, and thus the number of\ncharacters to be embedded is limited. In this paper, we focus on the\nfunctionality of identity-based signatures (IBS) where any strings can be\nemployed as a verification key, and explore whether IBS can be used for\ngenerating a vanity address. We attach importance to the fact that it is not\nrealistic to replace ECDSA with key recovery, which is currently employed for\nissuing transactions in Ethereum, to an IBS scheme. Even if this replacement is\npossible, it is not a reasonable price for the ease of the vanity address\ngeneration. Thus, we pay attention to a generic construction of IBS from\nsignatures, and construct an IBS scheme from ECDSA with key recovery. Though we\ncannot directly generate a vanity address due to the key recovery functionality\nof the underlying ECDSA, we can connect any string with an address due to the\nfunctionality of IBS that can give additional meaning to the address. We\nimplement our system by Solidity, and demonstrate that the gas cost is almost\nsame as that of the ECDSA signature verification.", "AI": {"tldr": "This paper explores generating vanity addresses on blockchain using identity-based signatures (IBS) to overcome ECDSA's limitations while maintaining Ethereum's key recovery mechanisms and gas efficiency.", "motivation": "Current ECDSA-based blockchain addresses require a try-and-error approach to generate vanity addresses, limiting embedded character count. Replacing ECDSA with key recovery mechanisms is impractical for Ethereum's transaction system, necessitating a balanced solution.", "method": "The authors construct an IBS scheme from ECDSA with key recovery functionality, leveraging IBS's ability to use arbitrary strings as verification keys for meaningful address customization without full protocol replacement.", "result": "The implementation in Solidity demonstrates equivalent gas costs to ECDSA signature verification, proving technical feasibility. While direct vanity address generation is constrained by ECDSA key recovery, IBS enables linking any string to an address through its signature mechanism.", "conclusion": "IBS from ECDSA with key recovery offers a practical pathway for customizable addresses (vanity-like) without compromising Ethereum's existing transaction verification system or economic efficiency, demonstrating a viable compatibility solution."}}
{"id": "2507.12482", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.LG", "68N30, 68T05, 68T50", "D.2.5; D.2.7; F.3.2; I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.12482", "abs": "https://arxiv.org/abs/2507.12482", "authors": ["Ishraq Khan", "Assad Chowdary", "Sharoz Haseeb", "Urvish Patel"], "title": "Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding", "comment": "10 pages, 10 figures, 7 tables, IEEE Conference format, Q4 2025 model\n  release, Q1 2026 Kodezi OS deployment", "summary": "Large Language Models (LLMs) have advanced code generation and software\nautomation, but are fundamentally constrained by limited inference-time context\nand lack of explicit code structure reasoning. We introduce Kodezi Chronos, a\nnext-generation architecture for autonomous code understanding, debugging, and\nmaintenance, designed to operate across ultra-long contexts comprising entire\ncodebases, histories, and documentation, all without fixed window limits.\nKodezi Chronos leverages a multi-level embedding memory engine, combining\nvector and graph-based indexing with continuous code-aware retrieval. This\nenables efficient and accurate reasoning over millions of lines of code,\nsupporting repository-scale comprehension, multi-file refactoring, and\nreal-time self-healing actions. Our evaluation introduces a novel Multi Random\nRetrieval benchmark, specifically tailored to the software engineering domain.\nUnlike classical retrieval benchmarks, this method requires the model to\nresolve arbitrarily distant and obfuscated associations across code artifacts,\nsimulating realistic tasks such as variable tracing, dependency migration, and\nsemantic bug localization. Chronos outperforms prior LLMs and code models,\ndemonstrating a 23% improvement in real-world bug detection and reducing\ndebugging cycles by up to 40% compared to traditional sequence-based\napproaches. By natively interfacing with IDEs and CI/CD workflows, Chronos\nenables seamless, autonomous software maintenance, elevating code reliability\nand productivity while reducing manual effort. These results mark a critical\nadvance toward self-sustaining, continuously optimized software ecosystems.", "AI": {"tldr": "Kodezi Chronos is a next-gen architecture for autonomous code understanding/debugging, overcoming inference-time context limits through multi-level embedding memory and graph-based indexing, achieving 23% better bug detection and 40% fewer debugging cycles. Natively integrates with IDEs/CI/CD.", "motivation": "LLMs face challenges in handling large codebases due to limited context length and inability to reason about explicit code structures, hindering effective software maintenance and debugging.", "method": "Utilizes multi-level embedding memory engine with vector/graph-based indexing, continuous code-aware retrieval, and repository-scale comprehension capabilities to process ultra-long contexts across codebases/histories/documentation.", "result": "Chronos demonstrates 23% improvement in real-world bug detection accuracy and reduces debugging cycles by up to 40% compared to traditional LLMs/code models using the new Multi Random Retrieval benchmark.", "conclusion": "Kodezi Chronos represents a critical step toward self-sustaining software ecosystems by enabling autonomous code maintenance with native IDE/CI/CD integration, achieving state-of-the-art results in complex code task resolution."}}
{"id": "2507.12919", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.12919", "abs": "https://arxiv.org/abs/2507.12919", "authors": ["Victoria Childress", "Josh Collyer", "Jodie Knapp"], "title": "Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense", "comment": "35 pages, Under review for ACM Computing Surveys", "summary": "Architectural backdoors pose an under-examined but critical threat to deep\nneural networks, embedding malicious logic directly into a model's\ncomputational graph. Unlike traditional data poisoning or parameter\nmanipulation, architectural backdoors evade standard mitigation techniques and\npersist even after clean retraining. This survey systematically consolidates\nresearch on architectural backdoors, spanning compiler-level manipulations,\ntainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging\ndetection and defense strategies, including static graph inspection, dynamic\nfuzzing, and partial formal verification, and highlight their limitations\nagainst distributed or stealth triggers. Despite recent progress, scalable and\npractical defenses remain elusive. We conclude by outlining open challenges and\nproposing directions for strengthening supply-chain security, cryptographic\nmodel attestations, and next-generation benchmarks. This survey aims to guide\nfuture research toward comprehensive defenses against structural backdoor\nthreats in deep learning systems.", "AI": {"tldr": "This survey examines architectural backdoors in deep neural networks, which embed malicious logic into computational graphs, evading traditional defenses. It highlights shortcomings in current detection methods and proposes research directions for improving security.", "motivation": "Architectural backdoors represent a critical, understudied threat to deep learning systems, persisting through clean retraining and escaping standard security measures, necessitating specialized mitigation strategies.", "method": "The paper conducts a systematic consolidation of research on architectural backdoors, covering compiler-level manipulations, AutoML pipeline compromises, supply-chain vulnerabilities, and evaluates emerging detection/defense approaches like static analysis and formal verification.", "result": "Despite progress in detection techniques (e.g., static graph inspection), practical and scalable defenses remain lacking, particularly against sophisticated triggers like distributed or stealth backdoor activations.", "conclusion": "The survey identifies open challenges in structural backdoor research and advocates for advancing supply-chain security frameworks, cryptographic model attestations, and next-gen benchmarks to develop robust mitigation solutions."}}
{"id": "2507.12483", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12483", "abs": "https://arxiv.org/abs/2507.12483", "authors": ["Dong Wang", "Hanmo You", "Lingwei Zhu", "Kaiwei Lin", "Zheng Chen", "Chen Yang", "Junji Yu", "Zan Wang", "Junjie Chen"], "title": "A Survey of Reinforcement Learning for Software Engineering", "comment": null, "summary": "Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential\ndecision-making and has attracted growing interest across various domains,\nparticularly following the advent of Deep Reinforcement Learning (DRL) in 2015.\nSimultaneously, the rapid advancement of Large Language Models (LLMs) has\nfurther fueled interest in integrating RL with LLMs to enable more adaptive and\nintelligent systems. In the field of software engineering (SE), the increasing\ncomplexity of systems and the rising demand for automation have motivated\nresearchers to apply RL to a broad range of tasks, from software design and\ndevelopment to quality assurance and maintenance. Despite growing research in\nRL-for-SE, there remains a lack of a comprehensive and systematic survey of\nthis evolving field. To address this gap, we reviewed 115 peer-reviewed studies\npublished across 22 premier SE venues since the introduction of DRL. We\nconducted a comprehensive analysis of publication trends, categorized SE topics\nand RL algorithms, and examined key factors such as dataset usage, model design\nand optimization, and evaluation practices. Furthermore, we identified open\nchallenges and proposed future research directions to guide and inspire ongoing\nwork in this evolving area. To summarize, this survey offers the first\nsystematic mapping of RL applications in software engineering, aiming to\nsupport both researchers and practitioners in navigating the current landscape\nand advancing the field. Our artifacts are publicly available:\nhttps://github.com/KaiWei-Lin-lanina/RL4SE.", "AI": {"tldr": "The paper presents the first systematic survey of Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) applications in software engineering since 2015, analyzing 115 peer-reviewed studies from top venues to identify trends, methods, datasets, and evaluation practices while addressing open challenges and future directions.", "motivation": "Increasing system complexity and automation demands in software engineering (SE) have driven researchers to apply RL/DRL to tasks like design, development, and maintenance. However, no comprehensive review exists to synthesize advancements, challenges, or opportunities in this dynamic field.", "method": "The authors conducted a systematic mapping and review of 115 publications across 22 top SE conferences/journals since 2015. They classified studies based on SE areas, RL algorithms, dataset usage, model design, optimization approaches, and evaluation practices.", "result": "The analysis reveals publication trends in RL/DRL for SE, categorizes applications (e.g., code generation, testing, maintenance), highlights prevalent algorithms and challenges, and exposes gaps in dataset sharing, model interpretability, and evaluation consistency.", "conclusion": "This survey provides a foundational roadmap for RL/DRL in SE, offering actionable insights for researchers and practitioners to advance algorithmic innovation, data practices, and evaluation standards in this nascent domain."}}
{"id": "2507.12937", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.12937", "abs": "https://arxiv.org/abs/2507.12937", "authors": ["Zhuohan Cui", "Zikun Song"], "title": "Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach", "comment": null, "summary": "This paper presents a comprehensive analysis of T-Mobile's critical data\nbreaches in 2021 and 2023, alongside a full-spectrum security audit targeting\nits systems, infrastructure, and publicly exposed endpoints. By combining\ncase-based vulnerability assessments with active ethical hacking\ntechniques--including Shodan reconnaissance, API misuse simulations, VNC\nbrute-forcing, firmware reverse engineering, and web application scans--we\nuncover structural weaknesses persisting beyond the initial breach events.\nBuilding on these findings, we propose a multi-layered defensive strategy\nencompassing Zero Trust Architecture, granular role-based access control,\nnetwork segmentation, firmware encryption using AES with integrity checks, and\nAPI rate limiting and token lifecycle control. Financial modelling demonstrates\nthat a five-year investment yields less than 1.1% of expected breach losses,\nvalidating the cost-effectiveness of proactive security measures. Our work\nbridges post-incident forensic analysis with hands-on security evaluation,\nproviding an actionable blueprint for large-scale telecoms seeking operational\nresilience, regulatory compliance, and cross-domain threat readiness.", "AI": {"tldr": "This study analyzes T-Mobile's 2021/2023 data breaches through hands-on security testing and proposes cost-effective defenses validated by financial modeling.", "motivation": "The paper addresses the urgent need for telecom providers to achieve operational resilience against escalating data breach risks while maintaining regulatory compliance.", "method": "Combined case-based vulnerability assessments with practical ethical hacking (Shodan reconnaissance, API misuse simulations, VNC brute-forcing, firmware reverse engineering, web application scans) and economic analysis.", "result": "Identified persistent architectural weaknesses, developed multi-layered security framework (Zero Trust, RBAC, network segmentation, AES firmware encryption, API rate limiting), and proved cost-effectiveness through 5-year financial modeling showing losses would be 89 times higher without proactive measures.", "conclusion": "Provides an actionable security blueprint for large telecoms to enhance breach prevention through integrated forensic analysis and hands-on security evaluation, demonstrating proactive measures' value for threat readiness and compliance."}}
{"id": "2507.12558", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12558", "abs": "https://arxiv.org/abs/2507.12558", "authors": ["Tien P. T. Le", "Anh M. T. Bui", "Huy N. D. Pham", "Alessio Bucaioni", "Phuong T. Nguyen"], "title": "When Retriever Meets Generator: A Joint Model for Code Comment Generation", "comment": "The paper has been peer-reviewed and accepted for publication in the\n  proceedings of the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "summary": "Automatically generating concise, informative comments for source code can\nlighten documentation effort and accelerate program comprehension.\nRetrieval-augmented approaches first fetch code snippets with existing comments\nand then synthesize a new comment, yet retrieval and generation are typically\noptimized in isolation, allowing irrelevant neighbors topropagate noise\ndownstream. To tackle the issue, we propose a novel approach named RAGSum with\nthe aim of both effectiveness and efficiency in recommendations. RAGSum is\nbuilt on top offuse retrieval and generation using a single CodeT5 backbone. We\nreport preliminary results on a unified retrieval-generation framework built on\nCodeT5. A contrastive pre-training phase shapes code embeddings for\nnearest-neighbor search; these weights then seed end-to-end training with a\ncomposite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes\ncomment-generation error. More importantly, a lightweight self-refinement loop\nis deployed to polish the final output. We evaluated theframework on three\ncross-language benchmarks (Java, Python, C), and compared it with three\nwell-established baselines. The results show that our approach substantially\noutperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These\nfindings indicate that tightly coupling retrieval and generationcan raise the\nceiling for comment automation and motivateforthcoming replications and\nqualitative developer studies.", "AI": {"tldr": "RAGSum is a unified code comment generation framework that tightly couples retrieval and generation using CodeT5. It employs contrastive pre-training for embeddings, joint training with composite losses, and a self-refinement loop, achieving state-of-the-art performance across Java, Python, and C benchmarks.", "motivation": "Existing methods optimize retrieval and comment generation separately, leading to noisy results from irrelevant code snippets. This paper addresses the need for holistic optimization to improve comment automation effectiveness and efficiency.", "method": "RAGSum uses a single CodeT5 architecture with contrastive pre-training to enhance embedding quality for nearest-neighbor retrieval, followed by joint end-to-end training combining top-k retrieval accuracy and generation error minimization. A lightweight self-refinement mechanism refines outputs iteratively.", "result": "Evaluation on three cross-language (Java/Python/C) datasets shows RAGSum outperforms established baselines by margins of +5.2 in BLEU-4, +7.8 in METEOR, and +9.1 in ROUTE-L, demonstrating superior effectiveness of integrated retrieval-generation approaches.", "conclusion": "Tight integration of retrieval and generation raises comment automation ceilings, validates joint optimization of both components, and motivates future work including replication studies and developer-focused qualitative analysis to solidify these findings."}}
{"id": "2507.13023", "categories": ["cs.CR", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.13023", "abs": "https://arxiv.org/abs/2507.13023", "authors": ["Fei Wu", "Danning Sui", "Thomas Thiery", "Mallesh Pai"], "title": "Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest", "comment": "Accepted by AFT 2025", "summary": "This paper provides a comprehensive empirical analysis of the economics and\ndynamics behind arbitrages between centralized and decentralized exchanges\n(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions\nfrom on-chain data and introduce a robust empirical framework to estimate\narbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging\nan extensive dataset spanning 19 months from August 2023 to March 2025, we\nestimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from\n7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing\ncentralization trends as three searchers captured three-quarters of both volume\nand extracted value. We also demonstrate that searchers' profitability is tied\nto their integration level with block builders and uncover exclusive\nsearcher-builder relationships and their market impact. Finally, we correct the\npreviously underestimated profitability of block builders who vertically\nintegrate with a searcher. These insights illuminate the darkest corner of the\nMEV landscape and highlight the critical implications of CEX-DEX arbitrages for\nEthereum's decentralization.", "AI": {"tldr": "The study analyzes CEX-DEX arbitrage on Ethereum over 19 months, finding significant MEV extraction (233.8M USD) and increasing centralization, with top 3 searchers controlling 75% of volume and profits. It reveals searcher-builder integration dynamics and underestimated builder profits where vertical integration occurs.", "motivation": "The paper aims to understand economic dynamics of cross-exchange arbitrage in Ethereum's MEV landscape to quantify its impact on decentralization, addressing limitations in prior methods for measuring arbitrage revenue without CEX behavioral data.", "method": "Developed refined heuristics for identifying arbitrage transactions from on-chain data and created an empirical framework estimating arbitrage revenue through 7.2 million transaction observations over August 2023-March 2025, incorporating analysis of searcher-builder integration patterns.", "result": "1. 233.8M USD extracted by 19 major searchers\n2. Top 3 searchers captured 75% of volume/value\n3. Searcher profitability correlated with builder integration\n4. Discovered exclusive searcher-builder relationships affecting market dynamics\n5. Corrected MEV estimates showing_builder profits from vertical integration may be 21% higher than previously thought.", "conclusion": "The findings underscore growing centralization in Ethereum MEV practices, demonstrate how searcher-builder partnerships shape market outcomes, and reveal significant underestimation of vertically integrated_builder profits. This highlights systemic risks to Ethereum's decentralized ethos through exploitative arbitrage strategies."}}
{"id": "2507.12561", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12561", "abs": "https://arxiv.org/abs/2507.12561", "authors": ["Samal Nursapa", "Anastassiya Samuilova", "Alessio Bucaioni. Phuong T. Nguyen"], "title": "ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells", "comment": "The paper has been peer-reviewed and accepted for publication in the\n  proceedings of the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "summary": "Architectural smells such as God Class, Cyclic Dependency, and Hub-like\nDependency degrade software quality and maintainability. Existing tools detect\nsuch smells but rarely suggest how to fix them. This paper explores the use of\npre-trained transformer models--CodeBERT and CodeT5--for recommending suitable\nrefactorings based on detected smells. We frame the task as a three-class\nclassification problem and fine-tune both models on over 2 million refactoring\ninstances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%\naccuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our\nresults show that transformer-based models can effectively bridge the gap\nbetween smell detection and actionable repair, laying the foundation for future\nrefactoring recommendation systems. We release all code, models, and data under\nan open license to support reproducibility and further research.", "AI": {"tldr": "This paper proposes using transformer-based models like CodeBERT and CodeT5 for recommending refactorings to fix architectural smells, achieving high accuracy and F1 scores, and releases code/data for reproducibility.", "motivation": "Existing software architectural smell detection tools lack actionable repair suggestions, creating a gap between problem identification and resolution.", "method": "Fine-tuned CodeBERT and CodeT5 on ~2 million refactoring examples from 11,149 Java projects, framing the task as three-class classification.", "result": "CodeT5 achieved 96.9% accuracy and 95.2% F1 score for smell repair recommendations, surpassing CodeBERT and traditional approaches.", "conclusion": "Transformer models effectively enable end-to-end architectural smell detection and repair, establishing a reproducible foundation for future refactoring recommendation systems."}}
{"id": "2507.13028", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.13028", "abs": "https://arxiv.org/abs/2507.13028", "authors": ["Niklas Busch", "Philip Klostermeyer", "Jan H. Klemmer", "Yasemin Acar", "Sascha Fahl"], "title": "From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange", "comment": "14 pages, 5 figures", "summary": "Hardening computer systems against cyberattacks is crucial for security.\nHowever, past incidents illustrated, that many system operators struggle with\neffective system hardening. Hence, many computer systems and applications\nremain insecure. So far, the research community lacks an in-depth understanding\nof system operators motivation, practices, and challenges around system\nhardening. With a focus on practices and challenges, we qualitatively analyzed\n316 Stack Exchange (SE) posts related to system hardening. We find that access\ncontrol and deployment-related issues are the most challenging, and system\noperators suffer from misconceptions and unrealistic expectations. Most\nfrequently, posts focused on operating systems and server applications. System\noperators were driven by the fear of their systems getting attacked or by\ncompliance reasons. Finally, we discuss our research questions, make\nrecommendations for future system hardening, and illustrate the implications of\nour work.", "AI": {"tldr": "The study examines system operators' challenges and practices in cyberattack hardening through 316 Stack Exchange posts, identifying access control and deployment issues, misconceptions, and motivations like fear of attacks or compliance needs.", "motivation": "To address the lack of understanding in the research community regarding system operators' motivations and challenges in hardening systems against cyberattacks, aiming to improve system security practices.", "method": "Qualitative analysis of 316 Stack Exchange (SE) posts related to system hardening, focusing on practices and challenges.", "result": "Key challenges include access control and deployment issues; operators often have misconceptions and unrealistic expectations. Posts mainly addressed operating systems and server applications, with motivations linked to fear of attacks or compliance.", "conclusion": "The study discusses research questions, provides recommendations for future system hardening strategies, and highlights implications for enhancing operator practices and system security frameworks."}}
{"id": "2507.12642", "categories": ["cs.SE", "cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.12642", "abs": "https://arxiv.org/abs/2507.12642", "authors": ["Kiana Kheiri", "Aamna Aamir", "Andriy Miranskyy", "Chen Ding"], "title": "QSpark: Towards Reliable Qiskit Code Generation", "comment": null, "summary": "Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and\nStarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two\nRL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference\nOptimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit\nHumanEval benchmark, ORPO reaches 56.29\\% Pass@1 ($\\approx+10$ pp over\nGranite-8B-QK) and GRPO hits 49\\%, both beating all general-purpose baselines;\non the original HumanEval they score 65.90\\% and 63.00\\%. GRPO excels on basic\ntasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five\nadvanced tasks, highlighting clear gains yet room for progress in AI-assisted\nquantum programming.", "AI": {"tldr": "This paper improves AI-assisted quantum programming by fine-tuning a 32B model with GRPO and ORPO reinforcement learning methods on quantum code. ORPO achieves 56.29% Pass@1 on Qiskit HumanEval, surpassing prior baselines and showing strong performance on intermediate tasks, while GRPO excels at basic tasks but both methods highlight limitations in handling advanced quantum programming tasks.", "motivation": "Quantum circuits require error resilience, but existing LLMs like Granite-20B-Code and StarCoder frequently produce flawed Qiskit code. This creates a clear need for specialized training approaches to enhance quantum programming capabilities in AI models.", "method": "The authors fine-tuned a 32B language model using two reinforcement learning strategies: Group Relative Policy Optimization (GRPO) for basic task mastery and Odds-Ratio Preference Optimization (ORPO) for intermediate task improvement. They employed a richly annotated synthetic quantum code dataset for training and evaluation.", "result": "ORPO achieved 56.29% Pass@1 on Qiskit HumanEval (a +10 percentage point improvement over Granite-8B-QK) and 65.90% on original HumanEval. GRPO reached 49% Pass@1 on Qiskit HumanEval and 63.00% on original HumanEval, outperforming general-purpose baselines but underperforming ORPO on intermediate tasks.", "conclusion": "The work demonstrates significant progress in quantum-specific code generation (42/54 basic and 41/68 intermediate task success) but reveals limitations in handling advanced tasks. This highlights both the potential and current constraints of AI-assisted quantum programming, suggesting focused improvements are needed for more sophisticated applications."}}
{"id": "2507.13038", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.13038", "abs": "https://arxiv.org/abs/2507.13038", "authors": ["Yu Cui", "Hongyang Du"], "title": "MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems", "comment": null, "summary": "Multi-agent debate (MAD) systems leverage collaborative interactions among\nlarge language models (LLMs) agents to improve reasoning capabilities. While\nrecent studies have focused on increasing the accuracy and scalability of MAD\nsystems, their security vulnerabilities have received limited attention. In\nthis work, we introduce MAD-Spear, a targeted prompt injection attack that\ncompromises a small subset of agents but significantly disrupts the overall MAD\nprocess. Manipulated agents produce multiple plausible yet incorrect responses,\nexploiting LLMs' conformity tendencies to propagate misinformation and degrade\nconsensus quality. Furthermore, the attack can be composed with other\nstrategies, such as communication attacks, to further amplify its impact by\nincreasing the exposure of agents to incorrect responses. To assess MAD's\nresilience under attack, we propose a formal definition of MAD fault-tolerance\nand develop a comprehensive evaluation framework that jointly considers\naccuracy, consensus efficiency, and scalability. Extensive experiments on five\nbenchmark datasets with varying difficulty levels demonstrate that MAD-Spear\nconsistently outperforms the baseline attack in degrading system performance.\nAdditionally, we observe that agent diversity substantially improves MAD\nperformance in mathematical reasoning tasks, which challenges prior work\nsuggesting that agent diversity has minimal impact on performance. These\nfindings highlight the urgent need to improve the security in MAD design.", "AI": {"tldr": "MAD-Spear is a targeted prompt injection attack that exploits LLM agents' conformity tendencies in multi-agent debate systems, significantly degrading consensus quality while demonstrating the security risks and performance impacts of adversarial agent manipulation.", "motivation": "The paper addresses the understudied security vulnerabilities in multi-agent debate (MAD) systems, where prior research focused on accuracy/scalability but overlooked fault-tolerance and robustness against adversarial attacks.", "method": "1. Designed MAD-Spear: Composes prompt injection attacks with communication strategies to manipulate a subset of agents (via plausible incorrect responses) and exploit conformity in LLMs.\n2. Proposed a formal definition of MAD fault-tolerance and an evaluation framework assessing accuracy, consensus efficiency, and scalability under attacks.", "result": "1. MAD-Spear consistently outperforms baseline attacks in degrading system performance across 5 benchmark datasets of varying difficulty.\n2. Agent diversity significantly improves mathematical reasoning task performance, contradicting previous claims of minimal impact on MAD systems.", "conclusion": "The study demonstrates critical security weaknesses in MAD systems and highlights the necessity of rethinking MAD architectures to incorporate robust fault-tolerance mechanisms while leveraging agent diversity for performance improvements."}}
{"id": "2507.12649", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12649", "abs": "https://arxiv.org/abs/2507.12649", "authors": ["Christine van Stiphoudt", "Sergio Potenciano Menci", "Gilbert Fridgen"], "title": "A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain", "comment": null, "summary": "The ongoing digitalisation of the smart grid is resulting in an increase in\nautomated information exchanges across distributed energy systems. This process\nhas led to the development of new information and data models when the existing\nones fall short. To prevent potential disruptions caused by flaws in the newly\ndesigned information and data models, it is essential to evaluate them during\nthe design process before they are implemented in operation.\n  Currently, general explicit evaluation approaches outside the smart grid\ndomain stay at a high level without defining clear steps. Meanwhile, implicit\nevaluation approaches in the smart grid domain focus on testing systems that\nutilise information and data models already in use for functionality in terms\nof conformance and interoperability. Notably, no combination of explicit and\nimplicit evaluation approaches for newly designed information and data models\noffers a clearly defined set of steps during their design process in the smart\ngrid context.\n  Consequently, we design a three-phase evaluation approach using design\nscience research to address this gap. Our evaluation approach combines explicit\nand implicit evaluation methods and is applicable when developing new\ninformation and data models. We use the development of an information model and\ndata model focused on industrial flexibility descriptions to refine our\nevaluation approach. Additionally, we provide lessons learned from our\nexperience.", "AI": {"tldr": "This paper proposes a three-phase evaluation approach combining explicit and implicit methods to assess newly designed information/data models in smart grids during their development, using industrial flexibility descriptions as a test case.", "motivation": "The digitalization of smart grids is increasing automated data exchanges, but flaws in new information/data models risk causing operational disruptions. Current evaluation methods either lack defined steps (explicit approaches outside smart grids) or focus only on testing existing models (implicit smart grid approaches).", "method": "The researchers used design science research methodology to develop a three-phase evaluation approach. They validated this method by creating and refining information/data models for industrial flexibility descriptions in smart grids through iterative design phases.", "result": "The three-phase evaluation approach successfully combined explicit theoretical assessment with implicit practical testing of smart grid models. They produced an industrial flexibility information/data model and documented implementation lessons learned.", "conclusion": "The paper demonstrates a structured evaluation methodology that bridges the gap between theoretical assessment and practical system integration for smart grid data models, enabling early detection of flaws to prevent operational disruptions. The approach remains applicable to other information/data model development contexts."}}
{"id": "2507.13042", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.13042", "abs": "https://arxiv.org/abs/2507.13042", "authors": ["Taki Eddine Djidjekh", "Ga\u00ebl Loubet", "Alexandru Takacs"], "title": "Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors", "comment": null, "summary": "The integration of security and energy efficiency in Internet of Things\nsystems remains a critical challenge, particularly for battery-free and\nresource-constrained devices. This paper explores the scalability and\nprotocol-agnostic nature of a backscattering-based security mechanism by\nintegrating it into Bluetooth Low Energy battery-free Wireless Sensor Network.\nThe proposed approach leverages the Wireless Power Transfer link, traditionally\nused for energy harvesting, to generate additional identification signals\nwithout increasing energy consumption or computational demands. Experimental\nvalidation demonstrates the solution's functionality using compact, low-gain\nantenna, ensuring compatibility with size-constrained applications such as\nStructural Health Monitoring and smart transport. Furthermore, this work\naddresses the challenges associated with backscattering dynamic range and\nmulti-node Wireless Sensor Network scenarios, discussing potential collisions\nbetween identification signals and proposing future improvements to enhance\ngeneralizability and scalability. The findings underscore the potential of the\nbackscattering-based security mechanism for creating secure, sustainable, and\nscalable IoT deployments across diverse protocols and applications.", "AI": {"tldr": "This paper introduces a backscattering-based security mechanism for Bluetooth Low Energy battery-free Wireless Sensor Networks. It leverages existing Wireless Power Transfer for identification signals without additional energy use, demonstrating scalability and protocol-agnostic properties.", "motivation": "Battery-free IoT devices face challenges in balancing security and energy efficiency. Traditional solutions often increase power consumption or computational demands, which is unsustainable for such constrained systems.", "method": "The approach integrates backscattering security into Bluetooth Low Energy systems using the Wireless Power Transfer link to generate identification signals. Low-gain antennas were utilized to suit size-constrained applications, while addressing dynamic range limitations and multi-node collision risks.", "result": "Experimental validation confirmed functionality with compact antennas for Structural Health Monitoring and smart transport. The study identified potential signal collisions in multi-node scenarios and proposed scalability improvements.", "conclusion": "The backscattering-based mechanism proves viable for secure, sustainable IoT deployments, offering a protocol-agnostic solution scalable across applications like WSNs. Future work aims to enhance generalizability through collision mitigation techniques."}}
{"id": "2507.12653", "categories": ["cs.SE", "cs.CL", "H.4.m"], "pdf": "https://arxiv.org/pdf/2507.12653", "abs": "https://arxiv.org/abs/2507.12653", "authors": ["Jo\u00e3o Granja-Correia", "Remedios Hern\u00e1ndez-Linares", "Luca Ferranti", "Arm\u00e9nio Rego"], "title": "A Fuzzy Approach to Project Success: Measuring What Matters", "comment": "3 pages, 1 figure, presented at FUZZ-IEEE 2025", "summary": "This paper introduces a novel approach to project success evaluation by\nintegrating fuzzy logic into an existing construct. Traditional Likert-scale\nmeasures often overlook the context-dependent and multifaceted nature of\nproject success. The proposed hierarchical Type-1 Mamdani fuzzy system\nprioritizes sustained positive impact for end-users, reducing emphasis on\nsecondary outcomes like stakeholder satisfaction and internal project success.\nThis dynamic approach may provide a more accurate measure of project success\nand could be adaptable to complex evaluations. Future research will focus on\nempirical testing and broader applications of fuzzy logic in social science.", "AI": {"tldr": "The paper proposes a hierarchical Type-1 Mamdani fuzzy system to evaluate project success by prioritizing sustained end-user impact over traditional Likert-scale measures and secondary outcomes like stakeholder satisfaction.", "motivation": "Traditional Likert-scale measures oversimplify project success, ignoring context-dependent factors and multifaceted criteria such as sustained user impact vs. transient stakeholder metrics.", "method": "A hierarchical Type-1 Mamdani fuzzy logic system was developed to dynamically weigh primary (end-user impact) and secondary (stakeholder satisfaction, internal success) success factors with context-aware prioritization.", "result": "The theoretical framework demonstrated potential for more accurate project success evaluation through context-sensitive, user-centric fuzzy logic analysis rather than rigid static scoring.", "conclusion": "This fuzzy logic approach offers an adaptable tool for complex project success assessments, with future work needed to validate the model through empirical studies and social science applications."}}
{"id": "2507.13169", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13169", "abs": "https://arxiv.org/abs/2507.13169", "authors": ["Jeremy McHugh", "Kristina \u0160ekrst", "Jon Cefalu"], "title": "Prompt Injection 2.0: Hybrid AI Threats", "comment": null, "summary": "Prompt injection attacks, where malicious input is designed to manipulate AI\nsystems into ignoring their original instructions and following unauthorized\ncommands instead, were first discovered by Preamble, Inc. in May 2022 and\nresponsibly disclosed to OpenAI. Over the last three years, these attacks have\ncontinued to pose a critical security threat to LLM-integrated systems. The\nemergence of agentic AI systems, where LLMs autonomously perform multistep\ntasks through tools and coordination with other agents, has fundamentally\ntransformed the threat landscape. Modern prompt injection attacks can now\ncombine with traditional cybersecurity exploits to create hybrid threats that\nsystematically evade traditional security controls. This paper presents a\ncomprehensive analysis of Prompt Injection 2.0, examining how prompt injections\nintegrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),\nand other web security vulnerabilities to bypass traditional security measures.\nWe build upon Preamble's foundational research and mitigation technologies,\nevaluating them against contemporary threats, including AI worms, multi-agent\ninfections, and hybrid cyber-AI attacks. Our analysis incorporates recent\nbenchmarks that demonstrate how traditional web application firewalls, XSS\nfilters, and CSRF tokens fail against AI-enhanced attacks. We also present\narchitectural solutions that combine prompt isolation, runtime security, and\nprivilege separation with novel threat detection capabilities.", "AI": {"tldr": "This paper analyzes how modern prompt injection attacks combine with web vulnerabilities like XSS/CSRF to bypass security measures, proposing hybrid threat detection and architectural solutions for AI-enhanced attacks.", "motivation": "Prompt injection attacks have evolved with agentic AI systems, combining traditional cyber exploits to systematically evade security controls, creating critical threats requiring advanced mitigation strategies.", "method": "The study evaluates prompt injection attacks' integration with XSS, CSRF, and other web vulnerabilities using recent benchmarks to test existing security tools (e.g., WAFs, filters, tokens). It proposes architectural solutions combining prompt isolation, runtime security, privilege separation, and novel threat detection.", "result": "Demonstrated failure of traditional web security controls against AI-enhanced attacks; proposed solutions integrating multi-layered security mechanisms and hybrid threat detection show improved resilience to these evolving threats.", "conclusion": "The research confirms the necessity of combining modern security architecture elements with AI-specific threat detection to address hybrid cyber-AI attacks, building upon foundational work while establishing new benchmarks for mitigation effectiveness."}}
{"id": "2507.12665", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.12665", "abs": "https://arxiv.org/abs/2507.12665", "authors": ["Salvador D. Escobedo"], "title": "Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development", "comment": "Style reviewed by a LLM for improving clarity and English syntax", "summary": "We propose the Single Conversation Methodology (SCM), a novel and pragmatic\napproach to software development using large language models (LLMs). In\ncontrast to ad hoc interactions with generative AI, SCM emphasizes a structured\nand persistent development dialogue, where all stages of a project - from\nrequirements to architecture and implementation - unfold within a single,\nlong-context conversation. The methodology is grounded on principles of\ncognitive clarity, traceability, modularity, and documentation. We define its\nphases, best practices, and philosophical stance, while arguing that SCM offers\na necessary correction to the passive reliance on LLMs prevalent in current\npractices. We aim to reassert the active role of the developer as architect and\nsupervisor of the intelligent tool.", "AI": {"tldr": "The paper introduces Single Conversation Methodology (SCM), a structured software development approach using LLMs through a single, long-context conversation, emphasizing cognitive clarity, traceability, modularity, and documentation.", "motivation": "Current practices passively rely on ad hoc LLM interactions, necessitating a correction to reassert the developer's active role as architect and supervisor.", "method": "SCM defines phases, best practices, and philosophical principles for a structured dialogue with LLMs across all project stages, from requirements to implementation.", "result": "Presentation of SCM as a framework to improve LLM-based software development through structured conversation and developer agency.", "conclusion": "SCM provides a necessary shift toward active developer engagement with LLMs, ensuring better traceability and documentation in the development process."}}
{"id": "2507.13313", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.13313", "abs": "https://arxiv.org/abs/2507.13313", "authors": ["Chao Feng", "Alberto Huertas Celdran", "Jing Han", "Heqing Ren", "Xi Cheng", "Zien Zeng", "Lucas Krauter", "Gerome Bovet", "Burkhard Stiller"], "title": "A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models", "comment": null, "summary": "This paper introduces a dataset and experimental study for decentralized\nfederated learning (DFL) applied to IoT crowdsensing malware detection. The\ndataset comprises behavioral records from benign and eight malware families. A\ntotal of 21,582,484 original records were collected from system calls, file\nsystem activities, resource usage, kernel events, input/output events, and\nnetwork records. These records were aggregated into 30-second windows,\nresulting in 342,106 features used for model training and evaluation.\nExperiments on the DFL platform compare traditional machine learning (ML),\ncentralized federated learning (CFL), and DFL across different node counts,\ntopologies, and data distributions. Results show that DFL maintains competitive\nperformance while preserving data locality, outperforming CFL in most settings.\nThis dataset provides a solid foundation for studying the security of IoT\ncrowdsensing environments.", "AI": {"tldr": "The paper presents a dataset and experimental study on decentralized federated learning (DFL) for IoT malware detection, showing DFL outperforms traditional centralized methods while preserving data locality.", "motivation": "This paper aims to address the need for effective, privacy-preserving malware detection in IoT crowdsensing environments by exploring decentralized approaches compared to traditional centralized and federated learning methods.", "method": "The authors collected system call records and other computational traces from 21,582,484 events, aggregated into 30-second windows to form 342,106 features. They conducted comparative experiments on DFL platforms, evaluating performance across varying node counts, network topologies, and data distributions relative to centralized federated learning (CFL).", "result": "Experimental results show DFL maintains competitive performance with centralized methods while preserving data locality, and outperforms CFL in most tested scenarios and configurations. The dataset proves useful for studying IoT crowdsensing security dynamics.", "conclusion": "This study establishes a foundational dataset and demonstrates the superiority of DFL over CFL for malware detection in distributed IoT settings, supporting future research on securing crowdsensing environments through decentralized machine learning approaches."}}
{"id": "2507.13035", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13035", "abs": "https://arxiv.org/abs/2507.13035", "authors": ["Keila Lucas", "Rohit Gheyi", "M\u00e1rcio Ribeiro", "Fabio Palomba", "Luana Martins", "Elvys Soares"], "title": "Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases", "comment": "7 pages, Accepted at Insightful Ideas and Emerging Results (IIER)\n  Track of the Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Manual testing, in which testers follow natural language instructions to\nvalidate system behavior, remains crucial for uncovering issues not easily\ncaptured by automation. However, these test cases often suffer from test\nsmells, quality issues such as ambiguity, redundancy, or missing checks that\nreduce test reliability and maintainability. While detection tools exist, they\ntypically require manual rule definition and lack scalability. This study\ninvestigates the potential of Small Language Models (SLMs) for automatically\ndetecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143\nreal-world Ubuntu test cases, covering seven types of test smells. Phi-4\nachieved the best results, reaching a pass@2 of 97% in detecting sentences with\ntest smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond\ndetection, SLMs autonomously explained issues and suggested improvements, even\nwithout explicit prompt instructions. They enabled low-cost, concept-driven\nidentification of diverse test smells without relying on extensive rule\ndefinitions or syntactic analysis. These findings highlight the potential of\nSLMs as efficient tools that preserve data privacy and can improve test quality\nin real-world scenarios.", "AI": {"tldr": "The paper explores using Small Language Models (SLMs) to detect and improve test smells in manual test cases, finding Phi-4 achieves 97% pass@2 detection while offering low-cost, concept-based solutions for Ubuntu test cases.", "motivation": "Manual test cases suffer from test smells like ambiguity, redundancy, and missing checks that reduce reliability and maintainability. Existing detection tools require time-consuming rule definitions and lack scalability.", "method": "Evaluated 3 SLMs (Gemma3, Llama3.2, Phi-4) on 143 real Ubuntu test cases for 7 test smell types. Analyzed detection accuracy, explanation capabilities, and improvement suggestions without explicit instructions.", "result": "Phi-4 detected test smells in sentences with 97% pass@2 accuracy. Gemma3 and Llama3.2 achieved ~91%. All models autonomously explained issues and suggested improvements, achieving concept-driven detection without extensive rules or syntax analysis.", "conclusion": "SLMs provide scalable, cost-effective test smell detection with interpretation benefits while maintaining data privacy. The results demonstrate they outperform rule-based approaches for real-world manual testing quality improvement."}}
{"id": "2507.13081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13081", "abs": "https://arxiv.org/abs/2507.13081", "authors": ["Dongming Jin", "Weisong Sun", "Jiangping Huang", "Peng Liang", "Jifeng Xuan", "Yang Liu", "Zhi Jin"], "title": "iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development", "comment": "22pages, 4 figures", "summary": "Requirements development is a critical phase as it is responsible for\nproviding a clear understanding of what stakeholders need. It involves\ncollaboration among stakeholders to extract explicit requirements and address\npotential conflicts, which is time-consuming and labor-intensive. Recently,\nmulti-agent systems for software development have attracted much attention.\nHowever, existing research provides limited support for requirements\ndevelopment and overlooks the injection of human knowledge into agents and the\nhuman-agent collaboration. % To address these issues, this paper proposes a\nknowledge-driven multi-agent framework for intelligent requirement development,\nnamed iReDev. iReDev features: iReDev consists of six knowledge-driven agents\nto support the entire requirements development. They collaboratively perform\nvarious tasks to produce a software requirements specification. iReDev focuses\non integrating human knowledge for agents, enabling them to simulate real-world\nstakeholders. iReDev uses an event-driven communication mechanism based on an\nartifact pool. Agents continuously monitor the pool and autonomously trigger\nthe next action based on its changes, enabling iReDev to handle new\nrequirements quickly. iReDev introduces a human-in-the-loop mechanism to\nsupport human-agent collaboration, ensuring that the generated artifacts align\nwith the expectations of stakeholders. We evaluated the generated artifacts and\nresults show that iReDev outperforms existing baselines in multiple aspects. We\nfurther envision three key directions and hope this work can facilitate the\ndevelopment of intelligent requirements development.", "AI": {"tldr": "The paper proposes iReDev, a knowledge-driven multi-agent framework for intelligent requirements development that integrates human knowledge and event-driven collaboration mechanisms.", "motivation": "Requirements development is typically labor-intensive and conflict-prone, with existing multi-agent systems lacking sufficient support for this phase and overlooking human knowledge injection and collaboration.", "method": "iReDev utilizes six knowledge-driven agents working with an artifact pool for event-based communication, enabling dynamic requirement handling, and incorporates a human-in-the-loop mechanism for stakeholder alignment.", "result": "Evaluation of generated artifacts demonstrated iReDev's superiority over existing baselines in multiple performance aspects.", "conclusion": "The framework effectively addresses human-agent collaboration and rapid requirement updates while proposing three future research directions to advance intelligent requirements development."}}
{"id": "2507.13095", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13095", "abs": "https://arxiv.org/abs/2507.13095", "authors": ["Dongming Jin", "Zhi Jin", "Linyu Li", "Xiaohong Chen"], "title": "A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems", "comment": "5pages, 1 figure", "summary": "Recent advances in large pretrained models have led to their widespread\nintegration as core components in modern software systems. The trend is\nexpected to continue in the foreseeable future. Unlike traditional software\nsystems governed by deterministic logic, systems powered by pretrained models\nexhibit distinctive and emergent characteristics, such as ambiguous capability\nboundaries, context-dependent behavior, and continuous evolution. These\nproperties fundamentally challenge long-standing assumptions in requirements\nengineering, including functional decomposability and behavioral\npredictability. This paper investigates this problem and advocates for a\nrethinking of existing requirements engineering methodologies. We propose a\nconceptual framework tailored to requirements engineering of\npretrained-model-enabled software systems and outline several promising\nresearch directions within this framework. This vision helps provide a guide\nfor researchers and practitioners to tackle the emerging challenges in\nrequirements engineering of pretrained-model-enabled systems.", "AI": {"tldr": "This paper addresses the challenges of requirements engineering in software systems powered by large pretrained models, proposing a conceptual framework and research directions for the field.", "motivation": "The integration of large pretrained models introduces ambiguous capability boundaries, context-dependent behavior, and continuous evolution, which contradict traditional requirements engineering assumptions like functional decomposability and behavioral predictability.", "method": "The authors conduct an investigative analysis of the emerging characteristics in model-enabled systems and propose a tailored conceptual framework for requirements engineering.", "result": "A conceptual framework was developed for requirements engineering in pretrained-model-enabled systems, with several promising research directions identified.", "conclusion": "The paper establishes a vision and guiding framework for researchers and practitioners to adapt requirements engineering methodologies to the unique characteristics of model-driven software systems."}}
{"id": "2507.13117", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13117", "abs": "https://arxiv.org/abs/2507.13117", "authors": ["Andreas Pointner", "Josef Pichler", "Herbert Pr\u00e4hofer"], "title": "Inferring Attributed Grammars from Parser Implementations", "comment": "Accepted to ICSME 2025", "summary": "Software systems that process structured inputs often lack complete and\nup-to-date specifications, which specify the input syntax and the semantics of\ninput processing. While grammar mining techniques have focused on recovering\nsyntactic structures, the semantics of input processing remains largely\nunexplored. In this work, we introduce a novel approach for inferring\nattributed grammars from parser implementations. Given an input grammar, our\ntechnique dynamically analyzes the implementation of recursive descent parsers\nto reconstruct the semantic aspects of input handling, resulting in\nspecifications in the form of attributed grammars. By observing program\nexecutions and mapping the program's runtime behavior to the grammar, we\nsystematically extract and embed semantic actions into the grammar rules. This\nenables comprehensive specification recovery. We demonstrate the feasibility of\nour approach using an initial set of programs, showing that it can accurately\nreproduce program behavior through the generated attributed grammars.", "AI": {"tldr": "This paper presents a new approach to recover comprehensive input specifications by dynamically analyzing recursive descent parsers to infer semantic actions within attributed grammars, addressing gaps in existing grammar mining techniques.", "motivation": "Existing grammar mining techniques focus on syntactic structures but fail to capture semantic input processing logic, leading to incomplete and outdated system specifications.", "method": "The approach combines dynamic analysis of parser implementations with runtime input processing observation, mapping execution traces to grammar rules to systematically extract and embed semantic actions through attributed grammar synthesis.", "result": "Initial implementation successfully reconstructed attributed grammars that accurately reproduce program behavior across multiple test programs, demonstrating the feasibility of semantic recovery from parsers.", "conclusion": "The work establishes attributed grammar inference from parser code as a viable method for recovering semantic specifications, enabling more complete formal descriptions of input processing in software systems."}}
{"id": "2507.13123", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13123", "abs": "https://arxiv.org/abs/2507.13123", "authors": ["Xin Yin", "Xinrui Li", "Chao Ni", "Xiaodan Xu", "Xiaohu Yang"], "title": "Detecting LLM-generated Code with Subtle Modification by Adversarial Training", "comment": null, "summary": "With the rapid development of Large Language Models (LLMs), their powerful\ncode-generation capabilities have been widely applied in tasks like code\ncompletion and automated development, demonstrating the value of improving\ncoding efficiency. However, the extensive use of LLM-generated code also raises\nseveral new challenges. On the one hand, issues such as the regulation of code\nprovenance, copyright disputes, and code quality have become increasingly\nconcerning. How to effectively detect LLM-generated code and ensure its\ncompliant and responsible use has become a critical and urgent issue. On the\nother hand, in practical applications, LLM-generated code is often subject to\nmanual modifications, such as variable renaming or structural adjustments.\nAlthough some recent studies have proposed training-based and zero-shot methods\nfor detecting LLM-generated code, these approaches show insufficient robustness\nwhen facing modified LLM-generated code, and there is a lack of an effective\nsolution. To address the real-world scenario where LLM-generated code may\nundergo minor modifications, we propose CodeGPTSensor+, an enhanced version of\nCodeGPTSensor, which employs adversarial training to improve robustness against\ninput perturbations. CodeGPTSensor+ integrates an adversarial sample generation\nmodule, Multi-objective Identifier and Structure Transformation (MIST), which\nsystematically generates both high-quality and representative adversarial\nsamples. This module effectively enhances the model's resistance against\ndiverse adversarial attacks. Experimental results on the HMCorp dataset\ndemonstrate that CodeGPTSensor+ significantly improves detection accuracy on\nthe adversarial test set while maintaining high accuracy on the original test\nset, showcasing superior robustness compared to CodeGPTSensor.", "AI": {"tldr": "CodeGPTSensor+ improves detection of modified LLM-generated code using adversarial training via the MIST module, achieving higher robustness and accuracy on the HMCorp dataset compared to CodeGPTSensor.", "motivation": "The growing use of LLM-generated code in practical applications raises concerns about code provenance, copyright, and quality. Current detection methods lack robustness against minor code modifications, necessitating an effective solution for real-world scenarios.", "method": "CodeGPTSensor+ introduces the Multi-objective Identifier and Structure Transformation (MIST) module, which systematically generates high-quality adversarial samples. By adversarial training with these samples, the model enhances its resistance to diverse input perturbations, such as identifier changes and structural adjustments.", "result": "On the HMCorp dataset, CodeGPTSensor+ demonstrates significantly higher detection accuracy on an adversarial test set (with modified code) compared to prior models, while maintaining strong performance on the original test set.", "conclusion": "CodeGPTSensor+ addresses critical real-world challenges in detecting LLM-generated code post-modifications, providing superior robustness and ensuring its compliant and responsible use in coding tasks."}}
