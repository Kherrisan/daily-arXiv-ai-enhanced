{"id": "2508.15135", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.15135", "abs": "https://arxiv.org/abs/2508.15135", "authors": ["Sumudu Liyanage", "Sherlock A. Licorish", "Markus Wagner", "Stephen G. MacDonell"], "title": "On the need to perform comprehensive evaluations of automated program repair benchmarks: Sorald case study", "comment": null, "summary": "In supporting the development of high-quality software, especially necessary\nin the era of LLMs, automated program repair (APR) tools aim to improve code\nquality by automatically addressing violations detected by static analysis\nprofilers. Previous research tends to evaluate APR tools only for their ability\nto clear violations, neglecting their potential introduction of new (sometimes\nsevere) violations, changes to code functionality and degrading of code\nstructure. There is thus a need for research to develop and assess\ncomprehensive evaluation frameworks for APR tools. This study addresses this\nresearch gap, and evaluates Sorald (a state-of-the-art APR tool) as a proof of\nconcept. Sorald's effectiveness was evaluated in repairing 3,529 SonarQube\nviolations across 30 rules within 2,393 Java code snippets extracted from Stack\nOverflow. Outcomes show that while Sorald fixes specific rule violations, it\nintroduced 2,120 new faults (32 bugs, 2088 code smells), reduced code\nfunctional correctness--as evidenced by a 24% unit test failure rate--and\ndegraded code structure, demonstrating the utility of our framework. Findings\nemphasize the need for evaluation methodologies that capture the full spectrum\nof APR tool effects, including side effects, to ensure their safe and effective\nadoption.", "AI": {"tldr": "This study evaluates APR tool Sorald using a comprehensive framework, revealing introduced faults and code degradation despite violation fixes. It advocates for holistic evaluation methods to ensure safe APR tool adoption.", "motivation": "Existing APR tool evaluations focus narrowly on violation clearance, neglecting potential new faults, functional changes, and structural degradation. This study addresses the need for holistic evaluation frameworks to assess APR tool impacts comprehensively.", "method": "The researchers evaluated Sorald, a state-of-the-art APR tool, by analyzing its performance in repairing 3,529 SonarQube violations across 2,393 Java code snippets. They assessed introduced faults, functional correctness via unit test failure rates, and code structure degradation.", "result": "Sorald introduced 2,120 new faults (32 bugs, 2,088 code smells), exhibited a 24% unit test failure rate, and degraded code structure while fixing violations. These findings demonstrate the limitations of current APR tool evaluation practices.", "conclusion": "This study emphasizes the need for comprehensive evaluation frameworks for APR tools to capture both their benefits and introduced issues, ensuring safe and effective adoption."}}
{"id": "2508.15411", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15411", "abs": "https://arxiv.org/abs/2508.15411", "authors": ["Frederik Vandeputte"], "title": "Foundational Design Principles and Patterns for Building Robust and Adaptive GenAI-Native Systems", "comment": null, "summary": "Generative AI (GenAI) has emerged as a transformative technology,\ndemonstrating remarkable capabilities across diverse application domains.\nHowever, GenAI faces several major challenges in developing reliable and\nefficient GenAI-empowered systems due to its unpredictability and inefficiency.\nThis paper advocates for a paradigm shift: future GenAI-native systems should\nintegrate GenAI's cognitive capabilities with traditional software engineering\nprinciples to create robust, adaptive, and efficient systems.\n  We introduce foundational GenAI-native design principles centered around five\nkey pillars -- reliability, excellence, evolvability, self-reliance, and\nassurance -- and propose architectural patterns such as GenAI-native cells,\norganic substrates, and programmable routers to guide the creation of resilient\nand self-evolving systems. Additionally, we outline the key ingredients of a\nGenAI-native software stack and discuss the impact of these systems from\ntechnical, user adoption, economic, and legal perspectives, underscoring the\nneed for further validation and experimentation. Our work aims to inspire\nfuture research and encourage relevant communities to implement and refine this\nconceptual framework.", "AI": {"tldr": "This paper proposes integrating GenAI with traditional software principles using five design pillars and architectural patterns to build reliable, adaptive systems, while advocating for further research and validation.", "motivation": "GenAI's unpredictability and inefficiency hinder reliable system development, necessitating a paradigm shift to integrate cognitive capabilities with traditional software engineering principles.", "method": "The authors introduce five foundational GenAI-native design principles (reliability, excellence, evolvability, self-reliance, assurance) and propose architectural patterns (GenAI-native cells, organic substrates, programmable routers) to create robust systems.", "result": "They outline a GenAI-native software stack, analyze technical/user/economic/legal impacts, and highlight the importance of validation through experimentation.", "conclusion": "The paper aims to inspire future research and encourage the implementation and refinement of the proposed GenAI-native conceptual framework, emphasizing the need for further validation and experimentation."}}
