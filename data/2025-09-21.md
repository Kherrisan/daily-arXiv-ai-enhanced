<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models](https://arxiv.org/abs/2509.14265)
*Siyuan Chen,Zhichao Lu,Qingfu Zhang*

Main category: cs.SE

TL;DR: EoK: LLM-powered evolutionary framework enabling RISC-V kernel optimization via RAG and reused design principles, beating humans and existing methods.


<details>
  <summary>Details</summary>
Motivation: Emerging hardware domains (e.g., RISC-V) face software ecosystem barriers due to limited reference material, where traditional LLM-based optimization methods (successful in CUDA) underperform.

Method: EoK combines evolutionary program search with LLMs, leveraging Retrieval-Augmented Generation (RAG) and mined optimization principles from historical kernel libraries to guide exploration.

Result: EoK achieves a median 1.27x speedup on 80 kernel tasks, surpassing human experts and improving 20% over prior LLM-based approaches.

Conclusion: EoK demonstrates the viability of LLM-based automated kernel optimization in reference-scarce domains like RISC-V, outperforming human experts and prior methods.

Abstract: Automated kernel design is critical for overcoming software ecosystem
barriers in emerging hardware platforms like RISC-V. While large language
models (LLMs) have shown promise for automated kernel optimization,
demonstrating success in CUDA domains with comprehensive technical documents
and mature codebases, their effectiveness remains unproven for reference-scarce
domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based
evolutionary program search framework that automates kernel design for domains
with limited reference material. EoK mitigates reference scarcity by mining and
formalizing reusable optimization ideas (general design principles + actionable
thoughts) from established kernel libraries' development histories; it then
guides parallel LLM explorations using these ideas, enriched via
Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing
historically effective techniques. Empirically, EoK achieves a median 1.27x
speedup, surpassing human experts on all 80 evaluated kernel design tasks and
improving upon prior LLM-based automated kernel design methods by 20%. These
results underscore the viability of incorporating human experience into
emerging domains and highlight the immense potential of LLM-based automated
kernel optimization.

</details>


### [2] [Automated and Context-Aware Code Documentation Leveraging Advanced LLMs](https://arxiv.org/abs/2509.14273)
*Swapnil Sharma Sarker,Tanzina Taher Ifty*

Main category: cs.SE

TL;DR: This paper introduces a novel dataset for Javadoc generation, evaluates open-source LLMs for template-based documentation, and identifies LLaMA 3.1 as the most reliable model for this task.


<details>
  <summary>Details</summary>
Motivation: Existing automated documentation systems focus on code summarization, neglecting template-based Javadoc generation. Current LLMs lack specialized training data incorporating modern Java features and contextual information for this use case.

Method: 1) Created a context-aware Javadoc dataset with modern Java code structural/semantic info
2] Evaluated 5 open-source LLMs (LLaMA-3.1, Gemma-2, etc.) using zero-shot/few-shot/fine-tuning
3) Compared performance metrics across these setups

Result: LLaMA 3.1 demonstrated consistent superior performance across all evaluation setups. The new dataset provides a benchmark with framework coverage, modern Java features, and rich context information

Conclusion: The dataset advances template-based documentation research. LLaMA 3.1 stands as a viable open-source alternative to proprietary systems for automated Javadoc generation, especially when fine-tuned on the proposed dataset.

Abstract: Code documentation is essential to improve software maintainability and
comprehension. The tedious nature of manual code documentation has led to much
research on automated documentation generation. Existing automated approaches
primarily focused on code summarization, leaving a gap in template-based
documentation generation (e.g., Javadoc), particularly with publicly available
Large Language Models (LLMs). Furthermore, progress in this area has been
hindered by the lack of a Javadoc-specific dataset that incorporates modern
language features, provides broad framework/library coverage, and includes
necessary contextual information. This study aims to address these gaps by
developing a tailored dataset and assessing the capabilities of publicly
available LLMs for context-aware, template-based Javadoc generation. In this
work, we present a novel, context-aware dataset for Javadoc generation that
includes critical structural and semantic information from modern Java
codebases. We evaluate five open-source LLMs (including LLaMA-3.1, Gemma-2,
Phi-3, Mistral, Qwen-2.5) using zero-shot, few-shot, and fine-tuned setups and
provide a comparative analysis of their performance. Our results demonstrate
that LLaMA 3.1 performs consistently well and is a reliable candidate for
practical, automated Javadoc generation, offering a viable alternative to
proprietary systems.

</details>
