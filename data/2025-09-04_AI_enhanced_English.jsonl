{"id": "2509.02578", "categories": ["cs.CR", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.02578", "abs": "https://arxiv.org/abs/2509.02578", "authors": ["Abel C. H. Chen"], "title": "Secure Password Generator Based on Secure Pseudo-Random Number Generator", "comment": "in Chinese language", "summary": "In recent years, numerous incidents involving the leakage of website accounts\nand text passwords (referred to as passwords) have raised significant concerns\nregarding the potential exposure of personal information. These events\nunderscore the critical importance of both information security and password\nprotection. While many of these breaches are attributable to vulnerabilities\nwithin website infrastructure, the strength and security of the passwords\nthemselves also play a crucial role. Consequently, the creation of secure\npasswords constitutes a fundamental aspect of enhancing overall system security\nand protecting personal data. In response to these challenges, this study\npresents a secure password generation approach utilizing a cryptographically\nsecure Pseudo-Random Number Generator (PRNG). The generator is implemented\nusing a range of Message Authentication Code (MAC) algorithms, including the\nKeyed-Hash Message Authentication Code (HMAC), Cipher-based Message\nAuthentication Code (CMAC), and KECCAK Message Authentication Code (KMAC), to\nproduce robust random values suitable for password generation. To evaluate the\nproposed method, empirical assessments were conducted in accordance with the\nguidelines provided in the National Institute of Standards and Technology\n(NIST) Special Publication (SP) 800-90B. The evaluation focused on two primary\naspects: entropy estimation and verification of independent and identically\ndistributed (IID) properties. Experimental results indicate that the proposed\nmethod satisfies both entropy and IID requirements, thereby demonstrating its\nability to generate passwords with a high degree of randomness and security.", "AI": {"tldr": "This paper proposes a secure password generation method using HMAC, CMAC, and KMAC-based PRNG, validated by NIST standards for optimal randomness and protection against breaches.", "motivation": "Recent account and password leaks highlight the risks of weak passwords and vulnerabilities in website infrastructures. Strong password generation is critical for system security and preventing personal information exposure.", "method": "The study introduces a password generation method based on a cryptographically secure Pseudo-Random Number Generator (PRNG) implemented with HMAC, CMAC, and KMAC algorithms. The generated random values undergo NIST SP 800-90B validation for entropy estimation and IID property confirmation.", "result": "Empirical evaluations demonstrate the proposed method satisfies NIST-defined entropy and IID criteria, proving its ability to generate highly random and secure passwords.", "conclusion": "The proposed method effectively generates secure passwords by utilizing a cryptographically secure PRNG with HMAC, CMAC, and KMAC, meeting NIST entropy and IID requirements. This approach enhances system security and personal data protection."}}
{"id": "2509.02856", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.02856", "abs": "https://arxiv.org/abs/2509.02856", "authors": ["Syomantak Chaudhuri", "Thomas A. Courtade"], "title": "Managing Correlations in Data and Privacy Demand", "comment": "To appeat at ACM CCS, 2025", "summary": "Previous works in the differential privacy literature that allow users to\nchoose their privacy levels typically operate under the heterogeneous\ndifferential privacy (HDP) framework with the simplifying assumption that user\ndata and privacy levels are not correlated. Firstly, we demonstrate that the\nstandard HDP framework falls short when user data and privacy demands are\nallowed to be correlated. Secondly, to address this shortcoming, we propose an\nalternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that\njointly accounts for user data and privacy preference. We show that AHDP is\nrobust to possible correlations between data and privacy. Thirdly, we formalize\nthe guarantees of the proposed AHDP framework through an operational hypothesis\ntesting perspective. The hypothesis testing setup may be of independent\ninterest in analyzing other privacy frameworks as well. Fourthly, we show that\nthere exists non-trivial AHDP mechanisms that notably do not require prior\nknowledge of the data-privacy correlations. We propose some such mechanisms and\napply them to core statistical tasks such as mean estimation, frequency\nestimation, and linear regression. The proposed mechanisms are simple to\nimplement with minimal assumptions and modeling requirements, making them\nattractive for real-world use. Finally, we empirically evaluate proposed AHDP\nmechanisms, highlighting their trade-offs using LLM-generated synthetic\ndatasets, which we release for future research.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.03024", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03024", "abs": "https://arxiv.org/abs/2509.03024", "authors": ["Moontaha Nishat Chowdhury", "Andr\u00e9 Bauer", "Minxuan Zhou"], "title": "Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption", "comment": "The paper is accepted at the 21st IEEE International eScience\n  Conference (eScience'25) and will be published soon. Link:\n  https://www.escience-conference.org/2025/papers", "summary": "In today's data-driven world, recommendation systems personalize user\nexperiences across industries but rely on sensitive data, raising privacy\nconcerns. Fully homomorphic encryption (FHE) can secure these systems, but a\nsignificant challenge in applying FHE to recommendation systems is efficiently\nhandling the inherently large and sparse user-item rating matrices. FHE\noperations are computationally intensive, and naively processing various sparse\nmatrices in recommendation systems would be prohibitively expensive.\nAdditionally, the communication overhead between parties remains a critical\nconcern in encrypted domains. We propose a novel approach combining Compressed\nSparse Row (CSR) representation with FHE-based matrix factorization that\nefficiently handles matrix sparsity in the encrypted domain while minimizing\ncommunication costs. Our experimental results demonstrate high recommendation\naccuracy with encrypted data while achieving the lowest communication costs,\neffectively preserving user privacy.", "AI": {"tldr": "Presents CSR-based FHE matrix factorization for privacy-preserving recommendation systems to address sparsity and communication costs.", "motivation": "Recommendation systems use sensitive data, but FHE's high computational cost for sparse matrices and communication overhead in encrypted domains hinders adoption.", "method": "Combines Compressed Sparse Row (CSR)-based FHE matrix factorization to handle matrix sparsity and reduce communication overhead in encrypted domains.", "result": "Experimental results show high recommendation accuracy on encrypted data with minimal communication costs, effectively preserving user privacy.", "conclusion": "The CSR-FHE approach efficiently addresses FHE's computational and communication challenges in recommendation systems while maintaining user privacy."}}
{"id": "2509.03037", "categories": ["cs.CR", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.03037", "abs": "https://arxiv.org/abs/2509.03037", "authors": ["Shuzheng Wang", "Yue Huang", "Zhuoer Xu", "Yuming Huang", "Jing Tang"], "title": "TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum", "comment": null, "summary": "Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet\ncomprehensive security analysis remains difficult due to unverified code,\nproxy-based architectures, and the reliance on manual inspection of complex\nexecution traces. Existing approaches fall into two main categories: anomaly\ntransaction detection, which flags suspicious transactions but offers limited\ninsight into specific attack strategies hidden in execution traces inside\ntransactions, and code vulnerability detection, which cannot analyze unverified\ncontracts and struggles to show how identified flaws are exploited in real\nincidents. As a result, analysts must still manually align transaction traces\nwith contract code to reconstruct attack scenarios and conduct forensics. To\naddress this gap, TraceLLM is proposed as a framework that leverages LLMs to\nintegrate execution trace-level detection with decompiled contract code. We\nintroduce a new anomaly execution path identification algorithm and an\nLLM-refined decompile tool to identify vulnerable functions and provide\nexplicit attack paths to LLM. TraceLLM establishes the first benchmark for\njoint trace and contract code-driven security analysis. For comparison, proxy\nbaselines are created by jointly transmitting the results of three\nrepresentative code analysis along with raw traces to LLM. TraceLLM identifies\nattacker and victim addresses with 85.19\\% precision and produces automated\nreports with 70.37\\% factual precision across 27 cases with ground truth expert\nreports, achieving 25.93\\% higher accuracy than the best baseline. Moreover,\nacross 148 real-world Ethereum incidents, TraceLLM automatically generates\nreports with 66.22\\% expert-verified accuracy, demonstrating strong\ngeneralizability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.02860", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.02860", "abs": "https://arxiv.org/abs/2509.02860", "authors": ["Connor Wojtak", "Darek Gajewski", "Tomas Cerny"], "title": "Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems", "comment": "Accepted at MODELS 2025", "summary": "Microservice systems are becoming increasingly adopted due to their\nscalability, decentralized development, and support for continuous integration\nand delivery (CI/CD). However, this decentralized development by separate teams\nand continuous evolution can introduce miscommunication and incompatible\nimplementations, undermining system maintainability and reliability across\naspects from security policy to system architecture. We propose a novel\nmethodology that statically reconstructs microservice source code into a formal\nsystem model. From this model, a Satisfiability Modulo Theories (SMT)\nconstraint set can be derived, enabling formal verification. Our methodology is\nextensible, supporting software verification across multiple cross-cutting\nconcerns. We focus on applying the methodology to verify the system\narchitecture concern, presenting formal reasoning to validate the methodology's\ncorrectness and applicability for this concern. Additional concerns such as\nsecurity policy implementation are considered. Future directions are\nestablished to extend and evaluate the methodology.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.03058", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03058", "abs": "https://arxiv.org/abs/2509.03058", "authors": ["Zhenhua Xu", "Meng Han", "Wenpeng Xing"], "title": "EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint", "comment": "Accepted by EMNLP2025 Main", "summary": "The proliferation of large language models (LLMs) has intensified concerns\nover model theft and license violations, necessitating robust and stealthy\nownership verification. Existing fingerprinting methods either require\nimpractical white-box access or introduce detectable statistical anomalies. We\npropose EverTracer, a novel gray-box fingerprinting framework that ensures\nstealthy and robust model provenance tracing. EverTracer is the first to\nrepurpose Membership Inference Attacks (MIAs) for defensive use, embedding\nownership signals via memorization instead of artificial trigger-output\noverfitting. It consists of Fingerprint Injection, which fine-tunes the model\non any natural language data without detectable artifacts, and Verification,\nwhich leverages calibrated probability variation signal to distinguish\nfingerprinted models. This approach remains robust against adaptive\nadversaries, including input level modification, and model-level modifications.\nExtensive experiments across architectures demonstrate EverTracer's\nstate-of-the-art effectiveness, stealthness, and resilience, establishing it as\na practical solution for securing LLM intellectual property. Our code and data\nare publicly available at https://github.com/Xuzhenhua55/EverTracer.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.03093", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03093", "abs": "https://arxiv.org/abs/2509.03093", "authors": ["Fatih Pehlivan", "Ar\u00e7in \u00dclk\u00fc Erg\u00fczen", "Sahand Moslemi Yengejeh", "Mayasah Lami", "Anil Koyuncu"], "title": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations", "comment": "Accepted to ASE2025", "summary": "Traditional static analysis methods struggle to detect semantic design flaws,\nsuch as violations of the SOLID principles, which require a strong\nunderstanding of object-oriented design patterns and principles. Existing\nsolutions typically focus on individual SOLID principles or specific\nprogramming languages, leaving a gap in the ability to detect violations across\nall five principles in multi-language codebases. This paper presents a new\napproach: a methodology that leverages tailored prompt engineering to assess\nLLMs on their ability to detect SOLID violations across multiple languages. We\npresent a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,\nand GPT-4o Mini-on their ability to detect violations of all five SOLID\nprinciples. For this evaluation, we construct a new benchmark dataset of 240\nmanually validated code examples. Using this dataset, we test four distinct\nprompt strategies inspired by established zero-shot, few-shot, and\nchain-of-thought techniques to systematically measure their impact on detection\naccuracy. Our emerging results reveal a stark hierarchy among models, with\nGPT-4o Mini decisively outperforming others, yet even struggles with\nchallenging principles like DIP. Crucially, we show that prompt strategy has a\ndramatic impact, but no single strategy is universally best; for instance, a\ndeliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE\nprompt is superior for DIP violations. Across all experiments, detection\naccuracy is heavily influenced by language characteristics and degrades sharply\nwith increasing code complexity. These initial findings demonstrate that\neffective, AI-driven design analysis requires not a single best model, but a\ntailored approach that matches the right model and prompt to the specific\ndesign context, highlighting the potential of LLMs to support maintainability\nthrough AI-assisted code analysis.", "AI": {"tldr": "This paper evaluates LLMs' ability to detect SOLID design principle violations through tailored prompts, demonstrating that optimal detection requires matching models and prompting strategies to specific design challenges, with GPT-4o Mini showing strongest but imperfect performance.", "motivation": "Traditional static analysis methods inadequately detect semantic SOLID principle violations that require nuanced understanding of object-oriented design. Existing tools are limited by focusing on single principles or specific languages, creating a gap in analyzing multi-language codebases comprehensively.", "method": "The method involves leveraging tailored prompt engineering to evaluate four leading LLMs (CodeLlama, DeepSeekCoder, QwenCoder, GPT-4o Mini) on their ability to detect SOLID violations. A new benchmark dataset of 240 manually validated code examples was used, testing four prompt strategies derived from zero-shot, few-shot, and chain-of-thought techniques.", "result": "Results revealed a performance hierarchy among models (GPT-4o Mini leading) but all struggled with complex principles like DIP. Prompt strategies significantly impacted accuracy, with no universal best strategy \u2013 e.g., ENSEMBLE excelled at OCP while EXAMPLE was best for DIP. Accuracy declined sharply with increasing code complexity.", "conclusion": "The paper concludes that effective AI-driven design analysis requires a tailored approach combining the right LLMs with appropriate prompting strategies for specific design contexts, highlighting the potential of LLMs to improve maintainability through code analysis."}}
{"id": "2509.03098", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03098", "abs": "https://arxiv.org/abs/2509.03098", "authors": ["Gustavo Banegas", "Ana\u00eblle Le D\u00e9v\u00e9hat", "Benjamin Smith"], "title": "Compressed verification for post-quantum signatures with long-term public keys", "comment": null, "summary": "Many signature applications-such as root certificates, secure software\nupdates, and authentication protocols-involve long-lived public keys that are\ntransferred or installed once and then used for many verifications. This key\nlongevity makes post-quantum signature schemes with conservative assumptions\n(e.g., structure-free lattices) attractive for long-term security. But many\nsuch schemes, especially those with short signatures, suffer from extremely\nlarge public keys. Even in scenarios where bandwidth is not a major concern,\nlarge keys increase storage costs and slow down verification. We address this\nwith a method to replace large public keys in GPV-style signatures with\nsmaller, private verification keys. This significantly reduces verifier storage\nand runtime while preserving security. Applied to the conservative,\nshort-signature schemes Wave and Squirrels, our method compresses Squirrels-I\nkeys from 665 kB to 20.7 kB and Wave822 keys from 3.5 MB to 207.97 kB.", "AI": {"tldr": "A novel method compresses large public keys in post-quantum signature schemes (e.g., Wave, Squirrels) by replacing them with compact private keys, achieving 94\u201397% storage reduction and faster verification.", "motivation": "Long-lived public keys in post-quantum signature schemes often require large storage and slow verification, creating inefficiencies even when bandwidth is not constrained. This problem is critical for applications like root certificates and secure software updates, where key longevity is essential for long-term security.", "method": "The paper proposes a method to replace large public keys with smaller, private verification keys in GPV-style signatures. This approach optimizes verifier storage and verification speed without compromising the security guarantees of the underlying lattice-based schemes.", "result": "For the Squirrels-I scheme, public key size is reduced from 665 kB to 20.7 kB. For Wave822, the reduction is from 3.5 MB to 207.97 kB. These improvements preserve security against quantum attacks while enabling practical deployment in storage- and speed-sensitive scenarios.", "conclusion": "The study introduces a technique to reduce the size of public keys in GPV-style post-quantum signature schemes by using smaller private verification keys, achieving significant storage and runtime improvements while maintaining security. Applied to Wave and Squirrels, it reduces key sizes by 97% and 94.3%, respectively."}}
