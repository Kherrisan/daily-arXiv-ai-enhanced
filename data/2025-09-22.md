<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 13]
- [cs.SE](#cs.SE) [Total: 9]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Synergizing Static Analysis with Large Language Models for Vulnerability Discovery and beyond](https://arxiv.org/abs/2509.15433)
*Vaibhav Agrawal,Kiarash Ahi*

Main category: cs.CR

TL;DR: This paper proposes integrating Large Language Models (LLMs) with Static Application Security Testing (SAST) to improve vulnerability discovery by combining their strengths while mitigating weaknesses.


<details>
  <summary>Details</summary>
Motivation: Traditional SAST tools suffer from high false-positive rates and limited contextual understanding, while LLMs face issues with consistency and hallucinations in code analysis.

Method: A hybrid system combining LLMs and SAST tools (e.g., Semgrep) is developed to leverage contextual analysis and pattern recognition for triage, dynamic bug descriptions, exploit validation, and complex code analysis.

Result: SAST-Genius reduced false positives by 91% (225 to 20) compared to Semgrep alone, demonstrating significant improvements in accuracy and efficiency.

Conclusion: The integration of LLMs and SAST transforms security into a context-aware, workflow-enhancing process that outperforms standalone tools in vulnerability discovery and validation.

Abstract: This report examines the synergy between Large Language Models (LLMs) and
Static Application Security Testing (SAST) to improve vulnerability discovery.
Traditional SAST tools, while effective for proactive security, are limited by
high false-positive rates and a lack of contextual understanding. Conversely,
LLMs excel at code analysis and pattern recognition but can be prone to
inconsistencies and hallucinations. By integrating these two technologies, a
more intelligent and efficient system is created. This combination moves beyond
mere vulnerability detection optimization, transforming security into a deeply
integrated, contextual process that provides tangible benefits like improved
triage, dynamic bug descriptions, bug validation via exploit generation and
enhanced analysis of complex codebases. The result is a more effective security
approach that leverages the strengths of both technologies while mitigating
their weaknesses. SAST-Genius reduced false positives by about 91 % (225 to 20)
compared to Semgrep alone.

</details>


### [2] [Adversarially Robust Assembly Language Model for Packed Executables Detection](https://arxiv.org/abs/2509.15499)
*Shijia Li,Jiang Ming,Lanqing Liu,Longwei Yang,Ni Zhang,Chunfu Jia*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Detecting packed executables is a critical component of large-scale malware
analysis and antivirus engine workflows, as it identifies samples that warrant
computationally intensive dynamic unpacking to reveal concealed malicious
behavior. Traditionally, packer detection techniques have relied on empirical
features, such as high entropy or specific binary patterns. However, these
empirical, feature-based methods are increasingly vulnerable to evasion by
adversarial samples or unknown packers (e.g., low-entropy packers).
Furthermore, the dependence on expert-crafted features poses challenges in
sustaining and evolving these methods over time.
  In this paper, we examine the limitations of existing packer detection
methods and propose Pack-ALM, a novel deep-learning-based approach for
detecting packed executables. Inspired by the linguistic concept of
distinguishing between real and pseudo words, we reformulate packer detection
as a task of differentiating between legitimate and "pseudo" instructions. To
achieve this, we preprocess native data and packed data into "pseudo"
instructions and design a pre-trained assembly language model that recognizes
features indicative of packed data. We evaluate Pack-ALM against leading
industrial packer detection tools and state-of-the-art assembly language
models. Extensive experiments on over 37,000 samples demonstrate that Pack-ALM
effectively identifies packed binaries, including samples created with
adversarial or previously unseen packing techniques. Moreover, Pack-ALM
outperforms traditional entropy-based methods and advanced assembly language
models in both detection accuracy and adversarial robustness.

</details>


### [3] [Fluid Antenna System-assisted Physical Layer Secret Key Generation](https://arxiv.org/abs/2509.15547)
*Zhiyu Huang,Guyue Li,Hao Xu,Derrick Wing Kwan Ng*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates physical-layer key generation (PLKG) in multi-antenna
base station systems, by leveraging a fluid antenna system (FAS) to dynamically
customize radio environments. Without requiring additional nodes or extensive
radio frequency chains, the FAS effectively enables adaptive antenna port
selection by exploiting channel spatial correlation to enhance the key
generation rate (KGR) at legitimate nodes. To comprehensively evaluate the
efficiency of the FAS in PLKG, we propose an FAS-assisted PLKG model that
integrates transmit beamforming and sparse port selection under independent and
identically distributed and spatially correlated channel models, respectively.
Specifically, the PLKG utilizes reciprocal channel probing to derive a
closed-form KGR expression based on the mutual information between legitimate
channel estimates. Nonconvex optimization problems for these scenarios are
formulated to maximize the KGR subject to transmit power constraints and sparse
port activation. We propose an iterative algorithm by capitalizing on
successive convex approximation and Cauchy-Schwarz inequality to obtain a
locally optimal solution. A reweighted $\ell_1$-norm-based algorithm is applied
to advocate for the sparse port activation of FAS-assisted PLKG. Furthermore, a
low-complexity sliding window-based port selection is proposed to substitute
reweighted $\ell_1$-norm method based on Rayleigh-quotient analysis. Simulation
results demonstrate that the FAS-PLKG scheme significantly outperforms the
FA-PLKG scheme in both independent and spatially correlated environments. The
sliding window-based port selection method introduced in this paper has been
shown to yield superior KGR, compared to the reweighted $\ell_1$-norm method.
It is shown that the FAS achieves higher KGR with fewer RF chains through
dynamic sparse port selection.

</details>


### [4] [Hybrid Deep Learning-Federated Learning Powered Intrusion Detection System for IoT/5G Advanced Edge Computing Network](https://arxiv.org/abs/2509.15555)
*Rasil Baidar,Sasa Maric,Robert Abbas*

Main category: cs.CR

TL;DR: The paper introduces a CNN-BiLSTM-AE based intrusion detection system in a privacy-preserving FL framework for 5G-Advanced IoT, achieving high AUC and F1 scores with fast inference.


<details>
  <summary>Details</summary>
Motivation: The growing IoT and 5G-Advanced applications have increased the risks of cyber threats like DDoS, malware, and zero-day intrusions, necessitating effective and privacy-preserving intrusion detection solutions.

Method: The proposed system combines a CNN for local feature interactions, a BiLSTM for sequence analysis, and an AE for anomaly detection, all integrated within a federated learning framework to preserve privacy during distributed training.

Result: Evaluations on the UNSW-NB15 dataset show the fused model achieves an AUC of 99.59% and an F1 score of 97.36%, with low inference latency of ~0.0476 ms per sample, fitting URLLC's 10 ms requirement.

Conclusion: The model offers a secure, efficient, and explainable solution for 5G-Advanced IoT environments, addressing scalability and drift tolerance challenges in FL-based intrusion detection.

Abstract: The exponential expansion of IoT and 5G-Advanced applications has enlarged
the attack surface for DDoS, malware, and zero-day intrusions. We propose an
intrusion detection system that fuses a convolutional neural network (CNN), a
bidirectional LSTM (BiLSTM), and an autoencoder (AE) bottleneck within a
privacy-preserving federated learning (FL) framework. The CNN-BiLSTM branch
captures local and gated cross-feature interactions, while the AE emphasizes
reconstruction-based anomaly sensitivity. Training occurs across edge devices
without sharing raw data. On UNSW-NB15 (binary), the fused model attains AUC
99.59 percent and F1 97.36 percent; confusion-matrix analysis shows balanced
error rates with high precision and recall. Average inference time is
approximately 0.0476 ms per sample on our test hardware, which is well within
the less than 10 ms URLLC budget, supporting edge deployment. We also discuss
explainability, drift tolerance, and FL considerations for compliant, scalable
5G-Advanced IoT security.

</details>


### [5] [Cuckoo Attack: Stealthy and Persistent Attacks Against AI-IDE](https://arxiv.org/abs/2509.15572)
*Xinpeng Liu,Junming Liu,Peiyu Liu,Han Zheng,Qinying Wang,Mathias Payer,Shouling Ji,Wenhai Wang*

Main category: cs.CR

TL;DR: The paper proposes Cuckoo Attack, a method to stealthily and persistently hijack LLM-powered agents in AI-IDEs by injecting malicious payloads into configuration files. The study demonstrates the attack's impact and presents seven security checkpoints for vendors.


<details>
  <summary>Details</summary>
Motivation: Despite the growing use of AI-IDEs with agent-centric architecture, current attack methods lack stealth and persistence, limiting their real-world effectiveness. The paper aims to address this by introducing a more impactful attack methodology.

Method: The Cuckoo Attack embeds malicious payloads into configuration files commonly used in AI-IDEs. These files execute system commands during routine operations without user visibility, allowing attackers to maintain persistence and stealth. The attack is formalized into two stages: initial infection and persistence, with end-to-end testing on nine mainstream AI-IDE and agent pairs.

Result: The Cuckoo Attack can successfully execute commands within AI-IDEs without user detection. It poses significant risks, including local computer compromises and supply chain attacks through configuration file propagation. Additionally, the researchers have demonstrated the feasibility and impact through a Proof of Concept.

Conclusion: Cuckoo Attack highlights the security vulnerabilities in AI-IDE agent integrations due to their complex architectures and ubiquitous configuration usage. The paper's contribution includes raising awareness of these vulnerabilities, confirming the attack's practicality through testing, and providing seven actionable checkpoints to improve vendor security.

Abstract: Modern AI-powered Integrated Development Environments (AI-IDEs) are
increasingly defined by an Agent-centric architecture, where an LLM-powered
Agent is deeply integrated to autonomously execute complex tasks. This tight
integration, however, also introduces a new and critical attack surface.
Attackers can exploit these components by injecting malicious instructions into
untrusted external sources, effectively hijacking the Agent to perform harmful
operations beyond the user's intention or awareness. This emerging threat has
quickly attracted research attention, leading to various proposed attack
vectors, such as hijacking Model Context Protocol (MCP) Servers to access
private data. However, most existing approaches lack stealth and persistence,
limiting their practical impact.
  We propose the Cuckoo Attack, a novel attack that achieves stealthy and
persistent command execution by embedding malicious payloads into configuration
files. These files, commonly used in AI-IDEs, execute system commands during
routine operations, without displaying execution details to the user. Once
configured, such files are rarely revisited unless an obvious runtime error
occurs, creating a blind spot for attackers to exploit. We formalize our attack
paradigm into two stages, including initial infection and persistence. Based on
these stages, we analyze the practicality of the attack execution process and
identify the relevant exploitation techniques. Furthermore, we analyze the
impact of Cuckoo Attack, which can not only invade the developer's local
computer but also achieve supply chain attacks through the spread of
configuration files. We contribute seven actionable checkpoints for vendors to
evaluate their product security. The critical need for these checks is
demonstrated by our end-to-end Proof of Concept, which validated the proposed
attack across nine mainstream Agent and AI-IDE pairs.

</details>


### [6] [Future-Proofing Cloud Security Against Quantum Attacks: Risk, Transition, and Mitigation Strategies](https://arxiv.org/abs/2509.15653)
*Yaser Baseri,Abdelhakim Hafid,Arash Habibi Lashkari*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum Computing (QC) introduces a transformative threat to digital
security, with the potential to compromise widely deployed classical
cryptographic systems. This survey offers a comprehensive and systematic
examination of quantumsafe security for Cloud Computing (CC), focusing on the
vulnerabilities, transition strategies, and mitigation mechanisms required to
secure cloud infrastructures in the quantum era. We evaluated the landscape of
quantum threats across the entire CC stack, demonstrating how quantum
algorithms can undermine classical encryption and compromise cloud security at
multiple architectural layers. Using a structured risk assessment methodology
based on the STRIDE model, we evaluate quantum-induced attack vectors and their
impact on cloud environments. To address these challenges, we propose a layered
security framework that integrates hybrid cryptographic transition strategies,
cryptographic agility, and proactive risk mitigation. We analyze the
preparation and implementation approaches of the major Cloud Service Providers
(CSPs), including AWS, Azure and GCP, synthesizing platform-specific
initiatives toward Post-Quantum Cryptography (PQC). Furthermore, we provide a
detailed evaluation of standardized PQC algorithms, exploring their resilience
to side-channel and active attacks within cloud-native deployments. This survey
serves as a strategic reference for cloud architects, policymakers, and
researchers, offering actionable insights for navigating the complex transition
to quantum-resilient cloud systems. We conclude by identifying six key future
research directions: standardization and interoperability, performance and
scalability, implementation security, integration with emerging technologies,
systemic preparedness, and crypto-agile migration frameworks.

</details>


### [7] [Hornet Node and the Hornet DSL: A Minimal, Executable Specification for Bitcoin Consensus](https://arxiv.org/abs/2509.15754)
*Toby Sharp*

Main category: cs.CR

TL;DR: This work creates a verifiable Bitcoin consensus spec (Hornet DSL) and client (Hornet Node) that enable formal verification, reduce consensus risks, and offer a modern, educational alternative to the reference implementation.


<details>
  <summary>Details</summary>
Motivation: Bitcoin's consensus rules are embedded in a complex, unverifiable reference client codebase, creating risks of consensus-splitting bugs. A standalone formal specification would enable cross-version and cross-implementation verification to strengthen decentralization.

Method: Developed a compact, executable, declarative C++ specification of Bitcoin consensus rules and introduced the Hornet DSL. This DSL facilitates unambiguous encoding, formal reasoning, code generation, and adversarial testing.

Result: The Hornet Node client syncs mainnet efficiently with production-ready architecture, demonstrating layered design, optimized data structures, and clear separation of concerns. The DSL supports formal reasoning and code generation.

Conclusion: Hornet Node and Hornet DSL provide the first credible path toward a pure, formal, executable Bitcoin consensus specification, enhancing decentralization through verifiable compliance and modern design.

Abstract: Bitcoin's consensus rules are encoded in the implementation of its reference
client: "The code is the spec." Yet this code is unsuitable for formal
verification due to side effects, mutable state, concurrency, and legacy
design. A standalone formal specification would enable verification both across
versions of the reference client and against new client implementations,
strengthening decentralization by reducing the risk of consensus-splitting
bugs. Yet such a specification has long been considered intractable given the
complexity of Bitcoin's consensus logic. We demonstrate a compact, executable,
declarative C++ specification of Bitcoin consensus rules that syncs mainnet to
tip in a few hours on a single thread. We also introduce the Hornet
Domain-Specific Language (DSL) specifically designed to encode these rules
unambiguously for execution, enabling formal reasoning, consensus code
generation, and AI-driven adversarial testing. Our spec-driven client Hornet
Node offers a modern and modular complement to the reference client. Its clear,
idiomatic style makes it suitable for education, while its performance makes it
ideal for experimentation. We highlight architectural contributions such as its
layered design, efficient data structures, and strong separation of concerns,
supported by production-quality code examples. We argue that Hornet Node and
Hornet DSL together provide the first credible path toward a pure, formal,
executable specification of Bitcoin consensus.

</details>


### [8] [Inference Attacks on Encrypted Online Voting via Traffic Analysis](https://arxiv.org/abs/2509.15694)
*Anastasiia Belousova,Francesco Marchiori,Mauro Conti*

Main category: cs.CR

TL;DR: This paper exposes how encrypted traffic metadata in online voting systems can be exploited to breach privacy, even without decrypting content, and proposes practical countermeasures like timestamp equalization and payload padding.


<details>
  <summary>Details</summary>
Motivation: The rapid adoption of online voting necessitates addressing understudied threats like network traffic analysis, which can compromise voter privacy and election trustworthiness despite robust cryptographic protocols.

Method: The paper employs rule-based and machine learning techniques to analyze metadata from encrypted network traffic, evaluating attacks on two online voting platforms.

Result: The attacks achieved classification accuracy up to 99.5%, revealing vulnerabilities in ballot submission timing and validity. Mitigations reduced attack effectiveness but underscored system weaknesses.

Conclusion: The study highlights significant privacy vulnerabilities in online voting systems through network traffic analysis, demonstrating that even encrypted metadata can be exploited. Countermeasures like payload padding and timestamp equalization effectively mitigate these risks.

Abstract: Online voting enables individuals to participate in elections remotely,
offering greater efficiency and accessibility in both governmental and
organizational settings. As this method gains popularity, ensuring the security
of online voting systems becomes increasingly vital, as the systems supporting
it must satisfy a demanding set of security requirements. Most research in this
area emphasizes the design and verification of cryptographic protocols to
protect voter integrity and system confidentiality. However, other vectors,
such as network traffic analysis, remain relatively understudied, even though
they may pose significant threats to voter privacy and the overall
trustworthiness of the system.
  In this paper, we examine how adversaries can exploit metadata from encrypted
network traffic to uncover sensitive information during online voting. Our
analysis reveals that, even without accessing the encrypted content, it is
possible to infer critical voter actions, such as whether a person votes, the
exact moment a ballot is submitted, and whether the ballot is valid or spoiled.
We test these attacks with both rule-based techniques and machine learning
methods. We evaluate our attacks on two widely used online voting platforms,
one proprietary and one partially open source, achieving classification
accuracy as high as 99.5%. These results expose a significant privacy
vulnerability that threatens key properties of secure elections, including
voter secrecy and protection against coercion or vote-buying. We explore
mitigations to our attacks, demonstrating that countermeasures such as payload
padding and timestamp equalization can substantially limit their effectiveness.

</details>


### [9] [An Adversarial Robust Behavior Sequence Anomaly Detection Approach Based on Critical Behavior Unit Learning](https://arxiv.org/abs/2509.15756)
*Dongyang Zhan,Kai Tan,Lin Ye,Xiangzhan Yu,Hongli Zhang,Zheng He*

Main category: cs.CR

TL;DR: This paper introduces a robust malware detection framework using behavior-unit analysis with multilevel deep learning, effectively mitigating adversarial attacks by capturing contextual semantics while outperforming baselines in obfuscation attack resistance.


<details>
  <summary>Details</summary>
Motivation: Sequential deep learning models (e.g., RNN/LSTM) fail to defend against adversarial attacks that manipulate behavior sequences, creating vulnerabilities in malware detection. Existing approaches do not address obfuscation attacks that perturb sequential characteristics.

Method: The method involves: (1) identifying behavior units with representative semantic information; (2) using a multilevel deep learning model to analyze behavior unit semantics and contextual relationships; (3) mitigating perturbation attacks targeting both local and large-scale behaviors.

Result: Experimental validation demonstrates the proposed method outperforms existing techniques in detecting obfuscation attacks, showing improved robustness against perturbation attacks targeting both local and large-scale behavior patterns.

Conclusion: The proposed approach enhances malware classification robustness against adversarial attacks by leveraging behavior units, achieving superior performance across both low-level and high-level behavior logs.

Abstract: Sequential deep learning models (e.g., RNN and LSTM) can learn the sequence
features of software behaviors, such as API or syscall sequences. However,
recent studies have shown that these deep learning-based approaches are
vulnerable to adversarial samples. Attackers can use adversarial samples to
change the sequential characteristics of behavior sequences and mislead malware
classifiers. In this paper, an adversarial robustness anomaly detection method
based on the analysis of behavior units is proposed to overcome this problem.
We extract related behaviors that usually perform a behavior intention as a
behavior unit, which contains the representative semantic information of local
behaviors and can be used to improve the robustness of behavior analysis. By
learning the overall semantics of each behavior unit and the contextual
relationships among behavior units based on a multilevel deep learning model,
our approach can mitigate perturbation attacks that target local and
large-scale behaviors. In addition, our approach can be applied to both
low-level and high-level behavior logs (e.g., API and syscall logs). The
experimental results show that our approach outperforms all the compared
methods, which indicates that our approach has better performance against
obfuscation attacks.

</details>


### [10] [Flying Drones to Locate Cyber-Attackers in LoRaWAN Metropolitan Networks](https://arxiv.org/abs/2509.15725)
*Matteo Repetto,Enrico Cambiaso,Fabio Patrone,Sandro Zappatore*

Main category: cs.CR

TL;DR: The paper proposes a cyber-physical security framework using UAVs (FOLLOWME project)
                      to locate attackers in wireless IoT networks (particularly LoRaWAN), addressing the challenge
                      of identifying mobile adversaries in critical infrastructure.


<details>
  <summary>Details</summary>
Motivation: Critical IoT services face vulnerabilities due to wireless networks, but
                      tracing mobile attackers (e.g., with portable jamming devices)
                      is currently infeasible despite detectable attacks—hindering
                      effective threat mitigation in smart city environments.

Method: Integrates network telemetry (anomaly detection, attack pattern recognition with
                      gateway localization) with UAV-based wireless localization (systematic scanning of
                      high-risk areas). Focuses on LoRaWAN protocol for Smart City applications.

Result: Develops a framework that combines coarse-grained network alerts with UAV-driven
                      fine-grained localization to trace and intercept attackers in
                      long-range metropolitan IoT networks.

Conclusion: The project demonstrates feasible use of UAVs to overcome limitations of existing
                      tools in tracking mobile radio attacks, offering a scalable solution
                      for secure Smart City radio spectrum management.

Abstract: Today, many critical services and industrial systems rely on wireless
networks for interaction with the IoT, hence becoming vulnerable to a broad
number of cyber-threats. While detecting this kind of attacks is not difficult
with common cyber-security tools, and even trivial for jamming, finding their
origin and identifying culprits is almost impossible today, yet indispensable
to stop them, especially when attacks are generated with portable or self-made
devices that continuously move around. To address this open challenge, the
FOLLOWME project investigates the feasibility of using UAV to locate and even
chase attackers during illicit usage of the radio spectrum. The main objective
is to develop a cyber-physical security framework that integrates network
telemetry with wireless localization. The former triggers alarms in case of
anomalies or known attack patterns and provides a coarse-grained indication of
the physical area (i.e., the position of affected access gateways), whereas the
latter systematically scans such area to identify the exact location of the
attacker. The project will specifically address long-range metropolitan area
networks and focus on the LoRaWAN protocol, which is the typical scenario for
Smart City services.

</details>


### [11] [A High-performance Real-time Container File Monitoring Approach Based on Virtual Machine Introspection](https://arxiv.org/abs/2509.16030)
*Kai Tan,Dongyang Zhan,Lin Ye,Hongli Zhang,Binxing Fang,Zhihong Tian*

Main category: cs.CR

TL;DR: This paper proposes a VM-introspection-based container file monitoring solution that overcomes security weaknesses and performance limitations of existing host-based methods, achieving effective file monitoring with low overhead.


<details>
  <summary>Details</summary>
Motivation: Existing container file monitoring methods based on host OS or virtual machine introspection face security risks (e.g., container escape vulnerabilities) and high computational overhead, necessitating a more secure and efficient solution.

Method: The authors propose a container file monitoring approach utilizing virtual machine introspection instead of relying on the host operating system, enhancing security and reducing monitoring overhead.

Result: Experiments demonstrate effective container file monitoring with acceptable performance overhead, validating the approach's feasibility.

Conclusion: The proposed high-performance container file monitoring method based on virtual machine introspection effectively addresses security and performance issues in existing solutions.

Abstract: As cloud computing continues to advance and become an integral part of modern
IT infrastructure, container security has emerged as a critical factor in
ensuring the smooth operation of cloud-native applications. An attacker can
attack the service in the container or even perform the container escape attack
by tampering with the files. Monitoring container files is important for APT
detection and cyberspace security. Existing file monitoring methods are usually
based on host operating system or virtual machine introspection to protect file
security in real time. The methods based on the host operating system usually
monitor file operations in the host operating system. However, when the
container escapes to the host, the host operating system will no longer be
secure, so these methods face the problem of weak security. Aiming at the
problems of low security and high overload introduced in existing container
file monitoring, a high-performance container file monitoring method based on
virtual machine introspection is proposed. The experimental results show that
the proposed approach can effectively monitor the container files and introduce
an acceptable monitoring overload.

</details>


### [12] [ConCap: Practical Network Traffic Generation for Flow-based Intrusion Detection Systems](https://arxiv.org/abs/2509.16038)
*Miel Verkerken,Laurens D'hooge,Bruno Volckaert,Filip De Turck,Giovanni Apruzzese*

Main category: cs.CR

TL;DR: ConCap solves NIDS research's data problem by enabling realistic, labeled network data generation in a reproducible, open-source framework


<details>
  <summary>Details</summary>
Motivation: Prior NIDS research suffers from questionable data representativeness and reproducibility due to challenges in obtaining real-world network data, undermining scientific validity.

Method: Proposes ConCap, an open-source tool that creates isolated network environments to generate automatically-labeled network data (e.g., packets, NetFlows) through customizable configurations, ensuring research reproducibility with shared setup files.

Result: Empirical validation across 10 network activities, 21 activity variants, and 100 repetitions shows ConCap data mirrors real-world networks; benchmark comparisons confirm functional equivalence of ConCap NetFlows to real datasets; tool safely replicates attack chains for testing.

Conclusion: ConCap addresses the critical issue of data reliability and reproducibility in NIDS research by enabling the generation of realistic, labeled network data in a controlled environment, thereby enhancing the validity and replicability of experiments.

Abstract: Network Intrusion Detection Systems (NIDS) have been studied in research for
almost four decades. Yet, despite thousands of papers claiming scientific
advances, a non-negligible number of recent works suggest that the findings of
prior literature may be questionable. At the root of such a disagreement is the
well-known challenge of obtaining data representative of a real-world
network-and, hence, usable for security assessments. We tackle such a challenge
in this paper. We propose ConCap, a practical tool meant to facilitate
experimental research on NIDS. Through ConCap, a researcher can set up an
isolated and lightweight network environment and configure it to produce
network-related data, such as packets or NetFlows, that are automatically
labeled, hence ready for fine-grained experiments. ConCap is rooted on
open-source software and is designed to foster experimental reproducibility
across the scientific community by sharing just one configuration file. Through
comprehensive experiments on 10 different network activities, further expanded
via in-depth analyses of 21 variants of two specific activities and of 100
repetitions of four other ones, we empirically verify that ConCap produces
network data resembling that of a real-world network. We also carry out
experiments on well-known benchmark datasets as well as on a real "smart-home"
network, showing that, from a cyber-detection viewpoint, ConCap's
automatically-labeled NetFlows are functionally equivalent to those collected
in other environments. Finally, we show that ConCap enables to safely reproduce
sophisticated attack chains (e.g., to test/enhance existing NIDS). Altogether,
ConCap is a solution to the "data problem" that is plaguing NIDS research.

</details>


### [13] [How Exclusive are Ethereum Transactions? Evidence from non-winning blocks](https://arxiv.org/abs/2509.16052)
*Vabuk Pahari,Andrea Canidio*

Main category: cs.CR

TL;DR: The study examines Ethereum block proposers' exclusive/ private transactions, revealing 77.2-84% of builder revenues from exclusive transactions unexplained by sender-builder monopolies.


<details>
  <summary>Details</summary>
Motivation: This research investigates mechanisms driving builder revenues in Ethereum's MEV ecosystem to assess decentralization effects and market monopolization risks from transaction exclusivity patterns.

Method: Analyzed 15,097 blocks in an 8-minute window through transaction classification (exclusive/private), sender-routing analysis, and blockchain log pattern detection using Ethereum's December 3, 2024 block data.

Result: 84% of total transaction fees in winning blocks stem from exclusive transactions; 77.2% remain after duplicates, with only 7% linked to sender-builder monopolies. Private transactions contribute 16% of blockspace revenue.

Conclusion: Exclusive transaction dominance in builder revenues far exceeds sender-builder natural monopolies, suggesting structural market advantages over standard MEV extraction in Ethereum's current design.

Abstract: We analyze 15,097 blocks proposed for inclusion in Ethereum's blockchain over
an 8-minute window on December 3, 2024, during which 38 blocks were added to
the chain. We classify transactions as exclusive -- present only in blocks from
a single builder -- or private -- absent from the public mempool but included
in blocks from multiple builders. We find that exclusive transactions account
for 84% of the total fees paid by transactions in winning blocks. Furthermore,
we show that exclusivity cannot be fully explained by exclusive relationships
between senders and builders: about 7% of all exclusive transactions included
on-chain, by value, come from senders who route exclusively to a single
builder. Analyzing transaction logs shows that some exclusive transactions are
duplicates or variations of the same strategy, but even accounting for that,
the share of the total fees paid by transactions in winning blocks is at least
77.2%. Taken together, our findings highlight that exclusive transactions are
the dominant source of builder revenues.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges](https://arxiv.org/abs/2509.15283)
*Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo*

Main category: cs.SE

TL;DR: Open-source local LLMs solve only about half as many programming challenges as proprietary models, but the paper shows how to evaluate them using an improved offline framework that streamlines testing across thousands of programming tasks.


<details>
  <summary>Details</summary>
Motivation: This work addresses the need to compare performance between open-source local LLM deployments (with cost control) and state-of-the-art proprietary models in solving complex, context-rich programming tasks. This provides practical insights for organizations choosing between open vs. closed solutions.

Method: The authors enhanced the FACE framework by retrofitting it to operate offline using the Ollama runtime, consolidating the file structure into JSON files, and adding checkpointing. They evaluated eight open-source LLMs with 6.7-9 billion parameters across 3,589 Kattis programming problems.

Result: The open-source models achieved a pass@1 accuracy of approximately 50% compared to the acceptance rates of the proprietary models. This highlights a persistent performance gap but also shows the feasibility of evaluating large LLM performance using the enhanced offline framework.

Conclusion: The study concludes that while there is a performance gap between open-source local LLMs and proprietary models like Gemini 1.5 and ChatGPT-4 in competitive programming tasks, the evaluation framework demonstrates the practical benefits of open models and shows their rapid progress. This allows organizations to replicate the evaluation on in-house hardware.

Abstract: This study examines the performance of today's open-source, locally hosted
large-language models (LLMs) in handling complex competitive programming tasks
with extended problem descriptions and contexts. Building on the original
Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit
the pipeline to work entirely offline through the Ollama runtime, collapsing
FACE's sprawling per-problem directory tree into a handful of consolidated JSON
files, and adding robust checkpointing so multi-day runs can resume after
failures. The enhanced framework generates, submits, and records solutions for
the full Kattis corpus of 3,589 problems across eight code-oriented models
ranging from 6.7-9 billion parameters. The submission results show that the
overall pass@1 accuracy is modest for the local models, with the best models
performing at approximately half the acceptance rate of the proprietary models,
Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between
private, cost-controlled LLM deployments and state-of-the-art proprietary
services, yet also highlight the rapid progress of open models and the
practical benefits of an evaluation workflow that organizations can replicate
on in-house hardware.

</details>


### [15] [LoCaL: Countering Surface Bias in Code Evaluation Metrics](https://arxiv.org/abs/2509.15397)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: This paper introduces LoCaL, a benchmark to evaluate reference-based code evaluation metrics (CEMs) by exposing their surface-level bias. The authors highlight existing CEMs tend to prioritize superficial similarity over functional correctness and demonstrate their performance degradation on LoCaL's diverse code pairs.


<details>
  <summary>Details</summary>
Motivation: Existing CEMs rely on either expensive test case execution or flawed surface-based comparisons with reference implementations. Current evaluations lack scenarios that distinguish between surface and functional similarity, hindering progress in developing reliable metrics for LLM-generated code.

Method: The authors: (1）Analyzed four state-of-the-art reference-based CEMs for surface bias (2）Created LoCaL - a benchmark with 3,117 code pairs labeled with functional similarity scores derived from differential fuzzing (3）Compared CEM performance on LoCaL against baseline datasets

Result: All tested CEMs exhibited significant performance degradation on LoCaL compared to baseline datasets. The benchmark successfully identified surface-biased evaluation gaps through code pairs with conflicting surface/functional similarity patterns.

Conclusion: Exposing CEMs to surface-discrepant scenarios in LoCaL-style benchmarks can help develop more functionally robust metrics. The study emphasizes the need for evaluation frameworks that explicitly address the surface vs. functional similarity tradeoff in code generation assessment.

Abstract: With the increasing popularity of large language models (LLMs) and LLM-based
agents, reliable and effective code evaluation metrics (CEMs) have become
crucial for progress across several software engineering tasks. While popular
benchmarks often provide test cases to assess the correctness of generated
code, crafting and executing test cases is expensive. Reference-based CEMs
provide a cheaper alternative by scoring a candidate program based on its
functional similarity to a reference. Although prior research has focused on
reporting the weak correlation between these CEMs and functional correctness,
the causes are only assumed, and plausible solutions remain unexplored. In this
work, we critically evaluate four state-of-the-art reference-based CEMs,
revealing their strong bias towards surface-level features rather than code
functionality. Despite this surface bias, current evaluation datasets for these
CEMs rarely include code pairs that are surface-similar yet functionally
dissimilar, or functionally similar yet surface-dissimilar. To mitigate this
gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117
code pairs at both the method and program levels. Each pair is labeled with a
functional similarity score and aims to target regions where CEMs are likely to
perform poorly. The functional similarity scores are calculated through
differential fuzzing, which eliminates the need for predefined test cases and,
at the same time, improves the reliability of the scores by executing an order
of magnitude more tests than prior work. We find that all four CEMs show
significant performance degradation on LoCaL, compared to the baselines.
Finally, based on our findings, we draw the implication that exposing CEMs to
LoCaL-like data might facilitate the development of metrics that are robust to
surface bias.

</details>


### [16] [Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation](https://arxiv.org/abs/2509.15567)
*Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang*

Main category: cs.SE

TL;DR: The paper proposes using concise text templates to condense code changes (summarized changes, elicited comments, emphasized identifiers) to improve commit message generation via CodeLlama-7B fine-tuning, achieving significant improvements over six baselines.


<details>
  <summary>Details</summary>
Motivation: Developers often neglect high-quality commit messages despite their importance for software maintenance. Existing methods require complex representations (graphs/embeddings); this approach explores simpler, human-readable templates to enhance pre-trained models.

Method: 1) Templates condense code changes into summarized edits, code comments, and key identifiers using ChangeScribe. 2) Fine-tune CodeLlama-7B on template-commit message pairs. 3) Leverage templates' brevity while maintaining readability as input to language models.

Result: Outperformed six baselines by 51.7% (BLEU-Norm), 78.7% (METEOR), and 62.5% (ROUGE-L). Ablation studies and human evaluations confirmed the effectiveness of all template components.

Conclusion: Text templates provide a concise, effective alternative to complex representations for commit message generation, improving model performance while maintaining readability and interpretability for developers.

Abstract: Commit messages are valuable resources for describing why code changes are
committed to repositories in version control systems (e.g., Git). They
effectively help developers understand code changes and better perform software
maintenance tasks. Unfortunately, developers often neglect to write
high-quality commit messages in practice. Therefore, a growing body of work is
proposed to generate commit messages automatically. These works all
demonstrated that how to organize and represent code changes is vital in
generating good commit messages, including the use of fine-grained graphs or
embeddings to better represent code changes. In this study, we choose an
alternative way to condense code changes before generation, i.e., proposing
brief yet concise text templates consisting of the following three parts: (1)
summarized code changes, (2) elicited comments, and (3) emphasized code
identifiers. Specifically, we first condense code changes by using our proposed
templates with the help of a heuristic-based tool named ChangeScribe, and then
fine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding
commit messages. Our proposed templates better utilize pre-trained language
models, while being naturally brief and readable to complement generated commit
messages for developers. Our evaluation based on a widely used dataset showed
that our approach can outperform six baselines in terms of BLEU-Norm, METEOR,
and ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,
respectively. The ablation study and human evaluation also provide further
insights into the effectiveness of our approach.

</details>


### [17] [How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches](https://arxiv.org/abs/2509.15777)
*Haoran Xu,Zhi Chen,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng*

Main category: cs.SE

TL;DR: This paper addresses software vulnerability detection by introducing a two-stage framework combining version filtering and LLM-based dialogue voting, validated on 750 real vulnerabilities to show superior performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: Current methods for vulnerability patch detection suffer from scalability, accuracy, and generalization limitations. Manual approaches are error-prone, while automated solutions lack robustness and practical deployment viability, necessitating a paradigm shift.

Method: The authors introduce a two-stage framework combining (1) version-driven candidate filtering to reduce search space and (2) a large language model-based multi-round dialogue voting system for precise patch identification. This integrates semantic understanding with iterative refinement.

Result: Experiments on a dataset of 750 real vulnerabilities show the proposed method outperforms state-of-the-art approaches in accuracy and efficiency, validating its four key empirical insights.

Conclusion: This paper proposes a novel two-stage framework for vulnerability patch detection, demonstrating superior performance over existing methods through empirical validation on a real-world dataset. The insights derived from the study provide actionable guidelines for future research and practical deployment in software security.

Abstract: Open-source software vulnerability patch detection is a critical component
for maintaining software security and ensuring software supply chain integrity.
Traditional manual detection methods face significant scalability challenges
when processing large volumes of commit histories, while being prone to human
errors and omissions. Existing automated approaches, including heuristic-based
methods and pre-trained model solutions, suffer from limited accuracy, poor
generalization capabilities, and inherent methodological constraints that
hinder their practical deployment. To address these fundamental challenges,
this paper conducts a comprehensive empirical study of existing vulnerability
patch detection methods, revealing four key insights that guide the design of
effective solutions: the critical impact of search space reduction, the
superiority of pre-trained semantic understanding over architectural
complexity, the temporal limitations of web crawling approaches, and the
advantages of knowledge-driven methods. Based on these insights, we propose a
novel two-stage framework that combines version-driven candidate filtering with
large language model-based multi-round dialogue voting to achieve accurate and
efficient vulnerability patch identification. Extensive experiments on a
dataset containing 750 real vulnerabilities demonstrate that our method
outperforms current approaches.

</details>


### [18] [Failure Modes and Effects Analysis: An Experience from the E-Bike Domain](https://arxiv.org/abs/2509.15893)
*Andrea Bombarda,Federico Conti,Marcello Minervini,Aurora Zanenga,Claudio Menghi*

Main category: cs.SE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Software failures can have catastrophic and costly consequences. Functional
Failure Mode and Effects Analysis (FMEA) is a standard technique used within
Cyber-Physical Systems (CPS) to identify software failures and assess their
consequences. Simulation-driven approaches have recently been shown to be
effective in supporting FMEA. However, industries need evidence of the
effectiveness of these approaches to increase practical adoption. This
industrial paper presents our experience with using FMEA to analyze the safety
of a CPS from the e-Bike domain. We used Simulink Fault Analyzer, an industrial
tool that supports engineers with FMEA. We identified 13 realistic faults,
modeled them, and analyzed their effects. We sought expert feedback to analyze
the appropriateness of our models and the effectiveness of the faults in
detecting safety breaches. Our results reveal that for the faults we
identified, our models were accurate or contained minor imprecision that we
subsequently corrected. They also confirm that FMEA helps engineers improve
their models. Specifically, the output provided by the simulation-driven
support for 38.4% (5 out of 13) of the faults did not match the engineers'
expectations, helping them discover unexpected effects of the faults. We
present a thorough discussion of our results and ten lessons learned. Our
findings are useful for software engineers who work as Simulink engineers, use
the Simulink Fault Analyzer, or work as safety analysts.

</details>


### [19] [LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines](https://arxiv.org/abs/2509.15971)
*Owen Truong,Terrence Zhang,Arnav Marchareddy,Ryan Lee,Jeffery Busold,Michael Socas,Eman Abdullah AlOmar*

Main category: cs.SE

TL;DR: The paper introduces LeakageDetector, a VS Code extension to detect and fix three types of Data Leakage (Overlap, Preprocessing, Multi-test) in Jupyter Notebook ML code, offering automated correction via quick fixes and LLM-guided best practices.


<details>
  <summary>Details</summary>
Motivation: Data Leakage in ML model evaluation leads to overestimated performance, yet manual detection is error-prone. Existing tools lack integration directly in ML engineers' development environments.

Method: Developed a VS Code extension that analyzes Jupyter Notebooks for leakage patterns using static code analysis and AST parsing. Implements two correction strategies: manual quick fixes and LLM-powered suggestions for pipeline restructuring.

Result: LeakageDetector successfully identifies three major leakage types, with validation showing effectiveness in detecting real-world leakage scenarios and providing actionable fixes.

Conclusion: Automated leakage detection in development workflows improves ML code quality and reduces human error through immediate feedback and education on proper pipeline practices.

Abstract: In software development environments, code quality is crucial. This study
aims to assist Machine Learning (ML) engineers in enhancing their code by
identifying and correcting Data Leakage issues within their models. Data
Leakage occurs when information from the test dataset is inadvertently included
in the training data when preparing a data science model, resulting in
misleading performance evaluations. ML developers must carefully separate their
data into training, evaluation, and test sets to avoid introducing Data Leakage
into their code. In this paper, we develop a new Visual Studio Code (VS Code)
extension, called LeakageDetector, that detects Data Leakage, mainly Overlap,
Preprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond
detection, we included two correction mechanisms: a conventional approach,
known as a quick fix, which manually fixes the leakage, and an LLM-driven
approach that guides ML developers toward best practices for building ML
pipelines.

</details>


### [20] [Software Development Aspects of Integrating Linear Algebra Libraries](https://arxiv.org/abs/2509.16081)
*Marcel Koch,Tobias Ribizel,Pratik Nayak,Fritz Göbel,Gregor Olenik,Terry Cojean*

Main category: cs.SE

TL;DR: This paper analyzes the use and influence of the Ginkgo software library in various application domains.


<details>
  <summary>Details</summary>
Motivation: Simulation software drives scientific discovery and productivity, yet they often have to incorporate specialized components from unfamiliar domains to manage sparse numerical linear algebra tasks.

Method: The authors have focused on examining the experiences and impacts of integrating Ginkgo into different applications.

Result: Successful adaptations of Ginkgo have reduced the burden on developers to manage cross-domain software components and enhanced the applications' performance.

Conclusion: The integration of the Ginkgo library exemplifies a sustainable approach to using specialized software components in broader simulation contexts, making maintenance and performance improvements more feasible.

Abstract: Many scientific discoveries are made through, or aided by, the use of
simulation software. These sophisticated software applications are not built
from the ground up, instead they rely on smaller parts for specific use cases,
usually from domains unfamiliar to the application scientists. The software
library Ginkgo is one of these building blocks to handle sparse numerical
linear algebra on different platforms. By using Ginkgo, applications are able
to ease the transition to modern systems, and speed up their simulations
through faster numerical linear algebra routines. This paper discusses the
challenges and benefits for application software in adopting Ginkgo. It will
present examples from different domains, such as CFD, power grid simulation, as
well as electro-cardiophysiology. For these cases, the impact of the
integrations on the application code is discussed from a software engineering
standpoint, and in particular, the approaches taken by Ginkgo and the
applications to enable sustainable software development are highlighted.

</details>


### [21] [When Bugs Linger: A Study of Anomalous Resolution Time Outliers and Their Themes](https://arxiv.org/abs/2509.16140)
*Avinash Patil*

Main category: cs.SE

TL;DR: The study analyzes bug resolution anomalies in seven open-source projects, identifying patterns around test failures, enhancement requests, and UI issues using statistical and clustering techniques.


<details>
  <summary>Details</summary>
Motivation: To improve software quality and user satisfaction by understanding and addressing the causes of unusually long bug resolution times through systematic analysis.

Method: The authors employed statistical methods (Z-score, IQR) to detect anomalies in resolution durations and used TF-IDF and KMeans clustering for thematic analysis of bug summaries.

Result: Anomalies in bug resolution times were found across multiple projects, with frequent clustering around test failures, enhancement requests, and user interface-related issues.

Conclusion: The proposed method offers actionable insights for project maintainers to prioritize and resolve long-standing bugs effectively, contributing to better software maintenance practices.

Abstract: Efficient bug resolution is critical for maintaining software quality and
user satisfaction. However, specific bug reports experience unusually long
resolution times, which may indicate underlying process inefficiencies or
complex issues. This study presents a comprehensive analysis of bug resolution
anomalies across seven prominent open-source repositories: Cassandra, Firefox,
Hadoop, HBase, SeaMonkey, Spark, and Thunderbird. Utilizing statistical methods
such as Z-score and Interquartile Range (IQR), we identify anomalies in bug
resolution durations. To understand the thematic nature of these anomalies, we
apply Term Frequency-Inverse Document Frequency (TF-IDF) for textual feature
extraction and KMeans clustering to group similar bug summaries. Our findings
reveal consistent patterns across projects, with anomalies often clustering
around test failures, enhancement requests, and user interface issues. This
approach provides actionable insights for project maintainers to prioritize and
effectively address long-standing bugs.

</details>


### [22] [MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair](https://arxiv.org/abs/2509.16187)
*Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening*

Main category: cs.SE

TL;DR: This paper introduces MatchFixAgent, a multi-agent framework using LLMs for code translation validation and repair. It outperforms existing methods in cross-language generalization and repair effectiveness through semantic analysis, test generation, and automated bug fixing.


<details>
  <summary>Details</summary>
Motivation: Current code translation validation approaches have poor generalization across multiple programming languages due to high engineering overhead and reliance on insufficient test suites, leading to unreliable equivalence verification and ineffective repairs.

Method: The framework employs four specialized agents: a multi-agent architecture divides validation into semantic analysis subtasks, a test agent writes/execute tests, a repair agent fixes translation bugs based on test failures, and a verdict agent synthesizes analysis to declare (in)equivalence decisions.

Result: Evaluations on 2,219 translation pairs across 6 PL pairs show 99.2% equivalence validation accuracy (72.8% agreement with prior work, but 60.7% correct when disagreeing) and 50.6% repair success rate (vs 18.5% in prior work), demonstrating superior adaptability and accuracy.

Conclusion: MatchFixAgent establishes a more reliable and PL-agnostic approach to code translation validation and repair, significantly improving cross-language generalization and correction capabilities through its multi-agent architecture and LLM-driven semantic analysis framework.

Abstract: Code translation transforms source code from one programming language (PL) to
another. Validating the functional equivalence of translation and repairing, if
necessary, are critical steps in code translation. Existing automated
validation and repair approaches struggle to generalize to many PLs due to high
engineering overhead, and they rely on existing and often inadequate test
suites, which results in false claims of equivalence and ineffective
translation repair. We develop MatchFixAgent, a large language model
(LLM)-based, PL-agnostic framework for equivalence validation and repair of
translations. MatchFixAgent features a multi-agent architecture that divides
equivalence validation into several sub-tasks to ensure thorough and consistent
semantic analysis of the translation. Then it feeds this analysis to test agent
to write and execute tests. Upon observing a test failure, the repair agent
attempts to fix the translation bug. The final (in)equivalence decision is made
by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four
repository-level code translation techniques. We use 2,219 translation pairs
from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub
projects totaling over 900K lines of code. Our results demonstrate that
MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,
with the same equivalence validation result as prior work on 72.8% of them.
When MatchFixAgent's result disagrees with prior work, we find that 60.7% of
the time MatchFixAgent's result is actually correct. In addition, we show that
MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior
work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to
many PL pairs than prior work, while producing highly accurate validation
results.

</details>
