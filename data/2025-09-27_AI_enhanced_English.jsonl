{"id": "2509.20380", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.20380", "abs": "https://arxiv.org/abs/2509.20380", "authors": ["Samyak Jhaveri", "Vanessa Klotzmann", "Crista Lopes"], "title": "ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation", "comment": null, "summary": "The increasing ubiquity of GPUs is accompanied by the increasing complexity\nof their hardware and parallel programming frameworks. Directive-based parallel\nprogramming standards like OpenACC simplify GPU programming to some extent by\nabstracting away low-level complexities, but a fair amount of expertise is\nstill required in order to use those directives effectively.\n  We introduce ACCeLLiuM, two open weights Large Language Models specifically\nfine-tuned for generating expert OpenACC directives for data-parallel loops,\nalong with the supervised fine-tuning dataset that was used to train them. The\nACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from\npublic GitHub C/C++ repositories, with 3,223 pairs for training and 810 for\ntesting. Experimental evaluations show a pronounced performance gap in\ngenerating correct OpenACC pragmas between base LLMs and our fine-tuned\nversions. On the held-out test set, base LLMs fail to consistently generate\nvalid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid\npragmas with the correct directive type for $87\\%$ of the data-parallel loops,\nand exact pragmas--including directives, clauses, clause order, and clause\nvariables--for $50\\%$ of the cases. Even when not exact, generated pragmas\nfrequently incorporate the correct clauses in a different order than the\nground-truth label, or include additional clauses that enable finer control\nover parallel execution, data movement, and concurrency, offering practical\nvalue beyond strict string-matching. By publicly releasing the code, models,\nand dataset as ACCeLLiuM we hope to establish a reproducible benchmark for\nLLM-powered OpenACC pragma generation, and lower the barrier to automated GPU\noffloading of serially written programs.", "AI": {"tldr": "ACCeLLiuM fine-tuned LLMs outperform baselines in generating accurate OpenACC pragmas, enabling practical GPU offloading automation.", "motivation": "GPU parallel programming remains complex despite abstraction tools like OpenACC; reducing required expertise for effective directive usage is critical for broader adoption.", "method": "Developed ACCeLLiuM using a dataset of 4,033 OpenACC pragma-loop pairs via supervised fine-tuning. Models were evaluated using precision metrics for directive generation.", "result": "Fine-tuned LLMs achieved 87% valid directive-type accuracy and 50% exact pragma matches. Generated pragmas included useful clause variations even in non-exact cases.", "conclusion": "The study presents ACCeLLiuM, two fine-tuned LLMs for generating OpenACC directives, aiming to establish a reproducible benchmark and reduce barriers for automated GPU programming."}}
{"id": "2509.20385", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.20385", "abs": "https://arxiv.org/abs/2509.20385", "authors": ["Ishara Devendra", "Chaman Wijesiriwardana", "Prasad Wimalaratne"], "title": "State-of-the-Art in Software Security Visualization: A Systematic Review", "comment": null, "summary": "Software security visualization is an interdisciplinary field that combines\nthe technical complexity of cybersecurity, including threat intelligence and\ncompliance monitoring, with visual analytics, transforming complex security\ndata into easily digestible visual formats. As software systems get more\ncomplex and the threat landscape evolves, traditional text-based and numerical\nmethods for analyzing and interpreting security concerns become increasingly\nineffective. The purpose of this paper is to systematically review existing\nresearch and create a comprehensive taxonomy of software security visualization\ntechniques through literature, categorizing these techniques into four types:\ngraph-based, notation-based, matrix-based, and metaphor-based visualization.\nThis systematic review explores over 60 recent key research papers in software\nsecurity visualization, highlighting its key issues, recent advancements, and\nprospective future research directions. From the comprehensive analysis, the\ntwo main areas were distinctly highlighted as extensive software development\nvisualization, focusing on advanced methods for depicting software\narchitecture: operational security visualization and cybersecurity\nvisualization. The findings highlight the necessity for innovative\nvisualization techniques that adapt to the evolving security landscape, with\npractical implications for enhancing threat detection, improving security\nresponse strategies, and guiding future research.", "AI": {"tldr": "This paper systematically reviews software security visualization techniques, categorizing them into four types (graph-based, notation-based, matrix-based, metaphor-based) through analysis of 60 research papers, while identifying two main areas (software development and operational/cybersecurity visualization).", "motivation": "Traditional text-based/normative security analysis methods are becoming ineffective with system complexity and evolving threats.", "method": "Systematic review of over 60 recent key research papers to create a taxonomy and identify patterns.", "result": "A comprehensive taxonomy of four visualization types, identification of two core research areas, and analysis of key issues/advancements.", "conclusion": "Innovative adaptive visualization techniques are urgently needed to improve threat detection and security responses through evolving visualization methods."}}
{"id": "2509.20386", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.20386", "abs": "https://arxiv.org/abs/2509.20386", "authors": ["Nishant Gaurav", "Adit Akarsh", "Ankit Ranjan", "Manoj Bajaj"], "title": "Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments", "comment": null, "summary": "We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-\nficiently operate with extensive Model Control Protocol (MCP) tool sets that\nexceed the contextual memory limitations of large language models. Our approach\naddresses the fundamental challenge of tool selection in environments\ncontaining hundreds or thousands of available tools, where loading all tools\nsimultaneously is computationally infeasible. We propose and evaluate five\ndistinct architectures that progressively refine the tool selection process,\nculminating in a search-and-load mechanism that achieves intelligent tool\nselection with minimal computational overhead. Our experimental results\ndemonstrate that the proposed approach reduces tool loading by up to 50% while\nmaintaining task completion accuracy, advancing the path towards truly\ngeneral-purpose AI agents capable of dynamically adapting to diverse task\nenvironments.", "AI": {"tldr": "Dynamic ReAct enables efficient tool selection for large-scale AI agents by introducing a hierarchical system that reduces computational overhead by 50% while maintaining performance.", "motivation": "Traditional ReAct agents fail with extensive tool sets due to memory limitations and computational infeasibility of loading all tools simultaneously.", "method": "Five iterative architectures culminating in a context-aware search-and-load mechanism for progressive tool selection refinement.", "result": "50% reduction in tool loading overhead with preserved task completion accuracy across diverse environments.", "conclusion": "Dynamic ReAct advances general-purpose AI agents by enabling intelligent, low-overhead adaptation to large tool environments."}}
{"id": "2509.20387", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.20387", "abs": "https://arxiv.org/abs/2509.20387", "authors": ["Qusai Ramadan", "Jukka Ruohonen", "Abhishek Tiwari", "Adam Alami", "Zeyd Boukhers"], "title": "Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper", "comment": "Accepted at the 2025 IEEE 33rd International Requirements Engineering\n  Conference Workshops", "summary": "Decisions suggested by improperly designed software systems might be prone to\ndiscriminate against people based on protected characteristics, such as gender\nand ethnicity. Previous studies attribute such undesired behavior to flaws in\nalgorithmic design or biased data. However, these studies ignore that\ndiscrimination is often the result of a lack of well-specified fairness\nrequirements and their verification. The fact that experts' knowledge about\nfairness is often implicit makes the task of specifying precise and verifiable\nfairness requirements difficult. In related domains, such as security\nengineering, knowledge graphs have been proven to be effective in formalizing\nknowledge to assist requirements specification and verification. To address the\nlack of formal mechanisms for specifying and verifying fairness requirements,\nwe propose the development of a knowledge graph-based framework for fairness.\nIn this paper, we discuss the challenges, research questions, and a road map\ntowards addressing the research questions.", "AI": {"tldr": "This paper proposes a knowledge graph-based framework to address fairness requirements in software systems, aiming to bridge gaps in formalizing and verifying fairness, which differ from existing approaches focused on algorithmic bias or data issues.", "motivation": "The study addresses the lack of well-specified fairness requirements and their verification, highlighting that discrimination in software systems often stems from implicit expert knowledge and unaddressed fairness requirements, unlike prior focuses on biased data or algorithms.", "method": "The authors leverage knowledge graphs, inspired by security engineering applications, to formalize fairness knowledge and create a verifiable framework for fairness requirements, outlining challenges and a research roadmap.", "result": "The paper presents a framework for fairness knowledge graphs, identifies research challenges, formulates research questions, and proposes a roadmap for addressing these challenges.", "conclusion": "The framework enables systematic specification and verification of fairness requirements, offering a structured approach to mitigate discrimination risks in software systems through formalized, domain-agnostic knowledge representation."}}
{"id": "2509.20382", "categories": ["cs.CR", "cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20382", "abs": "https://arxiv.org/abs/2509.20382", "authors": ["Dilli Hang Rai", "Sabin Kafley"], "title": "Lightweight MobileNetV1+GRU for ECG Biometric Authentication: Federated and Adversarial Evaluation", "comment": "5 pages, 7 figures, 5 tables", "summary": "ECG biometrics offer a unique, secure authentication method, yet their\ndeployment on wearable devices faces real-time processing, privacy, and\nspoofing vulnerability challenges. This paper proposes a lightweight deep\nlearning model (MobileNetV1+GRU) for ECG-based authentication, injection of\n20dB Gaussian noise & custom preprocessing. We simulate wearable conditions and\nedge deployment using the ECGID, MIT-BIH, CYBHi, and PTB datasets, achieving\naccuracies of 99.34%, 99.31%, 91.74%, and 98.49%, F1-scores of 0.9869, 0.9923,\n0.9125, and 0.9771, Precision of 0.9866, 0.9924, 0.9180 and 0.9845, Recall of\n0.9878, 0.9923, 0.9129, and 0.9756, equal error rates (EER) of 0.0009, 0.00013,\n0.0091, and 0.0009, and ROC-AUC values of 0.9999, 0.9999, 0.9985, and 0.9998,\nwhile under FGSM adversarial attacks, accuracy drops from 96.82% to as low as\n0.80%. This paper highlights federated learning, adversarial testing, and the\nneed for diverse wearable physiological datasets to ensure secure and scalable\nbiometrics.", "AI": {"tldr": "This paper proposes a lightweight deep learning model (MobileNetV1+GRU) for secure ECG biometric authentication, evaluates its performance across datasets, and highlights challenges like adversarial attacks and dataset diversity needs.", "motivation": "ECG biometrics face challenges in real-time processing, privacy, and spoofing vulnerability when deployed on wearable devices, necessitating efficient and secure solutions.", "method": "A lightweight MobileNetV1+GRU model is designed with 20dB Gaussian noise injection and custom preprocessing. Evaluated on four datasets (ECGID, MIT-BIH, CYBHi, PTB) under wearable conditions and edge deployment, including adversarial FGSM attack testing.", "result": "Achieved 99.34% accuracy on ECGID (EER=0.0009, ROC-AUC=0.9999), 99.31% on MIT-BIH (EER=0.00013, ROC-AUC=0.9999), and similar strong metrics. Under FGSM attacks, accuracy drops to as low as 0.80%.", "conclusion": "The paper stresses the importance of federated learning, adversarial robustness testing, and diverse wearable physiology datasets to ensure secure, scalable biometric systems."}}
